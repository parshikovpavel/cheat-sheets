# Правила построения архитектуры

Основные правила надежности:

- использовать проверенные технологии
- сбор бэкапов
- мониторинг (профилирование), измерять все аспекты работы системы.  

Архитектура должна развиваться постепенно в соответствии с нагрузкой.

Правило 95 процентиля: стоит пренебречь 5% пользователей (использующих нестандартные браузеры, нестандартные файлы для загрузки, имеющих большие объемы данных), чтобы не усложнять архитектуру и отладить ее под большинство пользователей.

# Мониторинг (профилирование)

Типы мониторинга:

- Мониторинг серверов – мониторинг серверного железа и серверного ПО

- Мониторинг на уровне приложения – как работают подсистемы самого приложения, как они взаимодействуют с внешними сервисами

- мониторинг на уровне бизнес-логики – метрики по бизнес-объектам (сколько сделана заказов, сколько оставлено комментариев...)

Мониторинг включает

- сбор метрик

- сбор логов, ошибок

- трейсинг сообщений между сервисами в микросервисной архитектуре

Мониторинг решает проблемы:

- Расследование инцидентов

- Прогнозирование нагрузки

Основные внешние метрики проекта:

- RPS;

- время обработки запроса (включая перцентили);

- количество используемой памяти.

## Инструменты мониторинга

Виды инструментов мониторинга:

- *SaaS* (*software as a service*) – клиенту предоставляется внешний сервис для мониторинга, который полностью обслуживается другой стороной:
  - New Relic

- *Self-hosted* решение:

  - *Zabbix*

  - *Grafana*

### Внутренние метрики

Общие метрики:

- время ответа сервиса

- RPS к сервису


База данных:

- количество записей в таблицах


Очереди сообщений:

- длина очереди


- время нахождения сообщения в очереди


Memcached:

- соотношение hit/miss;


- топ нагруженных ключей;


- все внутренние метрики, которые отдаёт команда stats.


# Расчеты метрик

### Метрики памяти

Количество памяти, требуемое некоторому многопроцессному (или многопоточному) приложению (Apache, nginx, MySQL) определяется по формуле:



​                                 

  

Общее количество памяти ограничено доступной на сервере оперативной памятью. 

Если известно количество доступной на сервере памяти, то можно определить максимально возможное количество воркеров из предыдущей формулы:

  

### Метрики для RPS

Самый простейший случай, который можно посчитать, – один воркер обрабатывает только один запрос (Apache, MySQL). Nginx может на одном воркере обрабатывать несколько запросов.

Пусть на одном воркере обрабатывается только один запрос. 

Если известно количество параллельных воркеров ( в соответствии с ограничениями памяти, производительностью процессора, I/O) и среднее время выполнения запроса, то можно узнать максимально возможную RPS:

  

Из формулы можно выразить количество воркеров, которые требуется для того чтобы выдержать нужную нагрузку RPS:

  

Неравномерность RPS в течении дня

Для нагруженного сайта критически важно не суточное число запросов, а мгновенное. 10 млн суточных хитов (динамики) – это 116 запросов в секунду при совершенно равномерном распределении за сутки. Однако как правило характерным является 16 нагруженных часов с двумя/тремя пиками нагрузки (развлекательные ресурсы, fishki.net) или 50-100-200 рывков по 300-700% хитов на фоне тех же 16 часов среднего трафика (электронные сми).

### Примеры расчетов

#### Расчет количества памяти для поддержания нагрузки с нужным RPS на веб-сервере

Исходные условия:

·  веб-сервер Apache, который обрабатывает один запрос в одном воркере

·  нагрузка 500 RPS

·  время обработки запроса 40-100 мсек (у нас 40мсек). Для справки: у сложного фреймворка время обработки запроса 80-100 мсек, для легкого запроса время обработки 40-50 мсек. 

·  накладные расходы Apache на один воркер составляют 10 Мб

·  примем количество памяти, требуемое для ядра Apache, равным 0.

Найдем объем памяти для работы Apache:

  

  

  

#### Расчет количества памяти, потребляемого MySQL

Память, требуемую для ядра, составляют следующие кеши:

·  Пул буферов InnoDB innodb_buffer_pool_size. Подробнее Параметр innodb_buffer_pool_size

·  Буфер ключей MyISAM key_buffer. Подробнее Конфигурирование

·  Кеш запросов (Qcache) query_cache_size. Подробнее Конфигурационные параметры

Память, требуемая для каждого воркера, складывается из:

·  read_buffer_size — кэш под полные сканы таблиц (sequential scan);

·  read_rnd_buffer_size — кэш используется для какой-то специфической  Multi-Range Read optimization при сортировке;

·  sort_buffer_size — кэш, в котором выполняется сортировка результатов;

·  thread_stack — размер стека треда;

·  join_buffer_size — кэш, используемый при соединениях (JOIN).

Максимальное количество воркеров определяется директивой max_connections. 

Поэтому максимально потребляемую память можно рассчитать по формуле, написанно выше:

  

# Постоянные соединения

Это один из способ ускорения приложения. Постоянные соединения можно организовать между разными частями архитектуры. 

Преимущества:

- Постоянное открытие новых соединений нагружает процессор в системе и генерирует дополнительный служебный трафик. 

Недостатки:

- Хотя выбор соединения из пула требует также времени на сброс состояния  
- Может образовываться слишком много соединений с MySQL. На сервере должно быть доступно открытие большого количества потоков (в MySQL переменная `thread_cache`)

Примеры организации постоянных соединений:

- между бэкэндом и базой ([1](PHP.md#постоянные-соединения))
- между nginx и бэкэндами ([1](Nginx.md#keepalive))
- между браузером и веб-сервером ([1](HTTP.md#постоянное-соединение-keep-alive))

# Способы ускорения

## Программный

База данных:

- Убрать мусорные запросы, типа выбор требуемой базы данных перед каждым запросом. Если требуется менять базы, то можно писать полное именя базы перед таблицей. Убрать команду `SET NAMES UTF8`, которая в любом случае не нужна (она не изменяет кодировку в клиентской библиотеке, а воздействует только на сервер). Кодировку нужно настроить по умолчанию на сервере.

- Настроить индексирование БД ([1](Mysql.md#index))
- Выполнить профилирование системы (запросы к базе данных, кода) и оптимизировать узкие места
- если выполняются группы запросов к базе данных, то можно их запаковать в транзакцию ([1](#ускорение-группы-операций-через-транзакции))
- закрывать соединения с БД, если они не нужны, чтобы освобождать потоки MySQL

Другое:

- Использовать gzip сжатие
- отключить ненужные модули в службах (Apache, PHP)
- постоянные соединения ([1](#постоянные соединения))
- использовать кеширование на всех уровнях (приложение, *in-memory*, БД, браузер)
- не использовать *apache* или ставить перед ним *nginx*.

## Архитектурный

- *Scaling* ([1](#scaling))

Начинают с программной оптимизации. Однако существует точка сокращения отдачи, когда каждая следующая программной оптимизация требует все больше усилий и дает все менее заметный результат, хотя сложность приложения при этом быстро возрастает. В этом случае переходят к *scaling*'у.

# Scaling

*Scaling* (масштабирование системы) – применяется, если 

- один узел не справляется с нагрузкой на чтение или на запись. Происходит снижение производительности – в виде замедления обработки запросов, большего потребления процессора, ввода/вывода, роста конкуренции между запросами.
- данных так много, что они не помещаются в *storage* на один сервер
- *working set* очень большой, данные и индексы не помещаются в память одного сервера.

Виды *scaling*'а:

- *Scaling up* (масштабирование по вертикали, вертикальное масштабирование) 
- *Scaling out* (масштабирование по горизонтали) (существует много разновидностей).
- *Scaling back* (масштабирование наоборот) – удалить или заархивировать данные, которые используются редко или не используются вовсе.

Применение некоторых техник *scaling*'а требует существенного усложнения архитектуры. Поэтому перед проектированием системы нужно оценить, с какой нагрузкой придется иметь дело. Если оценка завышена, то будет зря потрачено некоторое время на разработку, а если занижено, то возросшая нагрузка застанет вас врасплох. При этом нужно учитывать не среднюю, а ожидаемую пиковую нагрузку. Приложение должно ее выдерживать.

## Scaling up

*Scaling up* (масштабирование по вертикали, вертикальное масштабирование) – покупают более мощные серверы. 

Имеет смысл для того, чтобы выиграть время и переделать архитектуру системы. Работает в течение некоторого времени, но лишь до тех пор, пока масштаб приложения не превысит критическую отметку. В какой-то момент наращивание мощности оборудования становится неприемлемым из финансовых соображений. Существует некий диапазон аппаратных решений с оптимальным соотношением цены и производительности. За пределами этого диапазона находится в основном специализированное и, соответственно, более дорогое оборудование.

### MySQL

MySQL не слишком хорошо масштабируется по вертикали, поскольку его трудно заставить эффективно использовать несколько процессоров и дисков. Для текущих версий MySQL пределом является 8 ЦП и 14 дисков. В схеме с репликацией имеет смысл усилить подчиненный сервер, т.к. поток репликации на подчиненном сервере не может толком задействовать несколько процессоров и дисков.

Обычно приложения, работающие на одном сервере, сначала упираются в ограничения при чтении, особенно при обработке сложных запросов. Такие запросы внутри MySQL функционируют в однопоточном режиме и если не хватает памяти и данные не помещаются в кеше, то возникает интенсивное обращения к дискам.

## Scaling out

*Scaling out* (масштабирование по горизонтали) – распределяет работу между несколькими узлами.

Под узлом  (репликасет, node) понимается функциональная единица. Это может быть:

- в простейшем случае один сервер


- *master*-*master* в режиме *active*-*passive*

- *master* и много *slav*'ов

Варианты:

- Большое количество чтения:
  - Кеширование ([1](#кеширование)). Имеет смысл, если на 20% данных приходится 80% нагрузки. 
    
    Примеры кеширования:
    
    - кеширование статических страниц или статических блоков страниц в nginx ([1](#кеширование-ответов-fastcgi-в-nginx))
    - использование распределенных кеширующих систем: memcached ([1](Memcached.md))
    
  - Репликация ([1](Mysql.md#replication)). 
- Большое количества записи:
  
  - Шардирование ([1](Sharding.md)) – масштабирование записи и чтения 
  - Функциональное секционирование

### Функциональное секционирование

Функциональное секционирование, или разделение обязанностей означает, что под разные задачи выделяются разные узлы. Например, можно разделить данные на серверах для OLTP- и OLAP-запросов. В более общем смысле, на каждом узле хранятся данные, необходимые конкретному приложению. Например, отделяются данные новостного раздела, форума, технической поддержки, базы знаний и т. д. Однако рано или поздно какое-нибудь приложение или функциональная область разрастется слишком сильно, и тогда придется искать другую стратегию.

## Scaling back

*Scaling back* (масштабирование наоборот) – архивировать и удалять информацию, ставшую ненужной, чтобы убрать данные с сильно нагруженного OLTP-сервера. Можно спроектировать приложение так, чтобы оно архивировало данные, к которым редко обращаются. Архивированные данные можно хранить в отдельных таблицах и обращаться к ним через представления или даже полностью переместить на другой сервер. Например, в Badoo неактивные пользователи перемещаются на «кладбище».

Наличие связей между данными может усложнить архивирование и удаление. Хорошо спроектированная программа архивирования сохраняет логическую согласованность. В процессе масштабирования приходится на время идти на нарушение ограничений внешних ключей при перемещении связных данных.

Зачастую можно убрать значительно больше данных, если процедура архивирования дополняется стратегией извлечения информации из архива (разархивирование). Если вход невозможен из-за отсутствия пользователя, то программа посмотрит, нет ли такого пользователя в архиве (в badoo, на «кладбище»), и если есть, то извлечет его оттуда и продолжит выполнение процедуры входа.

Можно не перемещать пользователя из архива, а использовать его данные прямо оттуда, это позволяет отделить активные данные от неактивных (разделить таблицу `users` на `active_users` и `inactive_users`). Это повышает эффективность использования кэша (активные пользователи не вытесняются из кеша массой неактивных) и позволяет применять для активных и неактивных данных различные аппаратные и программные архитектуры (память и диск, HDD и SSD).

В InnoDB единицей кэширования является страница. Если на одной странице умещается 100 пользователей и только 10% всех пользователей активны, то с точки зрения InnoDB каждая страница будет «горячей», и тем не менее 90% данных на странице – пустая трата памяти.

Можно использовать встроенный механизм секционирования таблиц.

Наиболее универсальный механизм разделения данных на горячие – по времени, т.к. недавние данные наверняка будут гораздо активнее более старых. Новые значения поступают на «активный» узел, в котором очень много памяти и быстрые диски. Старые данные уходят на узлы с большими, но сравнительно медленными дисками. Это реализуется через динамическое секционирование, например, указанием в таблице пользователей: 

```mysql
CREATE TABLE users ( 
	user_id int unsigned not null, 
	shard_new int unsigned not null, 
	shard_archive int unsigned not null, 
	archive_timestamp timestamp, 
	PRIMARY KEY (user_id) 
);
```

# Кеширование

<u>Требования к кэшируемым данным:</u>

- большое количество запросов на чтение


- малое количество вариантов кешируемых данных (например, результаты поиска нет смысла кешировать)


- редкие изменения (инвалидация)


Согласно закону Парето 20/80 – 80% запросов приходятся на 20% данных. И задача стоит выявить эти 20% данных и разместить их в кеше, в быстрой памяти.

Кеширование можно также рассматривать, как один из способов снизить *time cost* в обмен на *space cost* ([1](Algorithm.md#space-time-trade-off)). 

Результат работы функции может быть закеширован только в том случае, если функция обладает *ссылочной прозрачностью* (*referentially transparent*); то есть, если вызов функции имеет тот же эффект, что и просто возврат результата этой функции (я думаю, это связано с нульпотентностью).

<u>Расчет накладных расходов:</u>

Кэширование не всегда полезно, т.к. с кэшированием связаны определенные накладные расходы: 

- необходимо проверить наличие данных в кэше и обслужить запрос оттуда в случае попадания. 

- необходимо поместить данные в кэш или сделать их недействительными.

- усложняется логика работы приложения


Кэширование полезно лишь в том случае, когда:

```
Стоимость обслуживания с кешем < Стоимость обслуживания без кеша
```

- Стоимость обслуживания без кэша – это стоимость генерации данных при каждом запросе. 

- Стоимость обслуживания с кэшем:

  *C<sub>с кэшем</sub> = С<sub>проверки </sub>+ p<sub>непопадания </sub>× С<sub>генерации</sub> + p<sub>попадания </sub>× С<sub>выборки из кэша</sub>*

  p<sub>попадания </sub> называется hit, p<sub>непопадания – miss. 

Как правило, эффективность работы системы кеширования оценивают по *hit ratio*. Считается, что если *hit>95%* - отлично, *hit<80* – плохо.

<u>Типы кешей по активности:</u>

Кэши можно подразделить на пассивные и активные:

-  Запрашивая что-то из пассивного кэша, вы либо получаете результат, либо сообщение «такого у меня нет» (пример *memcached*). 
- Активный кэш передает поступивший запрос какой-то другой части приложения, которая и генерирует затребованный результат. Затем кэш сохраняет его и возвращает запросившей программе (пример - *nginx* с модулем кэширования). Активные кэши являются прозрачными и скрывают логику проверки, генерации и сохранения. Активные кэши строятся поверх пассивных.

<u>Недостатки:</u>

Кеширование иногда маскирует проблемы в системе, которые в обычные периоды времени (*cache hit ratio* высокий) не заметны. Но при нарастании нагрузки чаще выполняется инвалидация кеша, большее количество потоков занято перегенерацией кеша и система падает из-за того, что значительно вырастает время обработки одного запроса, не хватает потоков для обработки всех запросов ([1](#расчеты метрик)).

<u>Паттерн реализации кеширования в PHP:</u>

Кеширование может вручную явно прописываться в каждую функцию.

```php
function getData()
{
    if (false === ($data = $memcache->get($key))) {
        $data = calculate();
        $memcache->set($key, $data);
    }

    return $data;
}
```

Но по сути процедура кеширования является сквозной функциональностью (cross cuting concern). Поэтому более удобны механизмы автоматического кеширования, когда исходная функция вызывает внутри стандартного шаблона кеширования. Для это могут быть использованы стандартные паттерны (*decorator*, *observer*) или библиотеки АОП ([1](Design.md#аспектно-ориентированное-программирование-аоп))

## Уровни кеширования

Существует много уровней кэширования. Кэширование производится на всем пути следования, включая браузер пользователя. 

Чем ближе кэш к клиенту, тем больше ресурсов в нем хранится и тем он эффективнее, но тем сложнее выполнять его инвалидацию. 

Уровни кеша:

- кеш в браузере и в сети
- кеш между веб-сервером и браузером
- кеш на время запроса в памяти воркера
- кеш в локальной разделяемой памяти
- распределенный in-memory кеш
- кеширование в БД в *in-memory storage*
- кеширование в БД в дисковых *storage*
- кеши на диске

Каждому типу кэша присущи свои характеристики, например размер и задержка.

### Кэширование в БД в дисковых storage

Возможны следующие виды:

- Встроенные кеши MySQL (пул буферов InnoDB, кэш ключей MyISAM, кэш уровня ОС, *query cache*)


- Управляемые пользователем кэширующие таблицы. Кэширующие таблицы существуют дольше, чем большинство кэшей на уровне приложения, поскольку они не исчезают при перезапуске сервера, персистентны.


### Кеширование в БД в in-memory storage

Реализуется через таблицы в *MEMORY storage*. Хотя данные будут очищены после перезагрузки сервера – схемы таблиц будут сохраняться. 

Преимущества:

- поддерживает SQL


- хранением данных в памяти


* создания индексов на основе хеш-таблицы

Недостатки:

- проигрывает более простым методам доступа CRUD, типа Memcached.

### Кеш на время запроса в памяти воркера

Данные кешируются в памяти одного воркера на протяжении обработки одного запроса (как правило, в статической переменной PHP). Принцип работы также называется мемоизация (*memoization*) — сохранение результатов выполнения функций для предотвращения повторных вычислений. 

Реализации функции строится по следующему алгоритму:

- если функция ранее не вызывалась, то она вызывается и результат её выполнения сохраняется в переменную;


- если функция вызывалась, используется сохранённый результат.

```php
function get_name_from_id($user_id) {
    static $name;
    if (!isset($name[$user_id])) {
        $name[$user_id] = $db->select('...'); // Выбрать из базы данных 
    }
    return $name[$user_id];
} 
```

### Кэш в локальной разделяемой памяти

Недостатки:

- локальны
- требуют согласования между несколькими узлами

Библиотеки для реализации – `shmop`, `shm`. 

Примеры применения: 

- таблица шардирования

### Распределенный in-memory кэш

Примеры: 

- memcached. 
- redis

Преимущества:

- Не нужно проблемы согласования, возникающие, когда одна и та же информация локально кэшируется в разных местах.

Недостатки:

- Время задержки выше, чем у локальных
- выше конкуренция, чем у локальных

### Кэши  на  диске

Недостаток:

- Медленные 

Применение:

- объекты, не помещающиеся в памяти
- статическое содержимое: 
  - предварительно сгенерированные изображения, tn-ки ([1](#создание-обработанных-картинок-tnок))
  - статические страницы ([1](#кеширование-статических-страниц)). 
  - сохранить массив данных в  `.js` файл, и сослаться на него в html. `.js` будет закешировано в браузере. Сброс кеша выполняется изменением файла и сменой версии файла в `.html`. 

Периодически запускаемый скрипт может реализовывать любую стратегию управления кешем: 

- TTL (удаление файлов, созданных более N минут назад)
- ограничения размера кэша (LRU, с учетом времени последнего доступа, MRU, LFU).

#### Кеширование статических страниц

Можно генерировать статические страницы и кешировать их на диске. Можно использовать любую стратегию, по аналогии с созданием обработанных картинок (tn'ок) ([1](#создание-обработанных-картинок-tnок))

Необходимо подобрать формат для имени статических страниц, который позволит при запросе серверу *Nginx* проверить наличие статической страницы в папке для запрашиваемого URI.

Если вся страница не является полностью статической, то можно хотя бы закешировать в статические файлы отдельные ее части. Для сборки страницы целиком из статических блоков необходимо применить технологию включения на стороне сервера (*server-side include – SSI*).

### Кеш в браузере и в сети

Это кеши, которые встроены в браузер и находятся между веб-сервером и браузером в сети (*proxy cache, gateway cache*). Наиболее эффективный тип кеша, т.к. находится близко к клиенту. Однако наиболее сложный для инвалидации, поэтому в него необходимо желательно помещать только статические данные (например, изображения).

Преимущества использования:

- Уменьшение времени получения контента в браузере. Важно для клиента.


- снижение сетевого трафика. Для клиента – в случае *browser cache*, для сервера – в случае любых *cache* в сети.


Управление кешированием выполняется с помощью заголовков ответа HTTP ([1](HTTP.md#для-управления-кешированием)). Исторически заголовки кэшировании относились лишь к браузеру клиента, но сегодня следует учитывать их влияние на промежуточные точки в соединении.

#### Freshness и validation

*Fresh* (свежий) контент – контент, у которого установлено время истечения (`Expires`) или другой заголовок (`Cache-Control`), контролирующий время жизни, и он еще не истек. *Fresh* контент берется непосредственно из кэша, без взаимодействия с сервером-источником этого контента.

*Valid* (валидный) контент – контент, который уже устарел, т.е. *non-fresh*, но прошедший процесс *validation* (валидации) на сервере, который подтвердил, что контент актуален и соответственно не требует повторной загрузки на клиент. 

Процесс *validation* для *non-fresh* закешированного контента заключается в дополнении запроса специальными заголовками-валидаторами (`If-Modified-Since`, `If-None-Match`). Если контент браузера актуален, то сервер может его не возвращать, а ответить заголовком `304 Not modified`. Такой запрос называют условным, т.к. процесс его обработки зависит от условия.

#### Browser cache

*Browser cache* (кэш браузера) располагается на компьютере клиента, управляется браузером. Браузер один раз за сессию (текущем сеансе) проверяется *content freshness*, при необходимости выполняет *validation* его или загружает. 

#### Proxy cache

*Proxy cache* (прокси-кэш) – кеш на прокси-сервере в сети, обслуживающем множество клиентов. Запрошенные одним клиентом контент будет сохранен в кеше и может отдаваться другим клиентам. 

#### Gateway Cache

Gateway Cache (кэш-шлюз, reverse proxy cache, реверсивные прокси-кэши). Используются для снижения нагрузки на сервер. Включают в себя балансировщик нагрузки. 

Примеры:

- *nginx*

- *Content Delivery (Distribution) Network* (*CDN*, сеть доставки (дистрибуции) содержимого) — географически распределённая сетевая инфраструктура, позволяющая оптимизировать доставку и дистрибуцию *content*'а пользователям. При правильной настройке, CDN передаёт *content* клиентам через самый быстрый и ближайший к нему сервер. 

  Бонус: если вдруг падают сервера, CDN отдает данные из кэша так, что пользователи этого могут и не заметить.

#### Алгоритм работы кеша

1. Проверяется *freshness content*'а. 

2. Если *content* является устаревшим, серверу-источнику будет предложено проверить его *validity*, для того чтобы не загружать *content* целиком заново. 

3. Если *content* – *non-fresh* и *non-valid* – он загружается. 

4. Если заголовки ответа сообщают кэшу не сохранять ответ, он не сохранит.

5. Если в ответе нет информации о *freshness content*'а (`Expires` или `Cache-Control`) и не присутствует *validator* (`Last-Modified` или `ETag`), контент считается некэшируемым.

6. Иначе контент кешируется. HTTPS кешируется также как и HTTP.

#### Стратегия кэширования

Динамический контент как правило не кешируется выставлением заголовка:

```http
Cache-Control: max-age=0, no-cache, no-store
```

Однако иногда динамический контент не меняется какое-то время. В этом случае контент можно закешировать в браузере, если пользователь обращается к странице несколько раз, либо на промежуточных прокси-серверах.

Приемы:

- Если ресурс необходимо перекешировать, то его нужно переименовать, добавив к имени  увеличивающийся номер версии, временной ярлык, хэш.


- Один и тот же контент должен быть доступен по одному URL-адресу


- Динамический контент имеет смысл кешировать, если он статичен некоторое время и зависит только от URL-адреса. Отправку заголовков кеширования и валидацию по запросу (`If-None-Match`) должен обеспечивать скрипт на сервере. 


- Контент, который зависит от куков, информации об аутентификации или от какого-то другого внешнего фактора, нельзя кешировать. 


- Можно сделать динамический контент статическим, т.е. выгрузить его содержимое в файл при очередном изменении и переложить кеширование на веб-сервер.


- Запросы `POST` не кешируются большинством кэшей


- Если требуется на закешированную страницу поставить счетчик, то возможные варианты:
  - Скриптом дергать счетчик и отправлять данные для подсчета (URL).
  - Разместить на кешированной странице **некешируемый** *zeropyxel*, URL страницы можно получить из параметров запроса к *zeropyxel* или из заголовка `Referer`.

- Если хочется кешировать страницы, индивидуальные для каждого пользователя, можно с помощью заголовка `Cache-Control` указать, что требуется проводить *validation* *content*' а при каждом запросе с помощью заголовка (обязательно нужно использовать также `ETag`)

  ```http
  Cache-Control: public, no-cache
  ```

  В запросе на валидацию вместе с заголовком `If-None-Match` будут переданы куки с аутентификацией пользователя. В скрипте можно решить по данным в сессии пользователя: вернуть контент целиком или `304 Not Modified`.

- Если на странице есть элементы, отображение которых отличается для разных пользователей, можно их загружать скриптом с помощью технологии AJAX.


## Типы кешей по уровню обработки

Чем глубже обработка данных перед кэшированием, тем больше времени удается сэкономить при попадании в кэш. Однако чем глубже обработка, тем эти возможности более гибко использовать эти данные.

Уровни (по убыванию глубины обработки):

- готовый HTML – самая глубокая обработка, но самый негибкий для изменений.

  Примеры применения:

  - для страницы гостевого пользователя, которая для всех гостей одинакова

  - в случае maintenance и failure

- блоки в HTML.
- промежуточные данные для формирования HTML

## Cache invalidation

*Cache invalidation* (инвалидация кеша) – это компромисс между полнотой, избыточностью и сложностью этой процедуры. 

Полнота инвалидации — насколько часто в кеше будут содержаться грязные данные. 

Избыточность – как часто кеш будет инвалидироваться без необходимости.

### Инвалидация по времени

Выполняется установкой времени жизни кэша (TTL). Вместе с кэшированным объектом хранится момент истечения срока хранения.

Удаление может выполнять:

- сама система кеширования
- ручной фоновый процесс
- в момент обращения запроса. 

Гарантирует, что сразу после изменения данных кеш грязен. Время, которое кеш остаётся грязным, мы можем легко ограничить, уменьшив время жизни (что в свою очередь сократит процент попаданий). Т.е. при ↓ TTL – полнота инвалидации улучшается, а избыточность ухудшается. Подходит для редко изменяющихся данных или для которых требования к актуальности не критичны.

### Инвалидация по событию

Если кэширование устаревших данных неприемлемо, то необходимо сразу *invalidate* данные в процессе, которые их изменяет. 

Возможны два варианта:

- инвалидация при записи
- инвалидация при чтении

#### Инвалидация при записи

<u>Варианты:</u> 

- помечать во всех инвалидируемых ключах, что данные недействительны, грязные, что их нужно перегенерировать в момент чтения


- сразу обновить данные во всех ключах, которые стали *invalid*. 


Желательно обновление кеша производить в фоновом режиме, не связанном с запросами пользователей. Недостаток фонового обновления: 

- усложнение кода
- на каждый кешируемый объект требуется написать инвалидирующий код. 

Есть попытки встроить инвалидирующий код прямо в библиотеку работы с запросами, т.е. отслеживать какие запросы кешировались и при изменении этих данных инвалидировать этот кеш, например, кешируется запрос:

```mysql
SELECT ...
...
where category_id=2 and published=true
```

на все изменяющие запросы, попадающие под это условие делаем *cache invalidation*.

#### Инвалидация при чтении

Инвалидация при записи очень накладна.  

Применяется версионирование объектов:

- вместе с объектом сохраняется его *version*, которая изменяется вместе с изменением объекта.

   ```
  'key': [
      'data': <данные>
      'version': <версия>
  ]
   ```

- либо *version* выносится в отдельный объект – *tag*. *Tag*  – это некоторое имя и связанная с ним *version*:

  ```
  '<tag_name>': <version>
  ```

  Такой кеш называется тегированным. 

Группа объектов – объекты, связанные и зависящие от *version* некоторого общего объекта (либо имеющие один общий *tag*).

Такую технику можно использовать:

- В кеше (memcached)
- Для кеширующих таблиц в БД. *Version*'s можно хранить в БД или в кеше.

<u>Структура *version*</u>

В качестве *version* можно использовать монотонно возрастающие числа, но это может привести к некорректному поведению при условии возможной потери ключей.

В качестве *version* удобнее использовать *timestamp* (с достаточной точностью, например, до миллисекунд). Тогда увеличение версии тэга будет всегда давать новую, бóльшую версию, даже в случае потери предыдущей версии. Версия тэга формируется на бекендах, их системные часы должны быть синхронизованы (без этого не будет работать и другая функциональность, например, корректное вычисление срока годности кэшей с коротким временем жизни),

Использование текущего времени в качестве версии тэга даёт еще одно преимущество в ситуации, когда БД проекта устроена по схеме мастер-слейв репликации. При изменении исходного объекта в БД мы изменяем версию тэга, связанного с ним (записываем туда текущее время, то есть время изменения). В другом процессе мы обнаруживаем, что кэш устарел, то есть его надо перестроить, перестроение – это читающий запрос (SELECT), который необходимо отправить на слейв-сервер БД, но в силу задержек репликации слейв-сервер еще мог не получить актуальную версию объекта в БД, в результате мы кэш сбросили, но при его перестроении снова закэшировали старый вариант объекта, что неприемлемо. Можно использовать версию тэга при решении вопроса, на какой сервер БД отправить запрос: если разница между текущим временем и версией какого-либо тэга кэша меньше некоторого интервала, определяемого максимальной задержкой репликации, мы отправляем запрос на мастер-сервер БД вместо слейва.

<u>Преимущество:</u> 

- при изменении *version* одного объекта (*tag*'а) происходит *invalidation* всей группы связанных объектов. 
- операции пересчета группы связанных объектов «размазываются» по времени.

<u>Примеры:</u>

Лента постов связана с группой постов, которые в ней отображаются. При изменении одного поста должны измениться все выборки, где этот пост встречается.  

Например, в ленте содержатся два поста `post1` и `post2`. Выделим для них в кеше теги `tag1` и `tag2`:

```
"tag1': <timestamp>
'tag2': <timestamp>
```

При кешировании ленты, запишем в кеш кроме данных самой ленты, еще текущие (на момент создания кэша) версии тэгов `tag1` и `tag2` (вместе со сроками годности для решения «проблемы стаи собак»)

```
[
	срок годности: 2008-11-07 21:00 
	data: [ … ] 
	tags: [ 
		tag1: 25 
		tag2: 63 
	] 
]
```

При получении кэша мы считаем его валидным, если текущие версии тэгов `tag1` и `tag2` равны версиям, записанным в кэше. Таким образом, если мы изменяем (увеличиваем) версию тэга `tag1`, все кэши, связанные с этим тэгом, которые были построены ранее, перестанут быть валидными (т.к. в них записана меньшая версия тэга `tag1`).  

<u>Недостатки:</u>

Использование такой схемы тэгирования увеличивает количество запросов к *memcached*, т.к. нам необходимо для каждого кэша получать *version*'s его *tag*'s. Накладные расходы можно сократить за счет использование *multi-get* запросов *memcached*.



#### Кэширование иерархий объектов

Зачастую удобней кешировать не полную выборку из всех таблиц, а данные из связанных таблиц разместить в отдельных кешах и ссылаться на них по первичному ключу. 

Пример: при кешировании результатов поиска у нас можно кешировать список первичных ключей постов, а сами посты хранить в отдельном кеше. 

Преимущество:

·   позволяет не дублировать описание постов в нескольких кешах. 

·   позволяет легко выполнять инвалидацию кешей с отдельными постами, изменение поста не требует пересмотра всех кешей, где он хранится. 

Недостатки: 

·   требуется несколько запросов в кеш на одну выборку, однако можно реализовать в два запроса: 

o  выбрать список ID постов

o  сделать multi_get в memcached за информацией о нескольких постах по их ID

·   возможны проблемы нарушения согласованности данных в кеше, т.к. список постов и отдельные посты в кеше могут правиться независимо. Например, может измениться заголовок поста таким образом, что перестанет содержать ключевые слова, отвечающие условиям поиска, однако результат поиска еще не удален из кэша. Если такая ситуация неприемлема, то можно воспользоваться кэшированием с версиями и хранить версии товаров вместе с результатами поиска. 

# High Availability

**Доступность** - доля времени, в течение которого приложение может отвечать на запросы. Измеряется в «девятках»; так, «пять девяток» 99.999% времени, то есть время простоя составляет примерно пять минут в год.

### Высокая доступность

Высокая доступность в системе гарантируется избыточностью и в случае выхода сервера из строя, подключением резервного. Каждое следующее увеличение степени доступности, как правило, обходится дороже предыдущего, т.е. отношение доступности к потраченным усилиям и стоимости нелинейно. 

Самый важный принцип в деле обеспечения высокой доступности – выявить и устранить единые точки отказа в системе за счет избыточных ресурсов в системе. Избыточность системы может принимать две формы: 

·   запасная пропускная способность

·   дублирование компонентов. Пример – поднять реплику, и при падении master поднять уровень slave до master.

При этом не нужно загружать компоненты «под завязку», поскольку в этом случае у вас остается запас для поддержания требуемой производительности при возрастании нагрузки или отказе некоторых компонентов.

Failover – переключение на резервный сервер при отказе основного. Failback – «возврат на основной сервер». Распределение нагрузки вышедшего из строя сервера по другим приводит к работе системы в режиме с ухудшенными характеристиками (degrade mode).

# Причины проблем

- Клиенты при подключении видят ошибку:

  - Скорее всего веб-сервер уперся в ограничение памяти или в ограничение количества *worker*'ов. Например, Apache создал большое количество процессов в режиме *keepalive* (постоянные соединения) и пока эти соединения не закроются, под новые *worker*'ы не хватает памяти. 

    

# Типы трафика

Для каждого типа трафика требуется свое аппаратное решение и программное решение, которое учитывает особенности этого трафика. 

При использовании HTTPS требуется более мощный процессор для работы с шифрованными данными.

Основные типы трафика:

- динамический HTML (dynamic)


- запросы к API – короткий запрос и короткий ответ, важны малые задержки на ответ (*latency*)


- cтатика (*static*) – большой объем ответа, задержки не очень чувствительны для пользователя, важна высокая скорость передачи данных (*сhannel capacity*).


- upload от пользователя – большой объем запроса, также высокая скорость передачи данных (сhannel capacity).


 

# Стандартная архитектура

Архитектура стандартного веб-проекта:

- перед бекендами размещается несколько балансировщиков в виде *nginx* на отдельном узле. 


- балансировка нагрузки на программные балансировщики *nginx* выполняется через DNS-балансировку


- nginx проксирует запросы к `*.php` на *Apache*. В итоге *Nginx* сам поддерживает большое количество `keep-alive` соединений небольшим количеством воркеров за счет эффективной архитектуры. До *Apache* долетает лишь малое количество очень коротких по времени проксированных запросов от nginx. Ответ *Apache* вычитывается в буфер *nginx* и отдается с требуемой клиентом скоростью.


- отдача статики непосредственно *nginx*.


- статика (картинки, видео) и динамика (php-скрипты) разносятся по разным серверам. Запросы к API-приложения, которые обрабатываются серверами динамики, небольшие по размеру и должны выполняться очень быстро. Запросы к статике, наоборот, тяжелые и для них не требуется значительная оперативность. Поэтому для них требуется разная конфигурация серверов по процессору и памяти. Если статика и динамика расположены на одном сервере, тяжелые запросы к статике начнут тормозить легкие оперативные запросы к API.


<u>Стоит ли включать в архитектуру Apache?</u> 

Есть мнения за и против. 

Нюансы:

- Apache жрет много ресурсов


- единственное преимущество перед PHP-FPM – файлы `.htaccess`


- по подсчетам Apache дополнительно съедает 200-500Мб ([1](#расчет-метрик)) и процессорное время. Но если честно, то и PHP-FPM жрет память и процессорное время.


# Безопасность

## DoS-атака

DoS (*Denial of Service*, отказ в обслуживании) 

Если обработка какой-либо страницы очень тяжелая (например, поиск), то злоумышленник может организовать DDOS атаку на этот адрес и привести к перегрузке базы данных. 

Также DDOS атака может быть организована случайно ботом, который массово сканирует тяжелые страницы.

Допустимые варианты решения проблемы: 

- отрубить атакуемый функционал (метод API)


- заблокировать атакующие IP


- настроить лимиты на URI. Добавить к функционалу капчу.


- установить лимиты по количеству коннектов. Минус – у других клиентов возникнут проблемы c загрузкой статики в несколько соединений.


- настроить netfilter


<u>Пример:</u>

У нас бот яндекса сканирует страницы в ленте комментариев с большим смещением. Это приводит к большому количеству запросов вида:

```mysql
SELECT * 
FROM comment c 
WHERE ...
ORDER BY ... 
LIMIT 50 OFFSET 25931900
```

Способ диагностики проблемы:

- посмотреть в `SHOW PROCESSLIST` на выполняемые запросы и время их выполнения


- посмотреть в лог *nginx* (*apache*), кто обращается по адресам с тяжелыми страницами


Способ решения проблемы:

- отрубить возможность обращаться к страницам с такими тяжелыми запросами для данного IP или для всех


- перезагрузить *nginx* (*apache*), чтобы сбросить соединения к базе данных, либо вручную сделать `KILL` тяжелым запросам.


# Алгоритм масштабирования приложения

Масштабирование любого Web приложения — это постепенный процесс, который включает:

1. Анализ нагрузки через мониторинг.

2. Определение наиболее подверженных нагрузке участков.

3. Вынесение таких участков на отдельные узлы и их оптимизация.

Этапы развития архитектуры по мере нарастания нагрузки:

1. На одном сервере *nginx*, *PHP-FPM* (*Apache*) и БД

2. Вынесение БД на отдельный сервер

3. Вынесение *nginx* на отдельный узел, проксирование запросов к скриптам на *PHP-FPM* (*Apache*) и отдача статики непосредственно nginx. Сервер PHP обычно называют бекендом.

4. Организация нескольких бэкэндов за *nginx*, т.к. PHP начинает тормозить всю систему. *Nginx* умеет балансировать нагрузку между ними. Для этого необходимо выделить список бекендов в `upstream` и использовать его в конфигурации. Можно использовать веса бекендов, если какие-то из них мощнее, чем другие.

5. Кэширование. Например, для хранения сессий. Memcache может быть представлен в виде кластера серверов с *consistent hashing*. 

Этапы развития БД при масштабировании: 

- репликация для масштабирования чтения 


- функциональное секционирование. Например, для системы блогов разбить данные на три части: пользователи, сообщения и комментарии. Их можно поместить на разные *nod*'ы (вначале это может быть один узел, а потом *master-slave*), а соединение таблиц выполнять на уровне приложения. 


- шардирование. Например, секционирование сообщений и комментариев (т.к. их больше и они длиннее) по идентификатору пользователя, узел можно организовать в топологии мастер-мастер для надежности. 


# Типы ресурсов

- Процессор


- Память (RAM)


- Disk IO


- Сеть


# Балансирование нагрузки

Балансировка нагрузки (*load balancing*) — механизм распределения запросов между несколькими серверами с целью:

- оптимизации использования ресурсов
- сокращения времени обслуживания запросов
- горизонтального масштабирования
- обеспечения отказоустойчивости (резервирования).

## Использование балансировщика

Балансировщик нагрузки (*load balancer*) — машина или программа, основная функция которой — определить на какой сервер послать запрос. Балансировщики могут быть сконфигурированы в отличии от DNS-балансирования. 

Примеры балансировщиков: 

- Nginx
- HAProxy
- Cisco CSS

Преимущества:

- Умеют периодически отслеживать доступность бэкендов и удалять из пула недоступные серверы. 


- Умеют перебирать по порядку бекенды, пока не найдет доступный бекенд ([1](Webserver.md#модуль-upstream))


Недостатки программных балансировщиков:

- представляют собой единую точку отказа и в случае падения балансировщика – падает вся система. Должны дублироваться


- при наращивании нагрузки и горизонтальном масштабировании становятся узким местом в системе. Трафик упрется в производительность и полосу пропускания узла, на котором размещен *load balanсer*. 


Способ решения этих проблем – применение DNS-балансировки.

## DNS-балансировка

<u>Принцип работы:</u> 

- DNS сервер (возможно даже установленный у нас) отдает несколько IP по одному доменному имени. 
- Клиент выбирает случайным образом один из IP адресов. 
- По «закону больших чисел» нагрузка равномерно размазывается по нескольким узлам.

В случае если выбранный браузером IP адрес не отвечает по 80 порту, то после истечения таймаута, браузер прозрачно для пользователя выбирает другой IP и делает запрос на него. 

<u>Понятие TTL.</u> 

Для DNS-записи в авторитетном DNS-сервере (*authoritative*) устанавливается параметр TTL (Time to live). Когда неавторитетный DNS-сервер получает в результате опроса у авторитетного DNS-сервера какую-то DNS-запись, он кеширует ее на время, указанное в TTL. При разрешении имени для той же DNS-записи с помощью кеширующего неавторитетного DNS-сервера до истечения срока действия TTL, кеширующий DNS-сервер будет отвечать ранее закэшированной DNS-записью, а не снова получать ее от авторитетного DNS-сервера.

Время задаётся в секундах, типичное значение составляет 86 400 секунд, то есть 24 часа. Это означает, что при изменении записи DNS, вплоть до 24 часов после изменения, DNS-серверы по всему миру могут выдавать старые данные из кеша, пока он не будет обновлён. Более короткие TTL могут сильно нагрузить авторитетный DNS-сервер и имеют смысл на случай изменения адреса критически важных сервисов.

Администратор кэширующего DNS-сервера может установить жесткий TTL, который не будет зависеть от TTL авторитетного DNS. Поэтому установка TTL на авторитетном DNS-сервере не может гарантировать, что все кеширующие DNS-серверы будут иметь новые DNS-записи после истечения срока действия TTL

<u>Ограничения.</u> 

Ответ от DNS сервера приходит по протоколу UDP в пакете размером 512 байт. В зависимости от количества служебных данных максимальное количество IP адресов при DNS-балансировке находится в диапазоне 4-25 штук. Как правило балансируют 4-6 адресов.

<u>Преимущества:</u>

- низкая стоимость балансировки, т.к. не требуется никакого программного/аппаратного обеспечения


- отсутствует единая точка отказа.


# Проблемы множества бекендов

Когда один бекенд с PHP не справляется с нагрузкой, добавляют еще несколько бекендов и распределяют нагрузку между ними каким-либо методом балансирования нагрузки. Помимо снижения нагрузки на один бекенд, это повышает отказоусточивость системы – при выходе из строя любого бекенда, остальные бекенды могут взять на себя его нагрузку.

При переходе к распределенной обработке запросов на множестве бекендов архитектура приложения должна быть перестроена. Результат обработки запроса не должен зависеть от того, на каком сервере он обработан (в пределе *stateless*-код, но так не бывает, чтобы код вообще без состояния).

## Проблема обработки файлов

При наличии нескольких бекендов возникает проблема синхронизации файлов при одновременной их обработке с нескольких бекендов. 

Варианты решения:

- с центральным сервером. Все запросы загрузки и обработки файлов направляются балансировщиком на один бекенд (`adm`). С этого же сервера файл после изменения отправляется на сервера статики, откуда раздается клиентам. Если он нужен на других серверах динамики, то его можно синхронизировать через `rsync`.


- отказаться от локального хранения файлов и хранить файлы в облаке. Наиболее популярны распределенные файловые хранилища с протоколом S3 (например, Amazon S3, Ceph)


## Проблема обработки сессий

Если на одном бекенде в локальной памяти поднята сессия, а следующий запрос балансировщик отправил на другую машину, то новая машина не будет видеть данную сессию. 

Варианты решения:

- постоянство сессий (*session persistence*) или липкость (*stickiness*).

  Nginx как балансировщик поддерживает несколько механизмов, позволяющих управлять балансировкой, и отправлять следующий запрос на ту же ноду, что и предыдущий ([1](Webserver.md#методы-балансировки)):
  - `ip_hash`
  - `hash`
  - `sticky session` (в коммерческой версии).

  Недостаток: балансировщик, который и так является узким местом системы, занят еще и обработкой состояния о том, какой запрос каким сервером обрабатывается.

- Хранить сессии в распределенной кеширующей системе (база данных, memcached). Не имеет значения, на какой из бекендов приходит запрос.

  Преимущество: 

  - не нагружает балансировщик

  

# Взаимодействие с внешним сервисом

Бекенды всегда взаимодействуют с тяжелыми внешними сервисами: 

- базы данных (MySQL)
- поисковые движки (Sphinx). 

В SOA-архитектуре вообще выделены отдельные внешние сервисы под каждую задачу. И в любой момент времени один из сервисов может начать тупить.

Еще более опасно, если обращение идет к стороннему внешнему сервису в сети с непредсказуемым временем исполнения. Например, так:

```php
$data = file_get_content("https://path/to/resource");
```

Если не предусмотрена защита от тупки такого внешнего сервиса, в результате тупки возникает каскадный отказ системы:

- ↑ вырастает время выполнения одного запроса


- ↑ вырастает количество активных воркеров


- бекенд упирает в максимальное количество воркеров


- новые запросы, даже не связанные с тупящим ресурсом, перестают обрабатываться


Способы диагностики проблемы: 

- профилирование через какой-то инструмент, показывающий запросы к внешним ресурсам (newrelic, zabbix?)


- просмотр сетевых соединений через unix-утилиты (netstat, tcpdump)


В зависимости от типа сервиса, взаимодействие с сервисом может выполняться:

- асинхронно (гораздо проще)


- синхронно (сложнее)


## Асинхронная обработка

Более простой вариант, т.к. тяжелое взаимодействие с сервисом можно выполнить в фоновом процессе. Применение любого вида асинхронной обработки сразу снимает проблему, однако не для каждого сервиса это подходит. Например, асинхронно невозможно обращаться к базе данных.

Способы решения проблемы: 

- если данные <u>только читаются</u> и <u>редко изменяются</u>, то их можно закешировать


- если данные <u>отправляются в сеть</u>, то это нужно делать асинхронно через Message Query. 


### Особенности использования cron

Связано с [1](Memcached.md#фоновое-перестроение-по-cron)

Обработку тяжелых запросов можно выполнять асинхронно с запуском по времени через `cron`.

Необходимо следовать советам:

- в `cron` помещать вызов PHP через CLI, и ни в коем случае не делать обращение к скрипту через веб-сервер. Т.к. это забирает ресурсы веб-сервера и уменьшает количество доступных воркеров.


- внимательно следить за временем выполнения скриптов с отключенным лимитом времени `set_time_limit(0)`, т.к. запрос может подвиснуть и жрать ресурсы системы


- нужно ставить блокировки на повторный запуск процедуры в `cron` до завершения предыдущего запуска. Варианты решения:
  - утилита `setlock` запускает другую программу и одновременно создает `lock`-файл, который служит мьютексом и защищает от повторного запуска
  - критическая секция в memcached

## Синхронная обработка

Синхронная обработка используется, если критично обращаться к ресурсу <u>в контексте запроса</u>.

Способы решения:

- самый простой способ, ставить просто таймаут.

- замаскировать проблему с сервисом – не показывать тот блок на странице, за который этот сервис отвечает. Как только запросы к сервису начнут проходить, блок на странице снова отобразиться. Некоторые сервисы критичны для всего сайта (например, база данных, кеши), в случае их падения пользователю необходимо вывести понятную ошибку (типа, мы в курсе и чиним).
- *Сircuit brеaker*

#### Сircuit brеaker 

Гораздо эффективнее между удаленным сервисом и бекендом разместить *circuit breaker* – проксю, которая бы вырубала тупящий сервис при срабатывании какого-нибудь условия. 

*Circuit breaker* может быть реализован как:

- модуль в коде на PHP


- отдельно стоящий демон, который проксирует через себя запросы.


Для *Circuit breaker* задаются порог предупреждения (*warning threshold*) и порог отключения (*disable threshold*). Когда количество тормозящих воркеров достигает *disable threshold* (например, 10%) *circuit brеaker* перестает отправлять запросы к сервису и сразу отдаёт бекендам ошибку, как будто бы сервис лежит. После этого воркер бекенда может отправить запрос на резервный сервис (например, на другой *slave DB*).

Время от времени *Circuit breaker* автоматически пропускает запрос от какого-нибудь воркера, чтобы посмотреть, не ожил ли всё-таки сервис. Если он отвечает адекватно, то мы снова включаем его в работу.

## Приемы у нас

### Изменения в структуру таблицы с логами

**Задача.** Требуется внести изменения в структуру таблицы с логами, которая находится под нагрузкой. 

**Решение.**

·  Создать временную пустую таблицу для логов 

·  Переименовать таблицы так, чтобы временная таблица стала на место основной.

·  Сделать изменения на основной таблице.

·  Снова поменять их местами

·  Перенести из временной таблицы данные в основную.

### Запросы висят на табличной блокировке

**Задача.** В результате изменения структуры таблицы возникла табличная блокировка, запросы висят на ожидании доступа к таблице.

**Решение.** Сделать правки в коде, если это возможно, чтобы переключить запросы на другую таблицу или хотя бы отключить обращения к таблице. Плюс перезапустить Apache.

## Хранение статики

Для хранения фотографий можно использовать:

- облачный storage

- коробочное решение

- хранить у себя в кластере

- сеть хранения данных (Storage Area Network, SAN) — подключеник внешних устройств хранения данных (дисковые массивы, оптические приводы) к серверам таким образом, чтобы операционная система распознала подключённые ресурсы как локальные.

### Хранение статики в своем кластере

Берем кластер из нескольких машин для хранения изображений. 

Применяем схему с *virtual shard*'ами. Организуем два *mapping*'а: 

- картинка → `vshard`. Один из вариантов: хранить всех картинки одного пользователя в одном *vshard*, для этого нужно отображать `user_id` → `vshard`. Можно использовать любые способы задания [*sharding function*](). 
- `vshard` → реальный `shard` (физический узел). Если количество `vshard` и `shard` небольшое, то это отображение может задаваться статически вручную ([table function](#Sharding.md#динамическое-недетерминированное-table-function)).

Для серверов статики обычно характерен небольшой объем входящего трафика, при большом объеме исходящего трафика. Поэтому необходимо масштабировать чтение статики.

Часто имеет место следующий *case*: только что залитые фотки очень горячие, а через какой-то момент времени они перестают запрашиваться. Они составляют небольшой горячий *dataset* (рабочее множество). Этот *case* соответствует ситуации, когда оптимально применение [кеширования]().

*Photocache* – отдельная машина с быстрыми SSD дисками, которая кеширует картинки и при *miss* перенаправляет запросы в *storage*. Для этого на *photocache* установлен *nginx*, который делает `proxy_pass` на *storage* при *miss*.

Общая схема запроса картинки: пользователь → *photocache* → *storage*.  

В photocache все картинки разделены на:

- *hot cache* – папка, в которой хранятся активно запрашиваемые картинки
- *cold cache* – папка, в которую переносятся картинки из *hot cache*, после того как снижается количество *request*’ов к ним. 

В *photocache* *nginx*  ведет `access.log`. В фоне работает *demon*, который считает статистику по доступу к картинкам. На основе статистики *demon* перемещает картинку между cach'ами или удаляет. 

Жизненный цикл картинки в *photocache*:

- картинка попадает в *hot cache*
- при снижении количества запросов картинки перемещаются из *hot cache* в *cold cache*.
- при снижении количества запросов картинки удаляются из *cold cache*.

 

<u>Высокая доступность</u>

Если требуется высокая доступность, то необходимо устранить точки отказа. 

Для данной архитектуры:

- пустой резервный *photocache*, который включается в работу и прогревается при отказе одного из *photocach*'ей.
- дублирование всех *storag*'ей. При этом основной и резервный *storage* могут работать параллельно на чтение (аналогично *replication*). Дублирование картинок выполняется в фоновом процессе.

Для обработки фоновых задач (обработка картинка, копирование на резервный *storage*) следует использовать *Message broker*.

### Особенности картинок

<u>Выбор формата:</u>

- `jpg` – с потерей качества, для сложных изображений, для фотографий
- `webs` – лучше `jpg`, но поддерживается не всеми браузерами
- `png` – без потери качества, для иконок
- `gif` – кодирование по палитре, поддержка анимации

<u>Структура для хранения:</u>

Необходимо использовать древовидную структуру из папок. Это позволит избежать ограничение на количество файлов в каталоге и тормозов системы при работе с такими каталогами. 

Нужно разделить для удобства все картинки по типам: `avatars`, `posts`, `comments`. 

Внутри этих папок наиболее удобно делить файлы в соответствии с бизнес логикой. Например, хранить в виде: `./yyyy/mm/dd/123.jpg`. Так проще удалять старые картинки и делать инкрементальный бекапы.

<u>Порядок загрузки изображения</u>

- уменьшить размер до минимально допустимого, чтобы не хранить огромные фотографии

- удалить метаданные

- преобразовать в дополнительные форматы (`.webp`). 

  При запросе пользователя, необходимо выполнить проверку поддержку `.webp` браузером и в зависимости от этого отдать `.webp` или `.jpg`:

  ```nginx
  server {
  	...
  	location ~* ^/.+\.(jpg|jpeg)$ {
  	  if ($http_accept ~* "webp")    {
  	      rewrite (.+) $1.webp;
  	  }
  	}
  ...
  }
  ```

### Создание обработанных картинок (tn'ок)

На *storag*'ах и *photocash*'ах  простаивает CPU, т.к. основная нагрузка на сеть и на диски. Поэтому CPU может быть загружен созданием обработанных картинок (например, генерацией *thumbnail*'s):

- генерацией *tn*'ок
- перекодирование изображений в более компактные форматы (webp или progressive jpeg)
- resize, crop, накладывание watermark.

Способы создания *tn*'ок.

<u>1 подход</u>

С хранением (кешированием) *tn*'ок для всех картинок. Генерация выполняется в момент загрузки  или после загрузки в фоне. 

Имеет смысл:

- если все изображения примерно одинаково горячие
- не ограничены в объеме storag'ей
- CPU storag'ей не справляют с нагрузкой по генерации thumbnails на каждый request

Особенности:

- ↑ *data size*, ↓ *CPU load*. 
- Ограничены некоторым набором размеров (*tn*'ок) 
- Длительный процесс генерации, если требуются новые *tn*'ки

<u>2 подход</u>

Не генерировать thumbnails заранее и не хранить их в storage. Генерация выполняется налету, в момент *request*'а. 

Имеет смысл:

- если все изображения примерно одинаково горячие
- ограничены в объеме storag'ей
- CPU storag'ей справляют с нагрузкой по генерации thumbnails на каждый request

Особенности:

- ↓ *data size*, ↑ *CPU load*.  
- достаточно иметь несколько *tn*-ок (маленькую, среднюю и большую), а для остальных размеров делать *resize*. 
- можем получить любой точный размер, который запрошен в URL. Это особенно актуально для мобильных версий с невысокой скоростью интернет.
- добавление новых размеров не требует процедуры генерации *tn*-ок для всех картинок.

<u>3 подход</u>

Гибридный подход. С генерацией *tn*'ок в момент первого *request* и кешированием картинки в файловой системе. Объединение преимуществ двух предыдущих подходов. 

- меньше *data size*, чем в 1 случае, и меньше *CPU load*, чем во 2 случае 
- загрузка CPU только в момент генерации *tn*'ки в первый раз
- добавление новых размеров не требует процедуры генерации *tn*-ок для всех картинок.
- сброс кеша осуществляется простым удаление файла.

Имеет смысл:

- если требуется гибко управлять набором закешированных *thumbnails*
- если есть горячие и холодные *thumbnails*

Желательно перед добавлением новой *tn*'ки "прогреть" кеш – запустить генерацию *tn*'ок на небольшом количестве *request*'ов.

Особенно важно избежать "проблемы стаи собак" (dog-pile effect, так же cache stampede) – когда множество запросов будет сделан к одним и тем же "горячим" thumbnails, который в тот момент еще не будут закешированы. Дополнительно, эту проблему можно решить, используя распределенную блокировку через memcache, чтобы одну картинку генерировал только один request, а остальные ожидали его окончания.

<u>Разновидности 3 подхода</u>

Будем генерировать *thumbnails* в момент первого *request*, но кеширование выполнять по какому-то условию. Например:

* если по статистике *thumbnail* запрашивается часто (требуется сбор статистики)
* если *thumbnail* генерируется для свежей фотографии и скорее всего будет горячим.

 Преимущества:

- меньше *data size*, чем в 4 случае, при правильном условии

Способы генерации:

- Наиболее быстро это делает Nginx+LuaJIT.
- с помощью PHP

<u>Технологии для реализации</u>

Nginx:

- как веб-сервер для отдачи статики, если она уже закеширована на диске. Проверяется через `try_files`.
- как *reverse proxy*, который взаимодействует с бекендами, которые генерируют *thumbnails*

Модули nginx:

- `ngx_http_image_filter_module` – для ресайза изображений
- `ngx_http_proxy_module` или `ngx_http_fastcgi_module` – для кеширования

Для ресайза фотографий:

- *Nginx*+*Lua*
- PHP+GD
- *Imagemagick*     



# Интересные задачи и фишки

## Наши задачи

Тест серверов на время ответа с помощью curl

Использование блокировок в БД

Требовалось, чтобы один набор данных обрабатывался только одним воркером. Для этого испольовалась InnoDB и exclusive-lock чтение данных с помощью:

SELECT ... FOR UPDATE

В этом случае остальные воркеры ставились в ожидание на блокировке и не могли одновременно читать эти же данные.

 

## Фишки вконтакте

в вопросе кэширования.

При вставке новых данных, на которые предполагается высокая нагрузка в ближайшее время, например новый пост в ленте пользователя, имеет смысл эти данные **предварительно закешировать** и отправить пост в ленту только после кеширования. 

Можно после изменения данных не делать кеш сразу не валидным, а поставить задание и записать задание в кеш позже, некоторое время показывая **просроченные данные** из кеша. 

При сохранении подряд нескольких ключей в кеш нужно случайно **варьировать время хранения** для размазывания нагрузки на время TTL (жизни ключа). 

**Конфигурации приложения** можно хранить: в файлах ini, json, yml; в PHP коде; во внешних системах, которые могут по запросу прислать конфиг. Реализация последнего варианта: конфиг пишется в master ноду, на каждом сервер динамики поднята slave нода, куда реплицируется конфиг. 

Для распределения нагрузки по записи в один ключ memcache необходимо воспользоваться **шардированием ключа**, например для реализации счетчиков, подсчета посещаемости. Инкрементируется не один счетчик, а например 10 тысяч ключей, при этом получение значения счетчика предполагает multi get всех ключей и складывание в коде. 

Если не требуется значительная точность, то можно **инкрементировать счетчики с вероятностью**, например, 1/10, снижая нагрузку на кеш в такое же количество раз. При чтении значения счетчика необходимо умножить результат на коэффициент вероятности, получая значение близкое к реальному. 

Улучшения в результате изменения архитектуры приводят либо к появлению новых фич (фичатим), либо оптимизации использования железа (архитектурная команда). 

Соцсеть - это не банковский процессинг и иногда можно пожертвовать стопроцентной надежностью и потерять немного данных или уйти в downtime.За счет этого можно сэкономить денег и показывать пользователям меньше рекламы, достигнув разумных компромиссов надежность/стоимость.

 

## Badoo



#### Надежность хранения

##### RAID

Можно использовать аппаратное дублирование даннх через RAID массивы. 

Минусы подхода:

·  задержки при восстановлении поврежденных данных. Например, на восстановление диска из RAID5.

·  в RAID5 скорость чтения/записи равна скорости самого медленного диска

·  система дисков жестко связана. Если глючит один диск – глючит вся система.

##### Ручная репликация статики

Удобней использовать ручную репликацию статики на несколько серверов. 

Плюсы:

·  отдельные узлы для хранения независимы, при выходе из строя узла системы остается доступной

·  нагрузку гораздо проще горизонтально масштабировать

Информация о синхронизируемых фото размещается в очереди, например, через mysql. Т.к. теперь фото читается с основного диска, как пользователями, так и backup разделом. Ставим перед ними буферный диск небольшого размера SSD. Фото вначале попадает в буфер, а потом по event из очереди копируется на основной и backup раздел.

Фотографии лучше делать immutable, не переписывая измененные фото, а создавая новые файлы без хранения версий. 

Возможно использование распределенных файловых хранилищ – ceph + s3 api, minio.

Файлы должны раскладываться на диске по папкам двух уровней вложенности, чтобы преодолеть ограничение на количество файлов в папке. 

### Версионирование API 

Хороший API всегда версионирован. И если нарушается обратная совместимость, то меняется мажорная версия, например, 1.0.0., 2.0.0 и т.д.

Однако у этого подхода есть ряд недостатков:

·  Любое существенное изменение функционала требует инкрементации мажорной версии, причем в старшей мажорной версии должны быть реализованы изменения всех младших, хотя хотелось бы чтобы разные изменения не зависили друг от друга. Например поэтому нельзя выкатить клиент с функциональностью старшей версии без реализованной функциональности младшей версии.

·  Не всем клиентам нужен одинаковый функционал (например, не все разрешают работать с камерой из браузера), поэтому не для всех клиентов мобильных устройств нужно учитывать появление новой версии

·  изменения протокола под AB тесты не соответствуют версиям основных изменений, это отдельное несовместимое изменение протокола. Т.е. протокол зависит не от версии клиента или версии API, а от внутренних настроек.

Лучший вариант – идентифицировать отдельно каждого клиента и предлагать ему такие данные, которые соответствуют его типу. Первый способ – передавать при каждом запросе клиента на сервер тип клиента и его версию. Однако этот способ очень сложен в поддержке если много различных улучшений и тогда объект на сервер, отвечающий за версионность очень сильно разрастается. Также нужно согласовывать между клиентом и сервером, что клиент поддерживает на данный момент в какой версии, а что перестал поддерживать, нельзя выкинуть функционал из клиента без согласования с сервером.

Версионирование – это решение проблемы изоляции функционала (поддерживаемого от неподдерживаемого). Поэтому идея алгоритма следуюшая: клиент на старте отправляет на сервер набор тех фич, которые он хочет поддерживать, сервер делает проверку этих фич на доступность данному клиенту и отвечает ему отфильтрованным списком допустимых фич и клиент после этого включает нужные фичи. Плюсы подхода:

·  старые клиенты не знают про новые фичи и не запрашивают их

·  можно распараллелить разработку клиента и сервера, т.к. клиент запрашивает только те фичи, которые он поддерживает

·  можно собирать статистику по использованию клиентами фич и выкинуть неиспользуемые вообще

·  можно на сервере переключать функциональность для двух групп при AB тестировании

·  можно протестировать фичу на небольшой группе пользователей, не усложняя архитектуру системы (не добавляя индексы например), и при успешности фичи можно ее допилить для highload.

Минусы:

·  избыточное количество передаваемых данных и обработки на сервере, особенно для постоянно используемых всеми фич.

·  количество фич постоянно растет, каждая мелкая правка – это фича. Способы решения: удалять неиспользуемые фичи, удалить фичи которые используют уже все клиенты, force update принудительно обновить старые клиенты когда там мало пользователей.

### Ручная репликация данных между бекендами

В Badoo вручную реализована репликация данных между бекендами. Репликация может быть реализована двумя способами:

·  синхронный

·  асинхронный

Наиболее эффективный – асинхронный способ, работающий в режиме eventual consistency. Для того чтобы не возникало проблем с несогласованностью данных на бекендах при обработке нескольких запросов одного пользователя, применяются sticky-сессии. Это гарантирует, что все запросы одного пользователя идут на один бекенд.