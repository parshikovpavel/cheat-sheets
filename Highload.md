Основные правила надежности:

- использовать проверенные технологии
- сбор бэкапов
- мониторинг (профилирование), измерять все аспекты работы системы.  

Архитектура должна развиваться постепенно в соответствии с нагрузкой.

Правило 95 процентиля: стоит пренебречь 5% пользователей (использующих нестандартные браузеры, нестандартные файлы для загрузки, имеющих большие объемы данных), чтобы не усложнять архитектуру и отладить ее под большинство пользователей.

## Мониторинг (профилирование)

Типы мониторинга:

- Мониторинг серверов – мониторинг серверного железа и серверного ПО

- Мониторинг на уровне приложения – как работают подсистемы самого приложения, как они взаимодействуют с внешними сервисами

- мониторинг на уровне бизнес-логики – метрики по бизнес-объектам (сколько сделана заказов, сколько оставлено комментариев...)

Мониторинг включает

- сбор метрик

- сбор логов, ошибок

- трейсинг сообщений между сервисами в микросервисной архитектуре

Мониторинг решает проблемы:

- Расследование инцидентов

- Прогнозирование нагрузки

Основные внешние метрики проекта:

- RPS;

- время обработки запроса (включая перцентили);

- количество используемой памяти.

### Инструменты мониторинга

Виды инструментов мониторинга:

- *SaaS* (*software as a service*) – клиенту предоставляется внешний сервис для мониторинга, который полностью обслуживается другой стороной:
  - New Relic

- *Self-hosted* решение:

- *Zabbix*

- *Grafana*

### Внутренние метрики

Общие метрики:

·  время ответа сервиса

·  RPS к сервису

База данных:

·  количество записей в таблицах

Очереди сообщений:

·  длина очереди

·  время нахождения сообщения в очереди

Memcached:

·  соотношение hit/miss;

·  топ нагруженных ключей;

·  все внутренние метрики, которые отдаёт команда stats.

## Расчеты метрик

### Метрики памяти

Количество памяти, требуемое некоторому многопроцессному (или многопоточному) приложению (Apache, nginx, MySQL) определяется по формуле:

​                                

  

Общее количество памяти ограничено доступной на сервере оперативной памятью. 

Если известно количество доступной на сервере памяти, то можно определить максимально возможное количество воркеров из предыдущей формулы:

  

### Метрики для RPS

Самый простейший случай, который можно посчитать, – один воркер обрабатывает только один запрос (Apache, MySQL). Nginx может на одном воркере обрабатывать несколько запросов.

Пусть на одном воркере обрабатывается только один запрос. 

Если известно количество параллельных воркеров ( в соответствии с ограничениями памяти, производительностью процессора, I/O) и среднее время выполнения запроса, то можно узнать максимально возможную RPS:

  

Из формулы можно выразить количество воркеров, которые требуется для того чтобы выдержать нужную нагрузку RPS:

  

Неравномерность RPS в течении дня

Для нагруженного сайта критически важно не суточное число запросов, а мгновенное. 10 млн суточных хитов (динамики) – это 116 запросов в секунду при совершенно равномерном распределении за сутки. Однако как правило характерным является 16 нагруженных часов с двумя/тремя пиками нагрузки (развлекательные ресурсы, fishki.net) или 50-100-200 рывков по 300-700% хитов на фоне тех же 16 часов среднего трафика (электронные сми).

### Примеры расчетов

#### Расчет количества памяти для поддержания нагрузки с нужным RPS на веб-сервере

Исходные условия:

·  веб-сервер Apache, который обрабатывает один запрос в одном воркере

·  нагрузка 500 RPS

·  время обработки запроса 40-100 мсек (у нас 40мсек). Для справки: у сложного фреймворка время обработки запроса 80-100 мсек, для легкого запроса время обработки 40-50 мсек. 

·  накладные расходы Apache на один воркер составляют 10 Мб

·  примем количество памяти, требуемое для ядра Apache, равным 0.

Найдем объем памяти для работы Apache:

  

  

  

#### Расчет количества памяти, потребляемого MySQL

Память, требуемую для ядра, составляют следующие кеши:

·  Пул буферов InnoDB innodb_buffer_pool_size. Подробнее Параметр innodb_buffer_pool_size

·  Буфер ключей MyISAM key_buffer. Подробнее Конфигурирование

·  Кеш запросов (Qcache) query_cache_size. Подробнее Конфигурационные параметры

Память, требуемая для каждого воркера, складывается из:

·  read_buffer_size — кэш под полные сканы таблиц (sequential scan);

·  read_rnd_buffer_size — кэш используется для какой-то специфической  Multi-Range Read optimization при сортировке;

·  sort_buffer_size — кэш, в котором выполняется сортировка результатов;

·  thread_stack — размер стека треда;

·  join_buffer_size — кэш, используемый при соединениях (JOIN).

Максимальное количество воркеров определяется директивой max_connections. 

Поэтому максимально потребляемую память можно рассчитать по формуле, написанно выше:

  

  

# Способы ускорения

- Программный:

  - Настроить индексирование БД ([1](Mysql.md#index))

  - Выполнить профилирование системы (базы данных, кода) и оптимизировать узкие места

  - если выполняются группы запросов к базе данных, то можно их запаковать в транзакцию ([1](#ускорение-группы-операций-через-транзакции))

  - Использовать gzip сжатие

  - Организовать постоянные соединения между разными частями архитектуры. Постоянное открытие новых соединений нагружает процессор в системе и генерирует дополнительный служебный трафик.  Примеры организации постоянных соединений:

  - - между бэкэндом и базой ([1](PHP.md#постоянные-соединения))

  - - между nginx и бэкэндами ([1](Nginx.md#keepalive))

  - - между браузером и веб-сервером ([1](HTTP.md#постоянное-соединение-keep-alive))

- *Scaling* ([1](#scaling))

Начинают с программной оптимизации. Однако существует точка сокращения отдачи, когда каждая следующая программной оптимизация требует все больше усилий и дает все менее заметный результат, хотя сложность приложения при этом быстро возрастает. В этом случае переходят к *scaling*'у.

# Scaling

*Scaling* (масштабирование системы) – применяется, если 

- один узел не справляется с нагрузкой на чтение или на запись. Происходит снижение производительности – в виде замедления обработки запросов, большего потребления процессора, ввода/вывода, роста конкуренции между запросами.
- данных так много, что они не помещаются в *storage* на один сервер
- *working set* очень большой, данные и индексы не помещаются в память одного сервера.

Виды *scaling*'а:

- *Scaling up* (масштабирование по вертикали, вертикальное масштабирование) 
- *Scaling out* (масштабирование по горизонтали) (существует много разновидностей).
- *Scaling back* (масштабирование наоборот) – удалить или заархивировать данные, которые используются редко или не используются вовсе.

Применение некоторых техник *scaling*'а требует существенного усложнения архитектуры. Поэтому перед проектированием системы нужно оценить, с какой нагрузкой придется иметь дело. Если оценка завышена, то будет зря потрачено некоторое время на разработку, а если занижено, то возросшая нагрузка застанет вас врасплох. При этом нужно учитывать не среднюю, а ожидаемую пиковую нагрузку. Приложение должно ее выдерживать.

## Scale up

*Scaling up* (масштабирование по вертикали, вертикальное масштабирование) – покупают более мощные серверы. 

Имеет смысл для того, чтобы выиграть время и переделать архитектуру системы. Работает в течение некоторого времени, но лишь до тех пор, пока масштаб приложения не превысит критическую отметку. В какой-то момент наращивание мощности оборудования становится неприемлемым из финансовых соображений. Существует некий диапазон аппаратных решений с оптимальным соотношением цены и производительности. За пределами этого диапазона находится в основном специализированное и, соответственно, более дорогое оборудование.

### MySQL

MySQL не слишком хорошо масштабируется по вертикали, поскольку его трудно заставить эффективно использовать несколько процессоров и дисков. Для текущих версий MySQL пределом является 8 ЦП и 14 дисков. В схеме с репликацией имеет смысл усилить подчиненный сервер, т.к. поток репликации на подчиненном сервере не может толком задействовать несколько процессоров и дисков.

Обычно приложения, работающие на одном сервере, сначала упираются в ограничения при чтении, особенно при обработке сложных запросов. Такие запросы внутри MySQL функционируют в однопоточном режиме и если не хватает памяти и данные не помещаются в кеше, то возникает интенсивное обращения к дискам.

## Scaling out

*Scaling out* (масштабирование по горизонтали) – распределить работу между несколькими серверами (существует много разновидностей).

Способы решения:

- Большое количество чтения:
  - [Кеширование](#кеширование). Имеет смысл, если на 20% данных приходится 80% нагрузки. Способы кеширования:
    - [кеширование статических страниц или статических блоков страниц в nginx](#кеширование-ответов-fastcgi-в-nginx)
    - выделение нескольких кешей. Ключи между кешами распределяются через [consistent hashing](#consistent-hashing). 
  - [Репликация](#репликация). Имеет смысл, если профиль нагрузки плоский.
- Большое количества записи:
  - [Шардирование](#Sharding.md) – масштабирование записи и чтения 

:



Варианты:

·   Репликация. Чтение выполняется на подчиненных серверах. Эта техника хорошо работает в приложениях, где много запросов на чтение.

·   Секционировать рабочую нагрузку по нескольким «узлам». Это единственный способ масштабировать запись.

Под узлом (репликасет, node) понимается функциональная единица. Это может быть:

·   в простейшем случае один сервер

·   главный-главный в режиме активный-пассивный

·   главный и много подчиненных серверов

#### Функциональное секционирование

Функциональное секционирование, или разделение обязанностей означает, что под разные задачи выделяются разные узлы. Например, можно разделить данные на серверах для OLTP- и OLAP-запросов. В более общем смысле, на каждом узле хранятся данные, необходимые конкретному приложению. Например, отделяются данные новостного раздела, форума, технической поддержки, базы знаний и т. д. Однако рано или поздно какое-нибудь приложение или функциональная область разрастется слишком сильно, и тогда придется искать другую стратегию.

#### Шардирование

Смотреть Шардирование

#### Генерация глобально уникальных идентификаторов

Варианты:

·   Использовать  конфигурационные  параметры  auto_increment_increment и auto_increment_offset, которые говорят серверу MySQL, на какую величину увеличивать автоинкрементный столбец и с какого значения начинать нумерацию. Можно их настроить, например, на чередование. Недостаток – требует внимания при конфигурировании серверов.

·   Использовать ключ в сервере memcached, удобно использовать функция incr(). При перезагрузке сервера memcached придется заново инициализировать начальное значение.

При использовании глобального генератора, необходимо следить за тем, чтобы эта единственная точка конкурентного доступа не стала узким местом приложения. Для снижения нагрузки с узла генерации идентификаторов можно выделять значения шардам не одиночно, а сериями. 

·   Создать таблицу на глобальном узле с автоинкрементным столбцом. Можно использовать для ускорения обработки таблицу MyISAM с одной строкой и одним автоинкрементным столбцом:

CREATE TABLE single_row ( 
 col1 int NOT NULL AUTO_INCREMENT, 
 col2 int NOT NULL, 
 PRIMARY KEY(col1), 
 UNIQUE KEY(col2) 
 ) ENGINE=MyISAM;

mysql> REPLACE INTO single_row(col2) VALUES(1);

·   Использовать комбинацию значений, например, номер секции и увеличивающееся число. 

Только для MyISAM можно использовать автоинкрементные ключи по двум столбцам

mysql> CREATE TABLE inc_test( 
 -> a INT NOT NULL, 
 -> b INT NOT NULL AUTO_INCREMENT, 
 -> PRIMARY KEY(a, b) 
 -> ) ENGINE=MyISAM; 
 mysql> INSERT INTO inc_test(a) VALUES(1), (1), (2), (2); 
 | a | b | 
 +---+---+ 
 | 1 | 1 | 
 | 1 | 2 | 
 | 2 | 1 | 
 | 2 | 2 |

·   Сгенерировать GUID (глобально уникальные идентификаторы) с помощью функции UUID_SHORT(), которая возвращает короткие и последовательные значения, приемлемые в качестве первичных ключей (в отличии от функции UUID, возвращающей длинные непоследовательные значения).

### Scale back

*Scaling back* (масштабирование наоборот) – удалить или заархивировать данные, которые используются редко или не используются вовсе.

Масштабирование наоборот, идея: архивировать и удалять информацию, ставшую ненужной, чтобы убрать данные с сильно нагруженного OLTP-сервера. Можно спроектировать приложение так, чтобы оно архивировало данные, к которым редко обращаются. Архивированные данные можно хранить в отдельных таблицах и обращаться к ним через представления или даже полностью переместить на другой сервер. Например, в Badoo неактивные пользователи перемещаются на «кладбище».

Наличие связей между данными может усложнить архивирование и удаление. Хорошо спроектированная программа архивирования сохраняет логическую согласованность. В процессе масштабирования приходится на время идти на нарушение ограничений внешних ключей при перемещении связных данных.

Зачастую можно убрать значительно больше данных, если процедура архивирования дополняется стратегией извлечения информации из архива (разархивирование). Если вход невозможен из-за отсутствия пользователя, то программа посмотрит, нет ли такого пользователя в архиве (в badoo, на «кладбище»), и если есть, то извлечет его оттуда и продолжит выполнение процедуры входа.

Можно не перемещать пользователя из архива, а использовать его данные прямо оттуда, это позволяет отделить активные данные от неактивных (разделить таблицу users на active_users и inactive_users). Это повышает эффективность использования кэша (активные пользователи не вытесняются из кеша массой неактивных) и позволяет применять для активных и неактивных данных различные аппаратные и программные архитектуры (память и диск, HDD и SSD).

В InnoDB единицей кэширования является страница. Если на одной странице умещается 100 пользователей и только 10% всех пользователей активны, то с точки зрения InnoDB каждая страница будет «горячей», и тем не менее 90% данных на странице – пустая трата памяти.

Можно использовать встроенный механизм секционированния таблиц.

Наиболее универсальный механизм разделения данных на горячие – по времени, т.к. недавние данные наверняка будут гораздо активнее более старых. Новые значения поступают на «активный» узел, в котором очень много памяти и быстрые диски. Старые данные уходят на узлы с большими, но сравнительно медленными дисками. Это реализуется через динамическое секционирование, например, указанием в таблице пользователей: 

CREATE TABLE users ( 

user_id int unsigned not null, 

shard_new int unsigned not null, 

shard_archive int unsigned not null, 

archive_timestamp timestamp, 

PRIMARY KEY (user_id) 

);

### Балансирование нагрузки

Прием: хранить весь объем данных на всех серверах, но на одном подчиненном сервере выполнять запросы к одному множеству секций, а на другом – к другому. При этом один сервер полностью резервирует другой. По сути это секционирование операций чтения, например, для пользователей, чьи фамилии начинаются с букв A–M, направлять запросы на один подчиненный сервер, а запросы для всех остальных пользователей – на другой. Кэш каждого сервера будет использоваться эффективнее, так как более вероятно, что данные для повторяющихся запросов уже находятся в кэше. В лучшем случае стратегия дает кэш, размер которого равен сумме размеров кэшей обоих серверов. Если распределять запросы на чтение между серверами случайно, то данные в кэше каждого сервера дублируются, поэтому его полный эффективный размер не превышает размер самого большого кэша на всех подчиненных серверах.

Балансирование нагрузки при репликации: 

·   направлять все запросы на запись, а также те критические запросы на чтение, для которых неактуальные данные неприемлемы, активному или главному серверу. Все остальные запросы на чтение попадают на подчиненный или пассивный сервер. 

·   вести учет отставания реплики в приложении.

·   учитывать, кто запрашивает данные. Установить в сессии флажок, который показывает, что в сеансе было произведено изменение, и в течение некоторого времени после этого события направлять запросы на чтение, главному серверу. Можно сочетать с учетом отставания реплики, если реплика успевает за изменения текущего пользователя, то читать с реплики.

·   Записывать в таблицу номер версии или временную метку объекта и по ней определять свежесть данных. Номером версии может быть координата в журнале транзакций на мастере (получить через SHOW MASTER STATUS). При чтении ее можно сверить с координатой на реплике (через  SHOW SLAVE STATUS) 

При добавлении сервера в пул необходимо в течении некоторого времени его прогреть, например, повторять на новом сервере все запросы SELECT с какого-нибудь активного сервера и только потом известить о нем балансировщик нагрузки.

### Высокая доступность

Высокая доступность в системе гарантируется избыточностью и в случае выхода сервера из строя, подключением резервного. Каждое следующее увеличение степени доступности, как правило, обходится дороже предыдущего, т.е. отношение доступности к потраченным усилиям и стоимости нелинейно. 

Самый важный принцип в деле обеспечения высокой доступности – выявить и устранить единые точки отказа в системе за счет избыточных ресурсов в системе. Избыточность системы может принимать две формы: 

·   запасная пропускная способность

·   дублирование компонентов. Пример – поднять реплику, и при падении master поднять уровень slave до master.

При этом не нужно загружать компоненты «под завязку», поскольку в этом случае у вас остается запас для поддержания требуемой производительности при возрастании нагрузки или отказе некоторых компонентов.

Failover – переключение на резервный сервер при отказе основного. Failback – «возврат на основной сервер». Распределение нагрузки вышедшего из строя сервера по другим приводит к работе системы в режиме с ухудшенными характеристиками (degrade mode).

## Оптимизация на уровне приложения

·   При оптимизации нужно изучить запросы и бизнес-процессы, например, подсчет строк нужно доверить БД, а сложные обработки регулярными выражениями – приложению. Иногда некоторые функции надо перенести в приложение, например, «ручное соединение» в приложении, позволяет реализовать более детальное и эффективное кэширование, уменьшить количество блокировок (особенно в случае использования MyISAM), ускорить работу приложения за счет эмуляции хеш-соединений в прикладном коде. 

·   На подключение тратится время, поэтому лучше использовать одно и то же соединение на протяжении всего запроса (или использовать постоянные соединения, хотя выбор соединения из пула требует также времени на сброс состояния).

·   Убрать мусорные запросы, типа выбор требуемой базы данных перед каждым запросом. Если требуется менять базы, то можно писать полное именя базы перед таблицей. Убрать команду SET NAMES UTF8, которая в любом случае не нужна (она не изменяет кодировку в клиентской библиотеке, а воздействует только на сервер). Кодировку нужно настроить по умолчанию на сервере.

·   Использовать пул соединений. Однако  может образовываться слишком много соединений с MySQL. В общем случае пул не рекомендуется, за исключением ситуации, когда подключение к MySQL обходится слишком дорого  из-за мед- 
 ленной сети (хотя MySQL спроектирован на быстрое соединение), или когда соединение используется всего для одного двух быст рых запросов, или когда подключение производится настолько часто, что не хватает номеров локальных портов Важно правильно сконфигурировать MySQL, в частности устанавливайте достаточно большое значение параметра количество потоков в кеше  thread_cache.

·   Следует закрывать соединения, если они не нужны. Потоки из кеша MySQL могли бы пригодиться другим процессам.

### Оптимизация веб-сервера

Сценарии на PHP очень требовательны к ресурсам и процесс Apache может потреблять десятки мегабайт. По завершении обработки запроса НЕ вся память возвращается операционной системе, т.к. Apache повторно использует ее для последующих запросов. Следовательно, если следующим поступит запрос на статический ресурс, например CSS-файл или изображение, то этот простенький запрос будет обслуживаться очень «толстым» процессом. Поэтому для легких задач, вроде отдачи статики, перед apache лучше раместить nginx.

Варианты ускорения: 

·   Перед apache можно разместить кэширующий прокси-сервер (Squid или Varnish), чтобы вообще не допустить запросы до веб-сервера.

·   Отключить ненужные модули Apache в httpd.conf, удалить ненужные модули PHP из php.ini.

·   Включить вечное кеширование CSS и JS. Для обновления файлов использовать номер версии в имени файла, например ?123 или 123_style.css.-

·   Не допускать длительное время жизни процесса Apache, не позволять Apache «кормить клиента с ложечки». Например, балансировщик нагрузки может буферизовать ответы веб-сервера, поэтому Apache может завершить свою часть работы быстро, а уж балансировщик будет потихоньку отдавать клиенту содержимое из буфера. 

·   Включить gzip-сжатие. Для современных процессоров эти накладные расходы ничтожны,

### Кеширование

Требования к кэшируемым данным:

·   большое количество запросов на чтение

·   малое количество вариантов кешируемых данных (например, результаты поиска нет смысла кешировать)

·   редкие изменения (инвалидация)

Согласно закону Парето 20/80 – 80% запросов приходятся на 20% данных. И задача стоит выявить эти 20% данных и разместить их в кеше, в быстрой памяти.

Кеширование можно также рассматривать, как один из способов снизить time cost в обмен на space cost (в space-time trade-off), т.е. мемоизированные функции уменьшает время выполнения в обмен на использование дополнительной памяти. 

Результат работы функции может быть закеширован только в том случае, если функция обладает *ссылочной прозрачностью* (referentially transparent); то есть, если вызов функции имеет тот же эффект, что и просто возврат результата этой функции (я думаю, это связано с нульпотентностью).

Расчет накладных расходов:

Кэширование не всегда полезно, т.к. с кэшированием связаны определенные накладные расходы: 

·   необходимо проверить наличие данных в кэше и обслужить запрос оттуда в случае попадания. 

·   необходимо поместить данные в кэш или сделать их недействительными.

·   усложняется логика работы приложения

Кэширование полезно лишь в том случае, когда эти издержки не превышают стоимость генерации и обслуживания страницы без кэша. Стоимость обслуживания без кэша – это стоимость генерации данных при каждом запросе. Стоимость обслуживания с кэшем:

  

  называется hit,   – miss. 

Как правило, эффективность работы системы кеширования оценивают по hit ratio. Считается, что если hit>95% - отлично, hit<80 – плохо.

 

Типы кешей по активности:

Кэши можно подразделить на пассивные и активные. Запрашивая что-то из пассивного кэша, вы либо получаете результат, либо сообщение «такого у меня нет» (пример memcached). Активный кэш передает поступивший запрос какой-то другой части приложения, которая и генерирует затребованный результат. Затем кэш сохраняет его и возвращает запросившей программе (пример - кэширующий прокси-сервер Squid). Активные кэши являются прозрачными и скрывают логику проверки, генерации и сохранения. Активные кэши строятся поверх пассивных.

Недостатки:

Кеширование иногда маскирует проблемы в системе, которые в обычные периоды времени (cache hit ratio высокий) не заметны. Но при нарастании нагрузки чаще выполняется инвалидация кеша, большее количество потоков занято перегенерацией кеша и система падает из-за того, что значительно вырастает время обработки одного запроса, не хватает потоков для обработки всех запросов (подробнее про анализ нагрузки Анализ нагрузки).

Паттерн реализации кеширования в PHP:

Кеширование может вручную явно прописываться в каждую функцию.

**function** getData()
 {
   **if** (**false** === ($data = $memcache->get($key))) {
     $data = calculate();
     $memcache->set($key, $data);
   }

   **return** $data;
 }

Но по сути процедура кеширования является сквозной функциональностью (cross cuting concern). Поэтому более удобны механизмы автоматического кеширования, когда исходная функция вызывает внутри стандартного шаблона кеширования. Для это могут быть использованы стандартные паттерны (decorator, observer) или библиотеки АОП (об этом подробнее Аспектно-ориентированное программирование (АОП))

#### Уровни кеширования

Существует много уровней кэширования. Кэширование производится на всем пути следования, включая браузер пользователя. 

Чем ближе кэш к клиенту, тем больше ресурсов в нем хранится и тем он эффективнее, но тем сложнее выполнять его инвалидацию. Извлекать изображение из кэша броузера лучше, чем из памяти веб-сервера, а последнее лучше, чем читать его с диска сервера. 

Каждому типу кэша присущи свои характеристики, например размер и задержка.

##### Кэширование на уровне БД

Возможны следующие виды:

·   Встроенные кеши MySQL (пул буферов InnoDB, кэш ключей MyISAM, кэш уровня ОС, query cache)

·   Управляемые пользователем кэширующие и сводные таблицы. Кэширующие таблицы существуют дольше, чем большинство кэшей на уровне приложения, поскольку они не исчезают при перезапуске сервера, персистентны.

##### Кэширование на уровне приложения

Кэш уровня приложения обычно размещается в памяти на том же самом компьютере или в памяти другого компьютера, доступного по сети. Чем глубже обработка данных перед кэшированием, тем больше времени удается сэкономить при попадании в кэш, самая глубокая обработка – готовые HTML-фрагменты.

###### Типы кэшей по месту хранения:

Кеша на время запроса в памяти воркера

Данные кешируются в памяти одного воркера на протяжении обработки одного запроса (как правило, в статической переменной PHP). Принцип работы также называется мемоизация (memoization) — сохранение результатов выполнения функций для предотвращения повторных вычислений. 

Реализации функции строится по следующему алгоритму:

·   если функция ранее не вызывалась, то она вызывается и результат её выполнения сохраняется в переменную;

·   если функция вызывалась, используется сохранённый результат.

**function** get_name_from_id($user_id) {
   **static** $name;
   **if** (!**isset**($name[$user_id])) {
     $name[$user_id] = $db->select(**'...'**); *// Выбрать из базы данных 
\*   }
   **return** $name[$user_id];

} 

В некоторых языках есть модуль Memoize.

Кэши в локальной разделяемой памяти

Высокая скорость доступа, но локальны и требуют согласования. Реализация: библиотеки *shmop,* *shm*. Примеры: таблица шардирования

Распределенные кэши в памяти

Пример: memcached. Не нужно проблемы согласования, возникающие, когда одна и та же информация кэшируется в разных местах. Время задержки у таких кэшей гораздо выше, проблемы конкуренции.

Кэши на диске

Медленные, лучше кэшировать объекты, не помещающиеся в памяти, или статическое содержимое: предварительно сгенерированные изображения, tn-ки, статические страницы. 

Приемы:

·   как сделано у нас с TN: проверять на диске наличие файла с картинкой TN, а если картинка отсутствует отправлять запрос на бекенд для генерации картинки в PHP. Бекенд сгенерирует изображение, поместит его на диск и вернет в браузер. Все последующие запросы будут просто возвращать картинку из файла. Сброс кеша осуществляется простым удаление файла.

·   сохранить массив данных в  JS файл, и сослаться на него в html. JS будет закешировано в браузере. Сброс кеша выполняется изменением файла и сменой версии файла в html. 

Периодически запускаемый скрипт может реализовывать любую стратегию управления кешем: TTL (удаление файлов, созданных более N минут назад), ограничения размера кэша (LRU, с учетом времени последнего доступа, MRU, LFU).

Таблицы баз данных в оперативной памяти

Этот механихм релизуется через таблицы в подсистеме хранения данных MEMORY. Хотя данные будут очищены после перезагрузки сервера - схемы таблиц будут сохраняться. 

Преимущества:

·   поддерживает SQL

·   хранением данных в памяти

**·**   создания индексов на основе хеш-таблицы

Недостатки:

·   проигрывает более простым методам доступа CRUD, типа Memcached.

###### Типы кешей по уровню обработки

Кэширование HTML-страницы целиком. 

Преимущества:

·   Наиболее эффективный вариант кеширования. 

Недостатки: 

·   отсутствует гибкость, например, невозможно менять какие-то части страницы под конкретного пользователя. 

Применение:

·   для страницы гостевого пользователя, которая для всех гостей одинакова

·   в случае maintenance и failure

Техники

Можно формировать статические страницы в фоновом процессе и сохранять в какую-то папку. Необходимо подобрать формат для имени статических страниц, который позволит при запросе серверу Nginx проверить наличие статической страницы в папке для запрашиваемого URI.

Если вся страница не является полностью статической, то можно хотя бы закешировать в статические файлы отдельные ее части. Для сборки страницы целиком из статических блоков необходимо применить технологию включения на стороне сервера (server-side include – SSI).

Скорее всего кешированные целиком страницы размещаются на диске, поэтому к ним применимы техники из Кэши на диске. Для статических страниц можно применять описанную там технику с TN (смотреть наличие статической страницы, а если ее нет, то формировать на бекенде).

Кэширование результатов компиляции php-файлов

Подробнее Акселераторы

Кэширование отдельных блоков страницы

Наиболее гибкий и доступный для управления программисту вариант кеширования. Позволяет менять содержимое страницы в зависимости от полученного запроса (сессий, кук, заголовков). 

##### На уровне браузера (browser) и в сети (proxy, gateway, CDN)

Это кеши, которые встроены в браузер (browse cache), и находятся между веб-сервером и браузером в сети (proxy cache, gateway cache). Наиболее эффективный тип кеша, т.к. находится близко к клиенту. Однако наиболее сложный для инвалидации, поэтому в него необходимо помещать статические данные (например, изображения).

Преимущества использования:

·   Уменьшение времени получения контента в браузере. Важно для клиента.

·   снижение сетевого трафика. Для клиента – в случае browser cache, для сервера – в случае любых cache в сети.

Управление кешированием выполняется с помощью заголовков ответа HTTP (подробнее Для управления кешированием). Исторически заголовки кэшировании относились лишь к браузеру клиента, но сегодня следует учитывать их влияние на промежуточные точки в соединении.

###### Свежий (freshness) и валидный (validation) контент

**Свежий** (freshness) контент извлекатся непосредственно из кэша без всяких проверок и взаимодействия с сервером-источником этого контента.

**Валидный** (validation) контент – контент, который уже устарел, т.е. несвежий, но прошедший процесс валидации на сервере, который потдвердил, что контент актуален и соответственно не требует повторной загрузки на клиент. 

Процесс **валидации** несвежего закешированного контента заключается в дополнении запроса специальными заголовками-валидаторами (If-Modified-Since, If-None-Match). Если контент браузера актуален, то сервер может его не возвращать, а ответить заголовком 304 Not modified. Такой запрос называют условным, т.к. процесс его обработки зависит от условия.

###### Кэш браузера (browser cache)

Располагается на компьютере клиента, управляется браузером. Браузер один раз за сессию (текущем сеансе) проверяется свежесть контента, при необходимости валидирует его или загружает. 

###### Прокси-кэш (Proxy cache)

Кеш на прокси-сервере в сети, обслуживающем множество клиентов. Может настраиваться вручную в браузере. Запрошенные одним клиентом контент будет сохранен в кеше и может отдаваться другим клиентам. 

###### Кэш-шлюз (Gateway Cache)

Так же называются “реверсивные прокси-кэши” (reverse proxy cache) или “суррогаты” (surrogate cache) шлюзы. Используются для снижения нагрузки на сервер. Включают в себя балансировщик нагрузки. 

Примером является сеть доставки (дистрибуции) содержимого (Content Delivery (Distribution) Network, CDN) — географически распределённая сетевая инфраструктура, позволяющая оптимизировать доставку и дистрибуцию [содержимого](https://ru.wikipedia.org/wiki/Данные_(вычислительная_техника)) пользователям. При правильной настройке, CDN передаёт контент клиентам через самый быстрый и ближайший к нему сервер. Бонус: если вдруг падают сервера, CDN отдает данные из кэша так, что пользователи этого могут и не заметить.

###### Алгоритм работы кеша

\1.  Проверяется свежесть (freshness) контента. Свежим считается контент, у которого установлено время истечения (Expires) или другой заголовок (Cache-Control), контролирующий время жизни, и он еще не истек. Свежий контент берется непосредственно из кэша, без взаимодействия с сервером-источником этого контента.

\2. Если контент является устаревшим, серверу-источнику будет предложено проверить его валидность, для того чтобы не загружать контент целиком заново. 

\3. Если контент не свежий и не валидный он загружается. 

\4. Если заголовки ответа сообщают кэшу не сохранять ответ, он не сохранит.

\5. Если в ответе нет информации о свежести контента (Expires или Cache-Control) и не присутствует валидатор (Last-Modified или ETag), контент считается некэшируемым.

\6. Иначе контент кешируется. HTTPS кешируется также как и HTTP.

###### Стратегия кэширования

Динамический контент как правило не кешируется выставлением заголовка:

**Cache-Control**: max-age=0, no-cache, no-store

Однако иногда динамический контент не меняется какое-то время. В этом случае контент можно закешировать в браузере, если пользователь обращается к странице несколько раз, либо на промежуточных прокси-серверах.

Приемы:

·   Если ресурс необходимо перекешировать, то его нужно переименовать, добавив к имени  увеличивающийся номер версии, временной ярлык, хэш.

·   Один и тот же контент должен быть доступен по одному URL-адресу

·   Динамический контент имеет смысл кешировать, если он статичен некоторое время и зависит только от URL-адреса. Отправку заголовков кеширования и валидацию по запросу (If-No-Match) должен обеспечивать скрипт на сервер. 

·   Контент, который зависит от куков, информации об аутентификации или от какого-то другого внешнего фактора, нельзя кешировать. 

·   Можно сделать динамический контент статическим, т.е. выгрузить его содержимое в файл при очередном изменении и переложить кеширование на веб-сервер.

·   Запросы POST не кешируются большинством кэшей

·   Если требуется на закешированную страницу поставить счетчик, то возможные варианты:

o  Скриптом дергать счетчик и отправлять данные для подсчета (URL).

o  Разместить на кешированной странице **некешируемый** zeropyxel, URL страницы можно получить из параметров запроса к zeropyxel или из заголовка Referer.

·   Если хочется кешировать страницы, индивидуальные для каждого пользователя, можно с помощью заголовка Cache-Control указать, что требуется проводить валидацию страницы при каждом запросе с помощью заголовка (обязательно нужно использовать также ETag)

**Cache****-Control**: public, **no****-cache**

В запросе на валидацию вместе с заголовком If-None-Match будут переданы куки с аутентификацией пользователя. В скрипте можно решить по данным в сессии пользователя: вернуть контент целиком или 304 Not Modified.

·   Если на странице есть элементы, отображение которых отличается для разных пользователей, можно их загружать скриптом с помощью технологии AJAX.

#### Инвалидация кэша

Инвалидация кеша – это компромисс между полнотой, избыточностью и сложностью этой процедуры. **Полнота инвалидации** — насколько часто в кеше будут содержаться грязные данные. **Избыточность** – как часто кеш будет инвалидироваться без необходимости.

##### Инвалидация по времени

Выполняется установкой времени жизни кэша (TTL). Вместе с кэшированным объектом хранится момент истечения срока хранения; Удаление выполняет либо сама система кеширования, либо ручной фоновый процесс, либо в момент обращения запроса. 

Гарантирует, что сразу после изменения данных кеш грязен. Время, которое кеш остаётся грязным, мы можем легко ограничить, уменьшив время жизни (что в свою очередь сократит процент попаданий). Т.е. при сокращении времени жизни кеша полнота инвалидации улучшается, а избыточность ухудшается. Подходит для редко изменяющихся данных или для которых требования к актуальности не критичны.

##### Инвалидация по событию

Если кэширование устаревших данных неприемлемо, то необходимо сразу инвалидировать данные в процессе, которые их изменяет. 

Возможны два варианта:

Инвалидация при записи

Варианты: 

·   просто помечать во всех инвалидируемых ключах, что данные недействительны, грязные, а перегенерировать в момент чтения

·   сразу обновить данные во всех ключах, которые стали недействительными. 

Желательно обновление кеша производить в фоновом режиме, не связанном с запросами пользователей. Недостаток фонового обновления: усложнение кода, на каждый кешируемый объект требуется написать инвалидирующий код. 

Есть попытки встроить инвалидирующий код прямо в библиотеку работы с запросами, т.е. отслеживать какие запросы кешировались и при изменении этих данных инвалидировать этот кеш, например, кешируется запрос

where category_id=2 and published=true

на все изменяющие запросы, попадающие под это условие делаем инвалидацию кеша. 

Инвалидация при чтении

Вместе с объектом сохраняется **номер его версии** или временная метка, от которых зависит кэшированный объект. Хранение номеров версий также называется тегированным кешем. 

Преимущество: 

·   операции пересчета связанных данных «размазываются» по времени.

Примеры:

·   вместе со stat пользователя в кеш помещается номер версии пользователя. При каждом обновлении данных пользователя user обновляется номер его версии (например, сохраняется также в кеше). При отображении статистики мы сравниваем версию пользователя в stat c версией пользователя в user, и при необходимости пересчитываем статистику пользователя. 

·   кэшировать вместе с комментариями к книге версии пользователя и версии книги, например, user_ver=1234 и book_ver=5678. И в кеше отдельно хранить текущую версию пользователя и книги. 

#### Кэширование иерархий объектов

Зачастую удобней кешировать не полную выборку из всех таблиц, а данные из связанных таблиц разместить в отдельных кешах и ссылаться на них по первичному ключу. 

Пример: при кешировании результатов поиска у нас можно кешировать список первичных ключей постов, а сами посты хранить в отдельном кеше. 

Преимущество:

·   позволяет не дублировать описание постов в нескольких кешах. 

·   позволяет легко выполнять инвалидацию кешей с отдельными постами, изменение поста не требует пересмотра всех кешей, где он хранится. 

Недостатки: 

·   требуется несколько запросов в кеш на одну выборку, однако можно реализовать в два запроса: 

o  выбрать список ID постов

o  сделать multi_get в memcached за информацией о нескольких постах по их ID

·   возможны проблемы нарушения согласованности данных в кеше, т.к. список постов и отдельные посты в кеше могут правиться независимо. Например, может измениться заголовок поста таким образом, что перестанет содержать ключевые слова, отвечающие условиям поиска, однако результат поиска еще не удален из кэша. Если такая ситуация неприемлема, то можно воспользоваться кэшированием с версиями и хранить версии товаров вместе с результатами поиска. 

# High Availability

**Доступность** - доля времени, в течение которого приложение может отвечать на запросы. Измеряется в «девятках»; так, «пять девяток» 99.999% времени, то есть время простоя составляет примерно пять минут в год.



# Причины проблем

·  Клиенты при подключении видят ошибку. Возможно веб-сервер уперся в ограничение памяти или в ограничение количества воркеров. Например, Apache создал большое количество процессов в режиме keepalive (постоянные соединения) и пока эти соединения не закроются, под новые воркеры не хватает памяти. Также возможна проблема асинхронной обработки тяжелых запросов. Асинхронная обработка тяжелых операций

## Типы трафика

Для каждого типа трафика требуется свое аппаратное решение и программное решение, которое учитывает особенности этого трафика. 

При использовании HTTPS требуется более мощный процессор для работы с шифрованными данными.

Основные типы трафика:

·  динамический HTML (dynamic)

·  запросы к API – короткий запрос и короткий ответ, важны малые задержки на ответ (latency)

·  cтатика (static) – большой объем ответа, задержки не очень чувствительны для пользователя, важна высокая скорость передачи данных (сhannel capacity).

·  upload от пользователя – большой объем запроса, также высокая скорость передачи данных (сhannel capacity).

 

## Стандартная архитектура

Архитектура стандартного веб-проекта:

·  перед бекендами размещается несколько балансировщиков в виде nginx на отдельном узле. 

·  балансировка нагрузки на программные балансировщики nginx выполняется через DNS-балансировку

·  nginx проксирует запросы к *.php на Apache. В итоге Nginx сам поддерживает большое количество keep-alive соединений небольшим количеством воркеров за счет эффективной архитектуры. До Apache долетает лишь малое количество очень коротких по времени проксированных запросов от nginx. Ответ Apache вычитывается в буфер nginx и отдается с требуемой клиентом скоростью.

·  отдача статики непосредственно nginx.

·  статика (картинки, видео) и динамика (php-скрипты) разносятся по разным серверам. Запросы к API-приложения, которые обрабатываются серверами динамики, небольшие по размеру и должны выполняться очень быстро. Запросы к статике, наоборот, тяжелые и для них не требуется значительная оперативность. Поэтому для них требуется разная конфигурация серверов по процессору и памяти. Если статика и динамика расположены на одном сервере, тяжелые запросы к статике начнут тормозить легкие оперативные запросы к API.

Стоит ли включать в архитектуру Apache? 

Есть мнения за и против. 

Нюансы:

·  Apache жрет много ресурсов

·  единственное преимущество перед PHP-FPM – файлы .htaccess

·  по подсчетам Apache дополнительно съедает 200-500Мб (тут расчет Расчеты метрик) и процессорное время. Но если честно, то и PHP-FPM жрет память и процессорное время.

## Безопасность

### DDOS-атака

Если обработка какой-либо страницы очень тяжелая (например, поиск), то злоумышленник может организовать DDOS атаку на этот адрес и привести к перегрузке базы данных. 

Также DDOS атака может быть организована случайно ботом, который массово сканирует тяжелые страницы.

Допустимые варианты решения проблемы: 

·  отрубить атакуемый функционал (метод API)

·  заблокировать атакующие IP

·  настроить лимиты на URI. Добавить к функционалу капчу.

·  установить лимиты по количеству коннектов. Минус – у других клиентов возникнут проблемы c загрузкой статики в несколько соединений.

·  настроить netfilter

Пример:

У нас бот яндекса сканировал страницы в ленте комментариев с большим смещением. Это приводило к большому количеству запросов вида:

SELECT * 

FROM comment c 

WHERE ...

ORDER BY ... 

LIMIT 50 OFFSET 25931900

Способ диагностики проблемы:

·  посмотреть в SHOW PROCESSLIST на выполняемые запросы и время их выполнения

·  посмотреть в лог nginx (apache), кто обращается по адресам с тяжелыми страницами

Способ решения проблемы:

·  отрубить возможность обращаться к страницам с такими тяжелыми запросами для данного IP или для всех

·  перезагрузить nginx(apache), чтобы сбросить соединения к базе данных, либо вручную сделать KILL тяжелым запросам.

## Алгоритм масштабирования приложения

Масштабирование любого Web приложения — это постепенный процесс, который включает:

\1.   [Анализ нагрузки](https://ruhighload.com/post/Правильный+мониторинг+).

\2.   Определение наиболее подверженных нагрузке участков.

\3.   Вынесение таких участков на отдельные узлы и их оптимизация.

Этапы развития архитектуры по мере нарастания нагрузки:

\1.   На одном сервере веб-сервер, приложение PHP и БД

\2.   Вынесение БД на отдельный сервер

\3.   Вынесение nginx на отдельный узел, проксирование запросов к скриптам на apache и отдача статики непосредственно nginx. Нужно настроить [deployment (выкатку) приложения](https://ruhighload.com/post/Deployment+большого+проекта) и на сервер Nginx и на сервер с PHP. Сервер PHP обычно называют бекендом.

server {

   server_name ruhighload.com;

 

   root /var/www/ruhighload;

   index index.php;

 

   location ~* \.(php)$ {

​    fastcgi_pass 10.10.10.1:9000;

​    fastcgi_index index.php;

​    include fastcgi_params;

​    fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;

  }

}

\4.   Организация нескольких бэкэндов за nginx, т.к. php начинает тормозить всю систему. Nginx умеет балансировать нагрузку между ними. Для этого Вам необходимо выделить список бекендов в upstream и использовать его в конфигурации:

upstream backend {

  server 10.10.10.1;

  server 10.10.10.2;

  server 10.10.10.3;

}

 

server {

   server_name ruhighload.com;

 

   root /var/www/ruhighload;

   index index.php;

 

   location ~* \.(php)$ {

​    fastcgi_pass backend;

​    fastcgi_index index.php;

​    include fastcgi_params;

​    fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;

  }

}

можно использовать веса бекендов, если какие-то из них мощнее, чем другие:

upstream backend {

  server 10.10.10.1 **weight=10**;

  server 10.10.10.2 **weight=2**;

  server 10.10.10.3 **weight****=4**;

}

\5.   Кэширование. Например, для хранения сессий. Memcache поддерживает несколько серверов, путем добавления через addServer. (консистентное хеширование). 

Этапы развития БД при масштабировании: 

·  репликация для масштабирования чтения 

·  функциональное секционирование. Например, для системы блогов разбить данные на три части: пользователи, сообщения и комментарии. Их можно поместить на разные узлы (вначале это может быть сервер, а потом мастер-слейв), а соединение таблиц выполнять на уровне приложения. 

·  шардирование. Например, секционирование сообщений и комментариев (т.к. их больше и они длиннее) по идентификатору пользователя, узел можно организовать в топологии мастер-мастер для надежности. 

## Типы ресурсов

·  Процессор

·  Память (RAM)

·  Disk IO

·  Сеть

## Балансирование нагрузки

Балансировка нагрузки (load balancing [ləʊd ˈbælənsɪŋ]) — механизм распределения запросов между несколькими серверами с целью оптимизации использования ресурсов, сокращения времени обслуживания запросов, горизонтального масштабирования, а также обеспечения отказоустойчивости (резервирования).

### Использование балансировщик

Балансировщик нагрузки (load balancer) — машина или программа, основная функция которой — определить на какой сервер послать запрос. Балансировщики могут быть сконфигурированы в отличии от dns балансирования. Примеры балансировщиков: NGINX, HAProxy, Cisco CSS и т.п.

Преимущества:

·  Умеют периодически отслеживать доступность бэкендов и удалять из пула недоступные серверы. 

·  Умеют перебирать по порядку бекенды, пока не найдет доступный бекенд (подробнее Модуль upstream)

Недостатки программных балансировщиков:

·   представляют собой единую точку отказа и в случае падения балансировщика – падает вся система. 

·  при наращивании нагрузки и горизонтальном масштабировании становятся узким местом в системе. Трафик упрется в производительность и полосу пропускания узла, на котором размещен load balanсer. 

Способ решения этих проблем – применение DNS-балансировки.

### DNS-балансировка

Принцип работы: DNS сервер (возможно даже установленный у нас) отдает несколько IP по одному доменному имени. Клиент выбирает случайным образом один из IP адресов. По «закону больших чисел» нагрузка равномерно размазывается по нескольким узлам.

В случае если выбранный браузером IP адрес не отвечает по 80 порту, то после истечения таймаута, браузер прозрачно для пользователя выбирает другой IP и делает запрос на него. 

Понятие TTL. Для DNS-записи в авторитетном DNS-сервере (authoritative) устанавливается параметр TTL (Time to live). Когда неавторитетный DNS-сервер получает в результате опроса у авторитетного DNS-сервера какую-то DNS-запись, он кеширует ее на время, указанное в TTL. При разрешении имени для той же DNS-записи с помощью кеширующего неавторитетного DNS-сервера до истечения срока действия TTL, кеширующий DNS-сервер будет отвечать ранее закэшированной DNS-записью, а не снова получать ее от авторитетного DNS-сервера.

Время задаётся в секундах, типичное значение составляет 86 400 секунд, то есть 24 часа. Это означает, что при изменении записи DNS, вплоть до 24 часов после изменения, DNS-серверы по всему миру могут выдавать старые данные из кеша, пока он не будет обновлён. Более короткие TTL могут сильно нагрузить авторитетный DNS-сервер и имеют смысл на случай изменения адреса критически важных сервисов.

Администратор кэширующего DNS-сервера может установить жесткий TTL, который не будет зависеть от TTL авторитетного DNS. Поэтому установка TTL на авторитетном DNS-сервере не может гарантировать, что все кеширующие DNS-серверы будут иметь новые DNS-записи после истечения срока действия TTL

Ограничения. Ответ от DNS сервера приходит по протоколу UDP в пакете размером 512 байт. В зависимости от количества служебных данных максимальное количество IP адресов при DNS-балансировке находится в диапазоне 4-25 штук. Как правило балансируют 4-6 адресов.

Преимущества:

·  низкая стоимость балансировки, т.к. не требуется никакого программного/аппаратного обеспечения

·  отсутствует единая точка отказа.

## Проблемы множества бекендов

Когда один бекенд с PHP не справляется с нагрузкой, добавляют еще несколько бекендов и распределяют нагрузку между ними каким-либо методом балансирования нагрузки. Помимо снижения нагрузки на один бекенд, это повышает отказоусточивость системы – при выходе из строя любого бекенда, остальные бекенды могут взять на себя его нагрузку.

При переходе к распределенной обработке запросов на множестве бекендов архитектура приложения должна быть перестроена. Результат обработки запроса не должен зависеть от того, на каком сервере он обработан (в пределе stateless-код, но так не бывает, чтобы код вообще без состояния).

Проблема обработки файлов

При наличии нескольких бекендов возникает проблема синхронизации файлов при одновременной их обработке с нескольких бекендов. 

Варианты решения:

·  у нас – все запросы загрузки и обработки файлов направляются балансировщиком на один бекенд (adm1). С этого же сервера файл после изменения отправляется на сервера статики, откуда раздается клиентам. Если он нужен на других серверах динамики, то его можно синхронизировать через rsync.

·  отказаться от локального хранения файлов и хранить файлы в облаке. Наиболее популярны распределенные файловые хранилища с протоколом S3 (например, Amazon S3, Ceph)

### Проблема обработки сессий

Если на одном бекенде в локальной памяти поднята сессия, а следующий запрос балансировщик отправил на другую машину, то новая машина не будет видеть данную сессию. 

Nginx как балансировщик поддерживает несколько механизмов, позволяющих управлять балансировкой, и отправлять следующий запрос на ту же ноду, что и предыдущий (подробнее Методы балансировки):

·  ip_hash

·  hash

·  sticky session (в коммерческой версии).

Этот механим называется постоянство сессий (session persistence) или липкость (stickiness [ˈstɪkɪnəs]). Недостаток такого механизма: балансировщик, который и так является узким местом системы, занят еще и обработкой состояния о том, какой запрос каким сервером обрабатывается.

Другой вариант, не нагружающий балансировщик: хранить сессии в распределенной кеширующей системе (база данных, memcached). В этом случае не имеет значения, на какой из бекендов приходит запрос.

## Взаимодействие с внешним сервисом

Бекенды всегда взаимодействуют с тяжелыми внешними сервисами: базы данных (MySQL), поисковые движки (Sphinx). В SOA-архитектуре вообще выделены отдельные внешние сервисы под каждую задачу. И в любой момент времени один из сервисов может начать тупить.

Еще более опасно, если обращение идет к стороннему внешнему сервису в сети с непредсказуемым временем исполнения. Например, так:

$data = file_get_content("https://path/to/resource");

Если не предусмотрена защита от тупки такого внешнего сервиса, в результате тупки возникает каскадный отказ системы:

·  ↑вырастает время выполнения одного запроса

·  ↑вырастает количество активных воркеров

·  бекенд упирает в максимальное количество воркеров

·  новые запросы, даже не связанные с тупящим ресурсом, перестают обрабатываться

Способы диагностики проблемы: 

·  профилирование через какой-то инструмент, показывающий запросы к внешним ресурсам (newrelic, zabbix?)

·  просмотр сетевых соединений через unix-утилиты (netstat, tcpdump)

В зависимости от типа сервиса, взаимодействие с сервисом может выполняться:

·  асинхронно (гораздо проще)

·  синхронно (сложнее)

### Асинхронная обработка

Более простой вариант, т.к. тяжелое взаимодействите с сервисом можно выполнить в фоновом процессе. Применение любого вида асинхронной обработки сразу снимает проблему, однако не для каждого сервиса это подходит. Например, асинхронно невозможно ображаться к базе данных.

Способы решения проблемы: 

·  если данные только читаются и редко изменяются, то их можно закешировать

·  если данные отправляются в сеть, то это нужно делать асинхронно через Message Query. 

#### Особенности использования cron

Обработку тяжелых запросов можно выполнять асинхронно с запуском по времени через cron.

Необходимо следовать советам:

·  в cron помещать вызов PHP через CLI, и ни в коем случае не делать обращение к скрипту через веб-сервер. Т.к. это забирает ресурсы веб-сервера и уменьшает количество доступных воркеров.

·  внимательно следить за временем выполнения скриптов с отключенным лимитом времени set_time_limit(0), т.к. запрос может подвиснуть и жрать ресурсы системы

·  нужно ставить блокировки на повторный запуск процедуры в cron до завершения предыдущего запуска (утилита setlock запускает другую программу и одновременно создает lock-файл, который служит мьютексом и защищает от повторного запуска)

### Синхронная обработка

Если критично обращаться к ресурсу в контексте запроса, то нужно хотя бы ставить таймаут.

Эффективный способ замаскировать проблему с сервисом – не показывать тот блок на странице, за который этот сервис отвечает. Как только запросы к сервису начнут проходить, блок на странице снова отобразиться. Некоторые сервисы критичны для всего сайта (например, база данных, кеши), в случае их падения пользователю необходимо вывести понятную ошибку (типа, мы в курсе и чиним).

#### Сircuit brеaker 

Гораздо эффективнее между удаленным сервисом и бекендом разместить circuit breaker – проксю, которая бы вырубала тупящий сервис при срабатывании какого-нибудь условия. 

Circuit breaker может быть реализован как:

·  модуль в коде на PHP

·  отдельно стоящий демон, который проксирует через себя запросы.

Для Circuit breaker задаются порог предупреждения (warning threshold) и порог отключения (disable threshold). Когда количество тормозящих воркеров достигает disable threshold (например, 10%) circuit brеaker перестает отправлять запросы к сервису и сразу отдаёт бекендам ошибку, как будто бы сервис лежит. После этого воркер бекенда может отправить запрос на резервный сервис (например, на другой slave DB).

Время от времени Circuit breaker автоматически пропускает запрос от какого-нибудь воркера, чтобы посмотреть, не ожил ли всё-таки сервис. Если он отвечает адекватно, то мы снова включаем его в работу.

## Приемы у нас

### Изменения в структуру таблицы с логами

**Задача.** Требуется внести изменения в структуру таблицы с логами, которая находится под нагрузкой. 

**Решение.**

·  Создать временную пустую таблицу для логов 

·  Переименовать таблицы так, чтобы временная таблица стала на место основной.

·  Сделать изменения на основной таблице.

·  Снова поменять их местами

·  Перенести из временной таблицы данные в основную.

### Запросы висят на табличной блокировке

**Задача.** В результате изменения структуры таблицы возникла табличная блокировка, запросы висят на ожидании доступа к таблице.

**Решение.** Сделать правки в коде, если это возможно, чтобы переключить запросы на другую таблицу или хотя бы отключить обращения к таблице. Плюс перезапустить Apache.

## Хранение статики

Для хранения фотографий можно использовать:

- облачный storage

- коробочное решение

- хранить у себя в кластере

- сеть хранения данных (Storage Area Network, SAN) — подключеник внешних устройств хранения данных (дисковые массивы, оптические приводы) к серверам таким образом, чтобы операционная система распознала подключённые ресурсы как локальные.

### Хранение статики в своем кластере

Берем кластер из нескольких машин для хранения изображений. 

Применяем схему с *virtual shard*'ами. Организуем два *mapping*'а: 

- картинка → `vshard`. Один из вариантов: хранить всех картинки одного пользователя в одном *vshard*, для этого нужно отображать `user_id` → `vshard`. Можно использовать любые способы задания [*sharding function*](). 
- `vshard` → реальный `shard` (физический узел). Если количество `vshard` и `shard` небольшое, то это отображение может задаваться статически вручную ([table function](#Sharding.md#динамическое-недетерминированное-table-function)).

Для серверов статики обычно характерен небольшой объем входящего трафика, при большом объеме исходящего трафика. Поэтому необходимо масштабировать чтение статики.

Часто имеет место следующий *case*: только что залитые фотки очень горячие, а через какой-то момент времени они перестают запрашиваться. Они составляют небольшой горячий *dataset* (рабочее множество). Этот *case* соответствует ситуации, когда оптимально применение [кеширования]().

*Photocache* – отдельная машина с быстрыми SSD дисками, которая кеширует картинки и при *miss* перенаправляет запросы в *storage*. Для этого на *photocache* установлен *nginx*, который делает `proxy_pass` на *storage* при *miss*.

Общая схема запроса картинки: пользователь → *photocache* → *storage*.  

В photocache все картинки разделены на:

- *hot cache* – папка, в которой хранятся активно запрашиваемые картинки
- *cold cache* – папка, в которую переносятся картинки из *hot cache*, после того как снижается количество *request*’ов к ним. 

В *photocache* *nginx*  ведет `access.log`. В фоне работает *demon*, который считает статистику по доступу к картинкам. На основе статистики *demon* перемещает картинку между cach'ами или удаляет. 

Жизненный цикл картинки в *photocache*:

- картинка попадает в *hot cache*
- при снижении количества запросов картинки перемещаются из *hot cache* в *cold cache*.
- при снижении количества запросов картинки удаляются из *cold cache*.

 

<u>Высокая доступность</u>

Если требуется высокая доступность, то необходимо устранить точки отказа. 

Для данной архитектуры:

- пустой резервный *photocache*, который включается в работу и прогревается при отказе одного из *photocach*'ей.
- дублирование всех storag'ей. При этом основной и резервный *storage* могут работать параллельно на чтение (аналогично *replication*). Дублирование картинок выполняется в фоновом процессе.

Для обработки фоновых задач (обработка картинка, копирование на резервный *storage*) следует использовать *Message broker*.

### Особенности картинок

<u>Выбор формата:</u>

- `jpg` – с потерей качества, для сложных изображений, для фотографий
- `webs` – лучше `jpg`, но поддерживается не всеми браузерами
- `png` – без потери качества, для иконок
- `gif` – кодирование по палитре, поддержка анимации

<u>Структура для хранения:</u>

Необходимо использовать древовидную структуру из папок. Это позволит избежать ограничение на количество файлов в каталоге и тормозов системы при работе с такими каталогами. 

Нужно разделить для удобства все картинки по типам: `avatars`, `posts`, `comments`. 

Внутри этих папок наиболее удобно делить файлы в соответствии с бизнес логикой. Например, хранить в виде: `./yyyy/mm/dd/123.jpg`. Так проще удалять старые картинки и делать инкрементальный бекапы.

<u>Порядок загрузки изображения</u>

- уменьшить размер до минимально допустимого, чтобы не хранить огромные фотографии

- удалить метаданные

- преобразовать в дополнительные форматы (`.webp`). 

  При запросе пользователя, необходимо выполнить проверку поддержку `.webp` браузером и в зависимости от этого отдать `.webp` или `.jpg`:

  ```nginx
  server {
  	...
  	location ~* ^/.+\.(jpg|jpeg)$ {
  	  if ($http_accept ~* "webp")    {
  	      rewrite (.+) $1.webp;
  	  }
  	}
  ...
  }
  ```

### Создание обработанных картинок (tn'ок)

На *storag*'ах и *photocash*'ах  простаивает CPU, т.к. основная нагрузка на сеть и на диски. Поэтому CPU может быть загружен созданием обработанных картинок (например, генерацией *thumbnail*'s):

- генерацией *tn*'ок
- перекодирование изображений в более компактные форматы (webp или progressive jpeg)
- resize, crop, накладывание watermark.

Способы создания *tn*'ок.

<u>1 подход</u>

С хранением (кешированием) *tn*'ок для всех картинок. Генерация выполняется в момент загрузки  или после загрузки в фоне. 

Имеет смысл:

- если все изображения примерно одинаково горячие
- не ограничены в объеме storag'ей
- CPU storag'ей не справляют с нагрузкой по генерации thumbnails на каждый request

Особенности:

- ↑ *data size*, ↓ *CPU load*. 
- Ограничены некоторым набором размеров (*tn*'ок) 
- Длительный процесс генерации, если требуются новые *tn*'ки

<u>2 подход</u>

Не генерировать thumbnails заранее и не хранить их в storage. Генерация выполняется налету, в момент *request*'а. 

Имеет смысл:

- если все изображения примерно одинаково горячие
- ограничены в объеме storag'ей
- CPU storag'ей справляют с нагрузкой по генерации thumbnails на каждый request

Особенности:

- ↓ *data size*, ↑ *CPU load*.  
- достаточно иметь несколько *tn*-ок (маленькую, среднюю и большую), а для остальных размеров делать *resize*. 
- можем получить любой точный размер, который запрошен в URL. Это особенно актуально для мобильных версий с невысокой скоростью интернет.
- добавление новых размеров не требует процедуры генерации *tn*-ок для всех картинок.

<u>3 подход</u>

Гибридный подход. С генерацией *tn*'ок в момент первого *request* и кешированием картинки в файловой системе. Объединение преимуществ двух предыдущих подходов. 

- меньше *data size*, чем в 1 случае, и меньше *CPU load*, чем во 2 случае 
- загрузка CPU только в момент генерации *tn*'ки в первый раз
- добавление новых размеров не требует процедуры генерации *tn*-ок для всех картинок.

Желательно перед добавлением новой *tn*'ки "прогреть" кеш – запустить генерацию *tn*'ок на небольшом количестве *request*'ов.

Особенно важно избежать "проблемы стаи собак" (dog-pile effect, так же cache stampede) – когда множество запросов будет сделан к одним и тем же "горячим" thumbnails, который в тот момент еще не будут закешированы. Дополнительно, эту проблему можно решить, используя распределенную блокировку через memcache, чтобы одну картинку генерировал только один request, а остальные ожидали его окончания.

<u>Разновидности 3 подхода</u>

1. с генерацией *tn*'ок в момент первого *request*, но кеширование выполняется по условию. Усложнение 3 случая (требуется продуманное условие). Например, если по статистике картинка запрашивает часто (требуется сбор статистики), или картинка относится к свежему посту (не требуется сбор статистики).  
   - меньше *data size*, чем в 4 случае, при правильном условии

Способы генерации:

- Наиболее быстро это делает Nginx+LuaJIT.
- с помощью PHP

https://vk.com/away.php?to=https%3A%2F%2Fm.habr.com%2Fru%2Fpost%2F77873%2F&cc_key=

Павел 8:47

ngx_http_image_filter_module — для ресайза изображений;ngx_http_proxy_module — для кеширования;ngx_http_secure_link_module — для защиты от спама;

В итоге дополнительные изображения можно забирать по ссылкам:

myproject.ru/preview/i[md5]/[path_to_image]myproject...
RU-CENTER - регистрация доменов, домен РФ,..
www.nic.ru
Павел
Павел 11:36

Да, три действия, только один раз в сутки, на не при каждом запросе.
Павел
Павел 19:21

У картинки меняется название

большая часть из которых к тому же больше никогда не будет запрошена.



# Интересные задачи и фишки

## Наши задачи

Тест серверов на время ответа с помощью curl

Использование блокировок в БД

Требовалось, чтобы один набор данных обрабатывался только одним воркером. Для этого испольовалась InnoDB и exclusive-lock чтение данных с помощью:

SELECT ... FOR UPDATE

В этом случае остальные воркеры ставились в ожидание на блокировке и не могли одновременно читать эти же данные.

 

## Фишки вконтакте

в вопросе кэширования.

При вставке новых данных, на которые предполагается высокая нагрузка в ближайшее время, например новый пост в ленте пользователя, имеет смысл эти данные **предварительно закешировать** и отправить пост в ленту только после кеширования. 

Можно после изменения данных не делать кеш сразу не валидным, а поставить задание и записать задание в кеш позже, некоторое время показывая **просроченные данные** из кеша. 

При сохранении подряд нескольких ключей в кеш нужно случайно **варьировать время хранения** для размазывания нагрузки на время TTL (жизни ключа). 

**Конфигурации приложения** можно хранить: в файлах ini, json, yml; в PHP коде; во внешних системах, которые могут по запросу прислать конфиг. Реализация последнего варианта: конфиг пишется в master ноду, на каждом сервер динамики поднята slave нода, куда реплицируется конфиг. 

Для распределения нагрузки по записи в один ключ memcache необходимо воспользоваться **шардированием ключа**, например для реализации счетчиков, подсчета посещаемости. Инкрементируется не один счетчик, а например 10 тысяч ключей, при этом получение значения счетчика предполагает multi get всех ключей и складывание в коде. 

Если не требуется значительная точность, то можно **инкрементировать счетчики с вероятностью**, например, 1/10, снижая нагрузку на кеш в такое же количество раз. При чтении значения счетчика необходимо умножить результат на коэффициент вероятности, получая значение близкое к реальному. 

Улучшения в результате изменения архитектуры приводят либо к появлению новых фич (фичатим), либо оптимизации использования железа (архитектурная команда). 

Соцсеть - это не банковский процессинг и иногда можно пожертвовать стопроцентной надежностью и потерять немного данных или уйти в downtime.За счет этого можно сэкономить денег и показывать пользователям меньше рекламы, достигнув разумных компромиссов надежность/стоимость.

 

## Badoo



#### Надежность хранения

##### RAID

Можно использовать аппаратное дублирование даннх через RAID массивы. 

Минусы подхода:

·  задержки при восстановлении поврежденных данных. Например, на восстановление диска из RAID5.

·  в RAID5 скорость чтения/записи равна скорости самого медленного диска

·  система дисков жестко связана. Если глючит один диск – глючит вся система.

##### Ручная репликация статики

Удобней использовать ручную репликацию статики на несколько серверов. 

Плюсы:

·  отдельные узлы для хранения независимы, при выходе из строя узла системы остается доступной

·  нагрузку гораздо проще горизонтально масштабировать

Информация о синхронизируемых фото размещается в очереди, например, через mysql. Т.к. теперь фото читается с основного диска, как пользователями, так и backup разделом. Ставим перед ними буферный диск небольшого размера SSD. Фото вначале попадает в буфер, а потом по event из очереди копируется на основной и backup раздел.

Фотографии лучше делать immutable, не переписывая измененные фото, а создавая новые файлы без хранения версий. 

Возможно использование распределенных файловых хранилищ – ceph + s3 api, minio.

Файлы должны раскладываться на диске по папкам двух уровней вложенности, чтобы преодолеть ограничение на количество файлов в папке. 

### Версионирование API 

Хороший API всегда версионирован. И если нарушается обратная совместимость, то меняется мажорная версия, например, 1.0.0., 2.0.0 и т.д.

Однако у этого подхода есть ряд недостатков:

·  Любое существенное изменение функционала требует инкрементации мажорной версии, причем в старшей мажорной версии должны быть реализованы изменения всех младших, хотя хотелось бы чтобы разные изменения не зависили друг от друга. Например поэтому нельзя выкатить клиент с функциональностью старшей версии без реализованной функциональности младшей версии.

·  Не всем клиентам нужен одинаковый функционал (например, не все разрешают работать с камерой из браузера), поэтому не для всех клиентов мобильных устройств нужно учитывать появление новой версии

·  изменения протокола под AB тесты не соответствуют версиям основных изменений, это отдельное несовместимое изменение протокола. Т.е. протокол зависит не от версии клиента или версии API, а от внутренних настроек.

Лучший вариант – идентифицировать отдельно каждого клиента и предлагать ему такие данные, которые соответствуют его типу. Первый способ – передавать при каждом запросе клиента на сервер тип клиента и его версию. Однако этот способ очень сложен в поддержке если много различных улучшений и тогда объект на сервер, отвечающий за версионность очень сильно разрастается. Также нужно согласовывать между клиентом и сервером, что клиент поддерживает на данный момент в какой версии, а что перестал поддерживать, нельзя выкинуть функционал из клиента без согласования с сервером.

Версионирование – это решение проблемы изоляции функционала (поддерживаемого от неподдерживаемого). Поэтому идея алгоритма следуюшая: клиент на старте отправляет на сервер набор тех фич, которые он хочет поддерживать, сервер делает проверку этих фич на доступность данному клиенту и отвечает ему отфильтрованным списком допустимых фич и клиент после этого включает нужные фичи. Плюсы подхода:

·  старые клиенты не знают про новые фичи и не запрашивают их

·  можно распараллелить разработку клиента и сервера, т.к. клиент запрашивает только те фичи, которые он поддерживает

·  можно собирать статистику по использованию клиентами фич и выкинуть неиспользуемые вообще

·  можно на сервере переключать функциональность для двух групп при AB тестировании

·  можно протестировать фичу на небольшой группе пользователей, не усложняя архитектуру системы (не добавляя индексы например), и при успешности фичи можно ее допилить для highload.

Минусы:

·  избыточное количество передаваемых данных и обработки на сервере, особенно для постоянно используемых всеми фич.

·  количество фич постоянно растет, каждая мелкая правка – это фича. Способы решения: удалять неиспользуемые фичи, удалить фичи которые используют уже все клиенты, force update принудительно обновить старые клиенты когда там мало пользователей.

### Ручная репликация данных между бекендами

В Badoo вручную реализована репликация данных между бекендами. Репликация может быть реализована двумя способами:

·  синхронный

·  асинхронный

Наиболее эффективный – асинхронный способ, работающий в режиме eventual consistency. Для того чтобы не возникало проблем с несогласованностью данных на бекендах при обработке нескольких запросов одного пользователя, применяются sticky-сессии. Это гарантирует, что все запросы одного пользователя идут на один бекенд.