# Highload

Основные правила надежности:

- использовать проверенные технологии
- сбор бэкапов
- мониторинг (профилирование), измерять все аспекты работы системы.  

Архитектура должна развиваться постепенно в соответствии с нагрузкой.

Правило 95 процентиля: стоит пренебречь 5% пользователей (использующих нестандартные браузеры, нестандартные файлы для загрузки, имеющих большие объемы данных), чтобы не усложнять архитектуру и отладить ее под большинство пользователей.

## Мониторинг (профилирование)

Типы мониторинга:

- Мониторинг сервер – мониторинг серверного железа и серверного ПО

- Мониторинг на уровне приложения – как работают подсистемы самого приложения, как они взаимодействуют с внешними сервисами

- мониторинг на уровне бизнес-логики – метрики по бизнес-объектам (сколько сделана заказов, сколько оставлено комментариев...)

Мониторинг включает

- сбор метрик

- сбор логов, ошибок

- трейсинг сообщений между сервисами в микросервисной архитектуре

Мониторинг решает проблемы:

- Расследование инцидентов

- Прогнозирование нагрузки

Основные внешние метрики проекта:

- RPS;

- время обработки запроса (включая перцентили);

- количество используемой памяти.

### Инструменты мониторинга

Виды инструментов мониторинга:

- *SaaS* (*software as a service*) – клиенту предоставляется внешний сервис для мониторинга, который полностью обслуживается другой стороной:
  - New Relic

- *Self-hosted* решение:

- *Zabbix*

- *Grafana*

### Внутренние метрики

Общие метрики:

·  время ответа сервиса

·  RPS к сервису

База данных:

·  количество записей в таблицах

Очереди сообщений:

·  длина очереди

·  время нахождения сообщения в очереди

Memcached:

·  соотношение hit/miss;

·  топ нагруженных ключей;

·  все внутренние метрики, которые отдаёт команда stats.

## Расчеты метрик

### Метрики памяти

Количество памяти, требуемое некоторому многопроцессному (или многопоточному) приложению (Apache, nginx, MySQL) определяется по формуле:

​                                

  

Общее количество памяти ограничено доступной на сервере оперативной памятью. 

Если известно количество доступной на сервере памяти, то можно определить максимально возможное количество воркеров из предыдущей формулы:

  

### Метрики для RPS

Самый простейший случай, который можно посчитать, – один воркер обрабатывает только один запрос (Apache, MySQL). Nginx может на одном воркере обрабатывать несколько запросов.

Пусть на одном воркере обрабатывается только один запрос. 

Если известно количество параллельных воркеров ( в соответствии с ограничениями памяти, производительностью процессора, I/O) и среднее время выполнения запроса, то можно узнать максимально возможную RPS:

  

Из формулы можно выразить количество воркеров, которые требуется для того чтобы выдержать нужную нагрузку RPS:

  

Неравномерность RPS в течении дня

Для нагруженного сайта критически важно не суточное число запросов, а мгновенное. 10 млн суточных хитов (динамики) – это 116 запросов в секунду при совершенно равномерном распределении за сутки. Однако как правило характерным является 16 нагруженных часов с двумя/тремя пиками нагрузки (развлекательные ресурсы, fishki.net) или 50-100-200 рывков по 300-700% хитов на фоне тех же 16 часов среднего трафика (электронные сми).

### Примеры расчетов

#### Расчет количества памяти для поддержания нагрузки с нужным RPS на веб-сервере

Исходные условия:

·  веб-сервер Apache, который обрабатывает один запрос в одном воркере

·  нагрузка 500 RPS

·  время обработки запроса 40-100 мсек (у нас 40мсек). Для справки: у сложного фреймворка время обработки запроса 80-100 мсек, для легкого запроса время обработки 40-50 мсек. 

·  накладные расходы Apache на один воркер составляют 10 Мб

·  примем количество памяти, требуемое для ядра Apache, равным 0.

Найдем объем памяти для работы Apache:

  

  

  

#### Расчет количества памяти, потребляемого MySQL

Память, требуемую для ядра, составляют следующие кеши:

·  Пул буферов InnoDB innodb_buffer_pool_size. Подробнее Параметр innodb_buffer_pool_size

·  Буфер ключей MyISAM key_buffer. Подробнее Конфигурирование

·  Кеш запросов (Qcache) query_cache_size. Подробнее Конфигурационные параметры

Память, требуемая для каждого воркера, складывается из:

·  read_buffer_size — кэш под полные сканы таблиц (sequential scan);

·  read_rnd_buffer_size — кэш используется для какой-то специфической  Multi-Range Read optimization при сортировке;

·  sort_buffer_size — кэш, в котором выполняется сортировка результатов;

·  thread_stack — размер стека треда;

·  join_buffer_size — кэш, используемый при соединениях (JOIN).

Максимальное количество воркеров определяется директивой max_connections. 

Поэтому максимально потребляемую память можно рассчитать по формуле, написанно выше:

  

  

## Способы ускорения

### Масштабирование системы

**Масштабирование системы** – применяется, если 

- один узел не справляется с нагрузкой на чтение или на запись
- данных так много, что они не помещаются в *storage* на один сервер
- *working set* очень большой и не помещается в память одного сервера.

Способы решения:

- Большое количество чтения:
  - [Кеширование](#кеширование). Имеет смысл, если на 20% данных приходится 80% нагрузки. Способы кеширования:
    - [кеширование статических страниц или статических блоков страниц в nginx](#кеширование-ответов-fastcgi-в-nginx)
    - выделение нескольких кешей. Ключи между кешами распределяются через [consistent hashing](#consistent-hashing). 
  - [Репликация](#репликация). Имеет смысл, если профиль нагрузки плоский.
- Большое количества записи:
  - [Шардирование](#Sharding.md) – масштабирование записи и чтения 

**На уровне кода:**

- если выполняются группы запросов к базе данных, то можно их [запаковать в транзакцию](#ускорение-группы-операций-через-транзакции)

·  Настроить индексирование БД

·  



·  Организовать постоянные соединения между разными частями архитектуры. Постоянное открытие новых соединений нагружает процессор в системе и генерирует дополнительный служебный трафик. 
 Примеры организации постоянных соединений

o  между бэкэндом и базой. Подробнее Постоянные соединения

o  между nginx и бэкэндами. Подробнее keepalive

o  между браузером и веб-сервером. Подробнее Постоянное соединение (keep-alive)

На уровне DevOps:

·  Включение режима keep-alive и настройка параметров этого режима:

\# Сколько времени соединение остается открытым
 keepalive_timeout 300
 \# Максимальное количество запросов по соединению
 keepalive_requests 10000

·  Использование HTTP2. Подробнее про оптимизации HTTP/2

·  Использование кеширования на всех уровнях

·  Использовать gzip сжатие

·   

 

## Причины проблем

·  Клиенты при подключении видят ошибку. Возможно веб-сервер уперся в ограничение памяти или в ограничение количества воркеров. Например, Apache создал большое количество процессов в режиме keepalive (постоянные соединения) и пока эти соединения не закроются, под новые воркеры не хватает памяти. Также возможна проблема асинхронной обработки тяжелых запросов. Асинхронная обработка тяжелых операций

## Типы трафика

Для каждого типа трафика требуется свое аппаратное решение и программное решение, которое учитывает особенности этого трафика. 

При использовании HTTPS требуется более мощный процессор для работы с шифрованными данными.

Основные типы трафика:

·  динамический HTML (dynamic)

·  запросы к API – короткий запрос и короткий ответ, важны малые задержки на ответ (latency)

·  cтатика (static) – большой объем ответа, задержки не очень чувствительны для пользователя, важна высокая скорость передачи данных (сhannel capacity).

·  upload от пользователя – большой объем запроса, также высокая скорость передачи данных (сhannel capacity).

 

## Стандартная архитектура

Архитектура стандартного веб-проекта:

·  перед бекендами размещается несколько балансировщиков в виде nginx на отдельном узле. 

·  балансировка нагрузки на программные балансировщики nginx выполняется через DNS-балансировку

·  nginx проксирует запросы к *.php на Apache. В итоге Nginx сам поддерживает большое количество keep-alive соединений небольшим количеством воркеров за счет эффективной архитектуры. До Apache долетает лишь малое количество очень коротких по времени проксированных запросов от nginx. Ответ Apache вычитывается в буфер nginx и отдается с требуемой клиентом скоростью.

·  отдача статики непосредственно nginx.

·  статика (картинки, видео) и динамика (php-скрипты) разносятся по разным серверам. Запросы к API-приложения, которые обрабатываются серверами динамики, небольшие по размеру и должны выполняться очень быстро. Запросы к статике, наоборот, тяжелые и для них не требуется значительная оперативность. Поэтому для них требуется разная конфигурация серверов по процессору и памяти. Если статика и динамика расположены на одном сервере, тяжелые запросы к статике начнут тормозить легкие оперативные запросы к API.

Стоит ли включать в архитектуру Apache? 

Есть мнения за и против. 

Нюансы:

·  Apache жрет много ресурсов

·  единственное преимущество перед PHP-FPM – файлы .htaccess

·  по подсчетам Apache дополнительно съедает 200-500Мб (тут расчет Расчеты метрик) и процессорное время. Но если честно, то и PHP-FPM жрет память и процессорное время.

## Безопасность

### DDOS-атака

Если обработка какой-либо страницы очень тяжелая (например, поиск), то злоумышленник может организовать DDOS атаку на этот адрес и привести к перегрузке базы данных. 

Также DDOS атака может быть организована случайно ботом, который массово сканирует тяжелые страницы.

Допустимые варианты решения проблемы: 

·  отрубить атакуемый функционал (метод API)

·  заблокировать атакующие IP

·  настроить лимиты на URI. Добавить к функционалу капчу.

·  установить лимиты по количеству коннектов. Минус – у других клиентов возникнут проблемы c загрузкой статики в несколько соединений.

·  настроить netfilter

Пример:

У нас бот яндекса сканировал страницы в ленте комментариев с большим смещением. Это приводило к большому количеству запросов вида:

SELECT * 

FROM comment c 

WHERE ...

ORDER BY ... 

LIMIT 50 OFFSET 25931900

Способ диагностики проблемы:

·  посмотреть в SHOW PROCESSLIST на выполняемые запросы и время их выполнения

·  посмотреть в лог nginx (apache), кто обращается по адресам с тяжелыми страницами

Способ решения проблемы:

·  отрубить возможность обращаться к страницам с такими тяжелыми запросами для данного IP или для всех

·  перезагрузить nginx(apache), чтобы сбросить соединения к базе данных, либо вручную сделать KILL тяжелым запросам.

## Алгоритм масштабирования приложения

Масштабирование любого Web приложения — это постепенный процесс, который включает:

\1.   [Анализ нагрузки](https://ruhighload.com/post/Правильный+мониторинг+).

\2.   Определение наиболее подверженных нагрузке участков.

\3.   Вынесение таких участков на отдельные узлы и их оптимизация.

Этапы развития архитектуры по мере нарастания нагрузки:

\1.   На одном сервере веб-сервер, приложение PHP и БД

\2.   Вынесение БД на отдельный сервер

\3.   Вынесение nginx на отдельный узел, проксирование запросов к скриптам на apache и отдача статики непосредственно nginx. Нужно настроить [deployment (выкатку) приложения](https://ruhighload.com/post/Deployment+большого+проекта) и на сервер Nginx и на сервер с PHP. Сервер PHP обычно называют бекендом.

server {

   server_name ruhighload.com;

 

   root /var/www/ruhighload;

   index index.php;

 

   location ~* \.(php)$ {

​    fastcgi_pass 10.10.10.1:9000;

​    fastcgi_index index.php;

​    include fastcgi_params;

​    fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;

  }

}

\4.   Организация нескольких бэкэндов за nginx, т.к. php начинает тормозить всю систему. Nginx умеет балансировать нагрузку между ними. Для этого Вам необходимо выделить список бекендов в upstream и использовать его в конфигурации:

upstream backend {

  server 10.10.10.1;

  server 10.10.10.2;

  server 10.10.10.3;

}

 

server {

   server_name ruhighload.com;

 

   root /var/www/ruhighload;

   index index.php;

 

   location ~* \.(php)$ {

​    fastcgi_pass backend;

​    fastcgi_index index.php;

​    include fastcgi_params;

​    fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;

  }

}

можно использовать веса бекендов, если какие-то из них мощнее, чем другие:

upstream backend {

  server 10.10.10.1 **weight=10**;

  server 10.10.10.2 **weight=2**;

  server 10.10.10.3 **weight****=4**;

}

\5.   Кэширование. Например, для хранения сессий. Memcache поддерживает несколько серверов, путем добавления через addServer. (консистентное хеширование). 

Этапы развития БД при масштабировании: 

·  репликация для масштабирования чтения 

·  функциональное секционирование. Например, для системы блогов разбить данные на три части: пользователи, сообщения и комментарии. Их можно поместить на разные узлы (вначале это может быть сервер, а потом мастер-слейв), а соединение таблиц выполнять на уровне приложения. 

·  шардирование. Например, секционирование сообщений и комментариев (т.к. их больше и они длиннее) по идентификатору пользователя, узел можно организовать в топологии мастер-мастер для надежности. 

## Типы ресурсов

·  Процессор

·  Память (RAM)

·  Disk IO

·  Сеть

## Балансирование нагрузки

Балансировка нагрузки (load balancing [ləʊd ˈbælənsɪŋ]) — механизм распределения запросов между несколькими серверами с целью оптимизации использования ресурсов, сокращения времени обслуживания запросов, горизонтального масштабирования, а также обеспечения отказоустойчивости (резервирования).

### Использование балансировщик

Балансировщик нагрузки (load balancer) — машина или программа, основная функция которой — определить на какой сервер послать запрос. Балансировщики могут быть сконфигурированы в отличии от dns балансирования. Примеры балансировщиков: NGINX, HAProxy, Cisco CSS и т.п.

Преимущества:

·  Умеют периодически отслеживать доступность бэкендов и удалять из пула недоступные серверы. 

·  Умеют перебирать по порядку бекенды, пока не найдет доступный бекенд (подробнее Модуль upstream)

Недостатки программных балансировщиков:

·   представляют собой единую точку отказа и в случае падения балансировщика – падает вся система. 

·  при наращивании нагрузки и горизонтальном масштабировании становятся узким местом в системе. Трафик упрется в производительность и полосу пропускания узла, на котором размещен load balanсer. 

Способ решения этих проблем – применение DNS-балансировки.

### DNS-балансировка

Принцип работы: DNS сервер (возможно даже установленный у нас) отдает несколько IP по одному доменному имени. Клиент выбирает случайным образом один из IP адресов. По «закону больших чисел» нагрузка равномерно размазывается по нескольким узлам.

В случае если выбранный браузером IP адрес не отвечает по 80 порту, то после истечения таймаута, браузер прозрачно для пользователя выбирает другой IP и делает запрос на него. 

Понятие TTL. Для DNS-записи в авторитетном DNS-сервере (authoritative) устанавливается параметр TTL (Time to live). Когда неавторитетный DNS-сервер получает в результате опроса у авторитетного DNS-сервера какую-то DNS-запись, он кеширует ее на время, указанное в TTL. При разрешении имени для той же DNS-записи с помощью кеширующего неавторитетного DNS-сервера до истечения срока действия TTL, кеширующий DNS-сервер будет отвечать ранее закэшированной DNS-записью, а не снова получать ее от авторитетного DNS-сервера.

Время задаётся в секундах, типичное значение составляет 86 400 секунд, то есть 24 часа. Это означает, что при изменении записи DNS, вплоть до 24 часов после изменения, DNS-серверы по всему миру могут выдавать старые данные из кеша, пока он не будет обновлён. Более короткие TTL могут сильно нагрузить авторитетный DNS-сервер и имеют смысл на случай изменения адреса критически важных сервисов.

Администратор кэширующего DNS-сервера может установить жесткий TTL, который не будет зависеть от TTL авторитетного DNS. Поэтому установка TTL на авторитетном DNS-сервере не может гарантировать, что все кеширующие DNS-серверы будут иметь новые DNS-записи после истечения срока действия TTL

Ограничения. Ответ от DNS сервера приходит по протоколу UDP в пакете размером 512 байт. В зависимости от количества служебных данных максимальное количество IP адресов при DNS-балансировке находится в диапазоне 4-25 штук. Как правило балансируют 4-6 адресов.

Преимущества:

·  низкая стоимость балансировки, т.к. не требуется никакого программного/аппаратного обеспечения

·  отсутствует единая точка отказа.

## Проблемы множества бекендов

Когда один бекенд с PHP не справляется с нагрузкой, добавляют еще несколько бекендов и распределяют нагрузку между ними каким-либо методом балансирования нагрузки. Помимо снижения нагрузки на один бекенд, это повышает отказоусточивость системы – при выходе из строя любого бекенда, остальные бекенды могут взять на себя его нагрузку.

При переходе к распределенной обработке запросов на множестве бекендов архитектура приложения должна быть перестроена. Результат обработки запроса не должен зависеть от того, на каком сервере он обработан (в пределе stateless-код, но так не бывает, чтобы код вообще без состояния).

Проблема обработки файлов

При наличии нескольких бекендов возникает проблема синхронизации файлов при одновременной их обработке с нескольких бекендов. 

Варианты решения:

·  у нас – все запросы загрузки и обработки файлов направляются балансировщиком на один бекенд (adm1). С этого же сервера файл после изменения отправляется на сервера статики, откуда раздается клиентам. Если он нужен на других серверах динамики, то его можно синхронизировать через rsync.

·  отказаться от локального хранения файлов и хранить файлы в облаке. Наиболее популярны распределенные файловые хранилища с протоколом S3 (например, Amazon S3, Ceph)

### Проблема обработки сессий

Если на одном бекенде в локальной памяти поднята сессия, а следующий запрос балансировщик отправил на другую машину, то новая машина не будет видеть данную сессию. 

Nginx как балансировщик поддерживает несколько механизмов, позволяющих управлять балансировкой, и отправлять следующий запрос на ту же ноду, что и предыдущий (подробнее Методы балансировки):

·  ip_hash

·  hash

·  sticky session (в коммерческой версии).

Этот механим называется постоянство сессий (session persistence) или липкость (stickiness [ˈstɪkɪnəs]). Недостаток такого механизма: балансировщик, который и так является узким местом системы, занят еще и обработкой состояния о том, какой запрос каким сервером обрабатывается.

Другой вариант, не нагружающий балансировщик: хранить сессии в распределенной кеширующей системе (база данных, memcached). В этом случае не имеет значения, на какой из бекендов приходит запрос.

## Взаимодействие с внешним сервисом

Бекенды всегда взаимодействуют с тяжелыми внешними сервисами: базы данных (MySQL), поисковые движки (Sphinx). В SOA-архитектуре вообще выделены отдельные внешние сервисы под каждую задачу. И в любой момент времени один из сервисов может начать тупить.

Еще более опасно, если обращение идет к стороннему внешнему сервису в сети с непредсказуемым временем исполнения. Например, так:

$data = file_get_content("https://path/to/resource");

Если не предусмотрена защита от тупки такого внешнего сервиса, в результате тупки возникает каскадный отказ системы:

·  ↑вырастает время выполнения одного запроса

·  ↑вырастает количество активных воркеров

·  бекенд упирает в максимальное количество воркеров

·  новые запросы, даже не связанные с тупящим ресурсом, перестают обрабатываться

Способы диагностики проблемы: 

·  профилирование через какой-то инструмент, показывающий запросы к внешним ресурсам (newrelic, zabbix?)

·  просмотр сетевых соединений через unix-утилиты (netstat, tcpdump)

В зависимости от типа сервиса, взаимодействие с сервисом может выполняться:

·  асинхронно (гораздо проще)

·  синхронно (сложнее)

### Асинхронная обработка

Более простой вариант, т.к. тяжелое взаимодействите с сервисом можно выполнить в фоновом процессе. Применение любого вида асинхронной обработки сразу снимает проблему, однако не для каждого сервиса это подходит. Например, асинхронно невозможно ображаться к базе данных.

Способы решения проблемы: 

·  если данные только читаются и редко изменяются, то их можно закешировать

·  если данные отправляются в сеть, то это нужно делать асинхронно через Message Query. 

#### Особенности использования cron

Обработку тяжелых запросов можно выполнять асинхронно с запуском по времени через cron.

Необходимо следовать советам:

·  в cron помещать вызов PHP через CLI, и ни в коем случае не делать обращение к скрипту через веб-сервер. Т.к. это забирает ресурсы веб-сервера и уменьшает количество доступных воркеров.

·  внимательно следить за временем выполнения скриптов с отключенным лимитом времени set_time_limit(0), т.к. запрос может подвиснуть и жрать ресурсы системы

·  нужно ставить блокировки на повторный запуск процедуры в cron до завершения предыдущего запуска (утилита setlock запускает другую программу и одновременно создает lock-файл, который служит мьютексом и защищает от повторного запуска)

### Синхронная обработка

Если критично обращаться к ресурсу в контексте запроса, то нужно хотя бы ставить таймаут.

Эффективный способ замаскировать проблему с сервисом – не показывать тот блок на странице, за который этот сервис отвечает. Как только запросы к сервису начнут проходить, блок на странице снова отобразиться. Некоторые сервисы критичны для всего сайта (например, база данных, кеши), в случае их падения пользователю необходимо вывести понятную ошибку (типа, мы в курсе и чиним).

#### Сircuit brеaker 

Гораздо эффективнее между удаленным сервисом и бекендом разместить circuit breaker – проксю, которая бы вырубала тупящий сервис при срабатывании какого-нибудь условия. 

Circuit breaker может быть реализован как:

·  модуль в коде на PHP

·  отдельно стоящий демон, который проксирует через себя запросы.

Для Circuit breaker задаются порог предупреждения (warning threshold) и порог отключения (disable threshold). Когда количество тормозящих воркеров достигает disable threshold (например, 10%) circuit brеaker перестает отправлять запросы к сервису и сразу отдаёт бекендам ошибку, как будто бы сервис лежит. После этого воркер бекенда может отправить запрос на резервный сервис (например, на другой slave DB).

Время от времени Circuit breaker автоматически пропускает запрос от какого-нибудь воркера, чтобы посмотреть, не ожил ли всё-таки сервис. Если он отвечает адекватно, то мы снова включаем его в работу.

## Приемы у нас

### Изменения в структуру таблицы с логами

**Задача.** Требуется внести изменения в структуру таблицы с логами, которая находится под нагрузкой. 

**Решение.**

·  Создать временную пустую таблицу для логов 

·  Переименовать таблицы так, чтобы временная таблица стала на место основной.

·  Сделать изменения на основной таблице.

·  Снова поменять их местами

·  Перенести из временной таблицы данные в основную.

### Запросы висят на табличной блокировке

**Задача.** В результате изменения структуры таблицы возникла табличная блокировка, запросы висят на ожидании доступа к таблице.

**Решение.** Сделать правки в коде, если это возможно, чтобы переключить запросы на другую таблицу или хотя бы отключить обращения к таблице. Плюс перезапустить Apache.

## Хранение статики

Для хранения фотографий можно использовать:

- облачный storage

- коробочное решение

- хранить у себя в кластере

- сеть хранения данных (Storage Area Network, SAN) — подключеник внешних устройств хранения данных (дисковые массивы, оптические приводы) к серверам таким образом, чтобы операционная система распознала подключённые ресурсы как локальные.

### Хранение статики в своем кластере

Берем кластер из нескольких машин для хранения изображений. 

Применяем схему с *virtual shard*'ами. Организуем два *mapping*'а: 

- картинка → `vshard`. Один из вариантов: хранить всех картинки одного пользователя в одном *vshard*, для этого нужно отображать `user_id` → `vshard`. Можно использовать любые способы задания [*sharding function*](). 
- `vshard` → реальный `shard` (физический узел). Если количество `vshard` и `shard` небольшое, то это отображение может задаваться статически вручную ([table function](#Sharding.md#динамическое-недетерминированное-table-function)).

Для серверов статики обычно характерен небольшой объем входящего трафика, при большом объеме исходящего трафика. Поэтому необходимо масштабировать чтение статики.

Часто имеет место следующий *case*: только что залитые фотки очень горячие, а через какой-то момент времени они перестают запрашиваться. Они составляют небольшой горячий *dataset* (рабочее множество). Этот *case* соответствует ситуации, когда оптимально применение [кеширования]().

*Photocache* – отдельная машина с быстрыми SSD дисками, которая кеширует картинки и при *miss* перенаправляет запросы в *storage*. Для этого на *photocache* установлен *nginx*, который делает `proxy_pass` на *storage* при *miss*.

Общая схема запроса картинки: пользователь → *photocache* → *storage*.  

В photocache все картинки разделены на:

- *hot cache* – папка, в которой хранятся активно запрашиваемые картинки
- *cold cache* – папка, в которую переносятся картинки из *hot cache*, после того как снижается количество *request*’ов к ним. 

В *photocache* *nginx*  ведет `access.log`. В фоне работает *demon*, который считает статистику по доступу к картинкам. На основе статистики *demon* перемещает картинку между cach'ами или удаляет. 

Жизненный цикл картинки в *photocache*:

- картинка попадает в *hot cache*
- при снижении количества запросов картинки перемещаются из *hot cache* в *cold cache*.
- при снижении количества запросов картинки удаляются из *cold cache*.

 

<u>Высокая доступность</u>

Если требуется высокая доступность, то необходимо устранить точки отказа. 

Для данной архитектуры:

- пустой резервный *photocache*, который включается в работу и прогревается при отказе одного из *photocach*'ей.
- дублирование всех storag'ей. При этом основной и резервный *storage* могут работать параллельно на чтение (аналогично *replication*). Дублирование картинок выполняется в фоновом процессе.

Для обработки фоновых задач (обработка картинка, копирование на резервный *storage*) следует использовать *Message broker*.

### Особенности картинок

<u>Выбор формата:</u>

- `jpg` – с потерей качества, для сложных изображений, для фотографий
- `webs` – лучше `jpg`, но поддерживается не всеми браузерами
- `png` – без потери качества, для иконок
- `gif` – кодирование по палитре, поддержка анимации

<u>Структура для хранения:</u>

Необходимо использовать древовидную структуру из папок. Это позволит избежать ограничение на количество файлов в каталоге и тормозов системы при работе с такими каталогами. 

Нужно разделить для удобства все картинки по типам: `avatars`, `posts`, `comments`. 

Внутри этих папок наиболее удобно делить файлы в соответствии с бизнес логикой. Например, хранить в виде: `./yyyy/mm/dd/123.jpg`. Так проще удалять старые картинки и делать инкрементальный бекапы.

<u>Порядок загрузки изображения</u>

- уменьшить размер до минимально допустимого, чтобы не хранить огромные фотографии

- удалить метаданные

- преобразовать в дополнительные форматы (`.webp`). 

  При запросе пользователя, необходимо выполнить проверку поддержку `.webp` браузером и в зависимости от этого отдать `.webp` или `.jpg`:

  ```nginx
  server {
  	...
  	location ~* ^/.+\.(jpg|jpeg)$ {
  	  if ($http_accept ~* "webp")    {
  	      rewrite (.+) $1.webp;
  	  }
  	}
  ...
  }
  ```

### Создание обработанных картинок (tn'ок)

На *storag*'ах и *photocash*'ах  простаивает CPU, т.к. основная нагрузка на сеть и на диски. Поэтому CPU может быть загружен созданием обработанных картинок (например, генерацией *thumbnail*'s):

- генерацией *tn*'ок
- перекодирование изображений в более компактные форматы (webp или progressive jpeg)
- resize, crop, накладывание watermark.

Способы создания *tn*'ок.

<u>1 подход</u>

С хранением (кешированием) *tn*'ок для всех картинок. Генерация выполняется в момент загрузки  или после загрузки в фоне. 

Имеет смысл:

- если все изображения примерно одинаково горячие
- не ограничены в объеме storag'ей
- CPU storag'ей не справляют с нагрузкой по генерации thumbnails на каждый request

Особенности:

- ↑ *data size*, ↓ *CPU load*. 
- Ограничены некоторым набором размеров (*tn*'ок) 
- Длительный процесс генерации, если требуются новые *tn*'ки

<u>2 подход</u>

Не генерировать thumbnails заранее и не хранить их в storage. Генерация выполняется налету, в момент *request*'а. 

Имеет смысл:

- если все изображения примерно одинаково горячие
- ограничены в объеме storag'ей
- CPU storag'ей справляют с нагрузкой по генерации thumbnails на каждый request

Особенности:

- ↓ *data size*, ↑ *CPU load*.  
- достаточно иметь несколько *tn*-ок (маленькую, среднюю и большую), а для остальных размеров делать *resize*. 
- можем получить любой точный размер, который запрошен в URL. Это особенно актуально для мобильных версий с невысокой скоростью интернет.
- добавление новых размеров не требует процедуры генерации *tn*-ок для всех картинок.

<u>3 подход</u>

Гибридный подход. С генерацией *tn*'ок в момент первого *request* и кешированием картинки в файловой системе. Объединение преимуществ двух предыдущих подходов. 

- меньше *data size*, чем в 1 случае, и меньше *CPU load*, чем во 2 случае 
- загрузка CPU только в момент генерации *tn*'ки в первый раз
- добавление новых размеров не требует процедуры генерации *tn*-ок для всех картинок.

Желательно перед добавлением новой *tn*'ки "прогреть" кеш – запустить генерацию *tn*'ок на небольшом количестве *request*'ов.

Особенно важно избежать "проблемы стаи собак" (dog-pile effect, так же cache stampede) – когда множество запросов будет сделан к одним и тем же "горячим" thumbnails, который в тот момент еще не будут закешированы. Дополнительно, эту проблему можно решить, используя распределенную блокировку через memcache, чтобы одну картинку генерировал только один request, а остальные ожидали его окончания.

<u>Разновидности 3 подхода</u>

1. с генерацией *tn*'ок в момент первого *request*, но кеширование выполняется по условию. Усложнение 3 случая (требуется продуманное условие). Например, если по статистике картинка запрашивает часто (требуется сбор статистики), или картинка относится к свежему посту (не требуется сбор статистики).  
   - меньше *data size*, чем в 4 случае, при правильном условии

Способы генерации:

- Наиболее быстро это делает Nginx+LuaJIT.
- с помощью PHP

https://vk.com/away.php?to=https%3A%2F%2Fm.habr.com%2Fru%2Fpost%2F77873%2F&cc_key=

Павел 8:47

ngx_http_image_filter_module — для ресайза изображений;ngx_http_proxy_module — для кеширования;ngx_http_secure_link_module — для защиты от спама;

В итоге дополнительные изображения можно забирать по ссылкам:

myproject.ru/preview/i[md5]/[path_to_image]myproject...
RU-CENTER - регистрация доменов, домен РФ,..
www.nic.ru
Павел
Павел 11:36

Да, три действия, только один раз в сутки, на не при каждом запросе.
Павел
Павел 19:21

У картинки меняется название

большая часть из которых к тому же больше никогда не будет запрошена.



# Интересные задачи и фишки

## Наши задачи

Тест серверов на время ответа с помощью curl

Использование блокировок в БД

Требовалось, чтобы один набор данных обрабатывался только одним воркером. Для этого испольовалась InnoDB и exclusive-lock чтение данных с помощью:

SELECT ... FOR UPDATE

В этом случае остальные воркеры ставились в ожидание на блокировке и не могли одновременно читать эти же данные.

 

## Фишки вконтакте

в вопросе кэширования.

При вставке новых данных, на которые предполагается высокая нагрузка в ближайшее время, например новый пост в ленте пользователя, имеет смысл эти данные **предварительно закешировать** и отправить пост в ленту только после кеширования. 

Можно после изменения данных не делать кеш сразу не валидным, а поставить задание и записать задание в кеш позже, некоторое время показывая **просроченные данные** из кеша. 

При сохранении подряд нескольких ключей в кеш нужно случайно **варьировать время хранения** для размазывания нагрузки на время TTL (жизни ключа). 

**Конфигурации приложения** можно хранить: в файлах ini, json, yml; в PHP коде; во внешних системах, которые могут по запросу прислать конфиг. Реализация последнего варианта: конфиг пишется в master ноду, на каждом сервер динамики поднята slave нода, куда реплицируется конфиг. 

Для распределения нагрузки по записи в один ключ memcache необходимо воспользоваться **шардированием ключа**, например для реализации счетчиков, подсчета посещаемости. Инкрементируется не один счетчик, а например 10 тысяч ключей, при этом получение значения счетчика предполагает multi get всех ключей и складывание в коде. 

Если не требуется значительная точность, то можно **инкрементировать счетчики с вероятностью**, например, 1/10, снижая нагрузку на кеш в такое же количество раз. При чтении значения счетчика необходимо умножить результат на коэффициент вероятности, получая значение близкое к реальному. 

Улучшения в результате изменения архитектуры приводят либо к появлению новых фич (фичатим), либо оптимизации использования железа (архитектурная команда). 

Соцсеть - это не банковский процессинг и иногда можно пожертвовать стопроцентной надежностью и потерять немного данных или уйти в downtime.За счет этого можно сэкономить денег и показывать пользователям меньше рекламы, достигнув разумных компромиссов надежность/стоимость.

 

## Badoo



#### Надежность хранения

##### RAID

Можно использовать аппаратное дублирование даннх через RAID массивы. 

Минусы подхода:

·  задержки при восстановлении поврежденных данных. Например, на восстановление диска из RAID5.

·  в RAID5 скорость чтения/записи равна скорости самого медленного диска

·  система дисков жестко связана. Если глючит один диск – глючит вся система.

##### Ручная репликация статики

Удобней использовать ручную репликацию статики на несколько серверов. 

Плюсы:

·  отдельные узлы для хранения независимы, при выходе из строя узла системы остается доступной

·  нагрузку гораздо проще горизонтально масштабировать

Информация о синхронизируемых фото размещается в очереди, например, через mysql. Т.к. теперь фото читается с основного диска, как пользователями, так и backup разделом. Ставим перед ними буферный диск небольшого размера SSD. Фото вначале попадает в буфер, а потом по event из очереди копируется на основной и backup раздел.

Фотографии лучше делать immutable, не переписывая измененные фото, а создавая новые файлы без хранения версий. 

Возможно использование распределенных файловых хранилищ – ceph + s3 api, minio.

Файлы должны раскладываться на диске по папкам двух уровней вложенности, чтобы преодолеть ограничение на количество файлов в папке. 

### Версионирование API 

Хороший API всегда версионирован. И если нарушается обратная совместимость, то меняется мажорная версия, например, 1.0.0., 2.0.0 и т.д.

Однако у этого подхода есть ряд недостатков:

·  Любое существенное изменение функционала требует инкрементации мажорной версии, причем в старшей мажорной версии должны быть реализованы изменения всех младших, хотя хотелось бы чтобы разные изменения не зависили друг от друга. Например поэтому нельзя выкатить клиент с функциональностью старшей версии без реализованной функциональности младшей версии.

·  Не всем клиентам нужен одинаковый функционал (например, не все разрешают работать с камерой из браузера), поэтому не для всех клиентов мобильных устройств нужно учитывать появление новой версии

·  изменения протокола под AB тесты не соответствуют версиям основных изменений, это отдельное несовместимое изменение протокола. Т.е. протокол зависит не от версии клиента или версии API, а от внутренних настроек.

Лучший вариант – идентифицировать отдельно каждого клиента и предлагать ему такие данные, которые соответствуют его типу. Первый способ – передавать при каждом запросе клиента на сервер тип клиента и его версию. Однако этот способ очень сложен в поддержке если много различных улучшений и тогда объект на сервер, отвечающий за версионность очень сильно разрастается. Также нужно согласовывать между клиентом и сервером, что клиент поддерживает на данный момент в какой версии, а что перестал поддерживать, нельзя выкинуть функционал из клиента без согласования с сервером.

Версионирование – это решение проблемы изоляции функционала (поддерживаемого от неподдерживаемого). Поэтому идея алгоритма следуюшая: клиент на старте отправляет на сервер набор тех фич, которые он хочет поддерживать, сервер делает проверку этих фич на доступность данному клиенту и отвечает ему отфильтрованным списком допустимых фич и клиент после этого включает нужные фичи. Плюсы подхода:

·  старые клиенты не знают про новые фичи и не запрашивают их

·  можно распараллелить разработку клиента и сервера, т.к. клиент запрашивает только те фичи, которые он поддерживает

·  можно собирать статистику по использованию клиентами фич и выкинуть неиспользуемые вообще

·  можно на сервере переключать функциональность для двух групп при AB тестировании

·  можно протестировать фичу на небольшой группе пользователей, не усложняя архитектуру системы (не добавляя индексы например), и при успешности фичи можно ее допилить для highload.

Минусы:

·  избыточное количество передаваемых данных и обработки на сервере, особенно для постоянно используемых всеми фич.

·  количество фич постоянно растет, каждая мелкая правка – это фича. Способы решения: удалять неиспользуемые фичи, удалить фичи которые используют уже все клиенты, force update принудительно обновить старые клиенты когда там мало пользователей.

### Ручная репликация данных между бекендами

В Badoo вручную реализована репликация данных между бекендами. Репликация может быть реализована двумя способами:

·  синхронный

·  асинхронный

Наиболее эффективный – асинхронный способ, работающий в режиме eventual consistency. Для того чтобы не возникало проблем с несогласованностью данных на бекендах при обработке нескольких запросов одного пользователя, применяются sticky-сессии. Это гарантирует, что все запросы одного пользователя идут на один бекенд.