

Cервис кэширования данных в оперативной памяти на основе хеш-таблицы.

Поддерживает распределение ключей по нескольким серверам в зависимости от хэша ключа. Вычисление хеша от ключа данных и выбора сервера для хранения ключа выполняет клиентская библиотека. 

Ситуация сбоя сервера трактуется как *cache miss*, что позволяет повышать отказоустойчивость комплекса за счет наращивания количества *memcached* серверов и возможности производить их горячую замену. 

При нехватке памяти, ключи из кеша удаляются согласно политике [LRU]()

Изначально разработан под *Livejournal*.

Существуют:

- *Memcached* – сам кеширующий сервер.

- *memcached* — расширение PHP для работы с сервером.

- *memcache* — расширение PHP для работы с этим сервером, используется чаще всего. *Memcache* ограниченней *Memcached* и не использует возможности сервера *Memcached* в полную силу, поэтому *Memcache* легче и производительней *Memcached* (примерно на 10%).

## Установка 

1. Установка сервера:

   `brew install memcached`

2. Установка `zlib`

   `brew install zlib`

3. Может быть нужна установка `pkg-config`????

   ```bash
   brew install pkg-config
   ```

   

4. Установка через `pecl install memcache` не работает.

   Требуется ручная установка:

   ```bash
   pecl download memcache
   open memcache-4.0.5.2.tgz  
   cd memcache-4.0.5.2/memcache-4.0.5.2
   phpize
   ./configure --with-zlib-dir=/usr/local/Cellar/zlib/1.2.11
   make
   sudo make install
   ```

5. Добавить в `php.ini`

   ```conf
   extension=memcache.so
   ```

   



### Опции *config* файла

Путь к *config* файлу /etc/memcached.conf

`-t threads` – число потоков, по умолчанию `4`. 

### Требования к ключу в Memcached

Ключ можно конструировать следующими способами:

·  в строковом человекопонятном формате ‘user_158

·  в обертке над memcached можно делать над ключом операцию:

$key = md5(serialize($options))

### Кластеризация в memcached (consistent hashing)

Может испольоваться для распределения нагрузки и достижения отказоустойчивости. Общий объем кэша будет равен сумме объемов кэшей всех memcached, входящих в кластер. Процесс memcached может быть запущен на сервере, где слабо используется процессор и не загружена до предела сеть.

При работе с кластером каждый сервер обрабатывает часть общего массива ключей проекта. При отказе сервера данные с части ключей будут утеряны и заново перегенерятся на других серверах. В случае необходимости важные ключи можно дублировать на нескольких серверах.

Для добавления серверов используется функция `addServer`. 

Алгоритм consistent hashing реализуетеся не в сервере, а на уровне клиента memcached в языке программирования, однако в каждом языке реализация своя, что приводит к несовместимости хэширования, невозможности доступа к кластеру из разных языков. 

Более подробно см. Консистентное кеширование

### Атомарность операций

Все одиночные запросы атомарны в силу корректных внутренних блокировок при нескольких потоках. Т.е. при записи значение ключа никогда не будет смесью двух записей. Однако в случае нескольких операций, например, считать значение, инкрементировать, записать, возможно возникновение состояния гонки.  Решение проблемы – использование синхронизационных примитивов (семафоров, мутексов и т.п.), однако в memcached они отсутствуют. Другим вариантом решения задачи является использование встроенных операций, которые заменяют неатомарную последовательность get/set, например, incr/decr, обеспечивающие атомарное увеличение (уменьшение). Атомарными являются также append/prepend (добавляет строку в конец/начало существующей записи), add и replace (задать/заменить значение ключа). 

### Счетчики

Реализация через обновление поля в БД не будет работать на высокой нагрузке. 

Остается воможность сбора статистики в memcache с последующим обновлением счетчика в базе данных. 

#### Счетчик через логгирование

Если не требуется отображение значения в «реальном времени», то можно реализовать через логирование.

Например, если требуется логгировать количество показов блока на сайте возможны варианты:

·  если блок вставляет скрипт на php, то он пишет это в лог (хотя можно сразу счетчик инкрементировать в кеше)

·  если эти блоки подгружает ajax-ом js, то он может сделать также запрос на сервер, который попадет в access log (хотя лучше запросом сразу инкрементировать счетчик, у нас так работает подсчет показов видео)

·  можно в каждый блок вставлять картинку 1х1 и считать по логам число запросов к этой картинке. Это более универсально, но зато забивает канал клиента лишними запросами (хотя также проще сразу логгировать, так реализован подсчет статистики в рассылках).

#### Счетчик пользователей

Для показа текущего значения счетчика просмотров следует выполнить операцию  incr над ключом. Если выполнение было успешным, это означает, что соответствующий ключ находится в memcached, мы просмотр засчитали, также получили новое значение счетчика как результат операции incr, которое мы можем показать пользователю. Если же операция incr вернула ошибку, то ключ счетчика в данный момент отсутствует в memcached, мы можем выбрать в качестве начального значения число просмотров из базы данных, увеличить его на единицу, и выполнить операцию set, устанавливая новое значение счетчика. При последующих просмотрах ключ уже будет находиться в memcached, и мы будем просто увеличивать его значение с помощью incr. В этой схеме присутствует состояние гонки (race condition). Если два клиента одновременно обращаются к счетчику, одновременно обнаруживают его отсутствие, и сделают две операции set, мы потеряем один просмотр.  В случае необходимости можно воспользоваться блокировками в memcached. Также можно воспользоваться операцией add вместо set, чтобы отследить ситуацию, если ключ успеет добавить другой клиент. 

#### Счетчик пользователей онлайн

Мы хотим рассчитать, сколько уникальных сессий (пользователей) обратилось к нашему сайту за последние 5 минут. Уникальность обращения пользователя с данной сессией в течение 5 минут можно отследить, сохраняя в сессии время последнего засчитанного обращения, если прошло более 5 минут – значит это новое (уникальное) обращение.

Выделим в memcached шесть ключей с именами, например, c_0, c_1, c_2, …, c_5. Текущим изменяемым ключом мы будем считать счетчик с номером, равным остатку от деления текущей минуты на 6 (например, 4). Если incr вернет ошибку (счетчика еще нет), установим его значение в 1 с помощью set, обязательно указав время жизни 6 минут. Значением счетчика онлайнеров будем считать сумму всех ключей, кроме текущего (т.е. c_0, c_1, c_2, c_3 и c_5).

Когда наступит следующая минута, текущим изменяемым ключом станет ключ c_5, при этом его предыдущее значение исчезнет (т.к. он был создан 6 минут назад с временем жизни те же 6 минут). Значением счетчика станет сумма ключей c с_0 по c_4, т.е. только что рассчитанное значение ключа с_4 уже начнет учитываться в отображаемом значении счетчика. Принцип аналогичен тому, как прорисовывается кадр в видеоконтроллере (двойная буферизация).

Такой счетчик может быть построен и на меньшем числе ключей. Минимально возможными для данной схемы являются два ключа: один обновляется, значение другого показывается, затем по прошествии 5 минут счетчики меняются местами, при этом тот, который только что обновлялся, сбрасывается. В приведенной схеме с многими ключами обеспечивается некоторое «сглаживание», которое обеспечивает более плавное изменение счетчика в случае резкого притока или оттока посетителей.

**Вариант:** Вести учет в счетчике в shared memory. Уникальность учета пользователя проверять через timestamp в сессии. Каждый сервер знает только свое количество пользователей online. Каждые $timeout минут веб-приложение сбрасывает счетчик в БД (можно в таблицу MEMORY) или memcache в виде кортежа {‘server_id’: $server_i_id, ‘online’: $local_online }. Общее количество пользователей получается суммированием в БД или кеше.

#### Учет пользователей онлайн

**У нас.** При каждом запросе зарегистированного пользователя в его сессии проверяет поле, которое хранит время последнего обновления его статуса-онлайн (хранится в кеше). Если поле отсутствует или время последнего обновления вышло за пределы (60 сек), то установить текущее время в качестве времени последнего обновления и запустить процедуру сохранения статуса-онлайн в кеш. Через replace в ключ «_{$user_id}» делается попытка перезаписать время обновления статуса-онлайн, если информацию о статусе-онлайн отсутстствует запускается следующая процедура:

·  Ключ «_{$user_id}» с timestamp статуса-онлайн пользователя записывает в кеш

·  определяется номер бакета, где будет храниться информация о наличии кеша со статусом-онлайн пользователя bucket_id=user_id%bucket_size

·  стартует критическая секция (реализована через мемкеш)

·  загружается из памяти бакет «_{$bucket_id}»

·  в него дописывается добавляемый user_id

·  завершается критическая секция

Схема с хранением списков user_id, которые онлайн, с шардированием этих списков по бакетам, позволяет сделать сброс данных о пользователя-онлайн в базу и вывести список пользователей онлайн.

**Вариант:** Если не требуется сбрасывать статус пользователя в БД, то проще делать его оффлайн удалением ключа не перебором всех ключей из бакетов по крону, а просто ключу "_{$user_id}" поставить expire=5 мин. 

**Вариант:** идентифицировать пользователей по IP-адресу

**Вариант:** делать учет пользователя не в момент обновления страницы, а по AJAX делать запросы с интервалом в 5 секунд.

 

### Требования к ключам и данным: 

·  длина ключей максимум 250 байт;

·  запрещены символы ord(char) < 33 и с ord(char) >= 127 (в том числе пробел=32);

·  объем данных, который можно хранить под одним ключом, ограничивается 1 Мб. 

### Выборки в кеше

Есть выборка из БД, которая используется на многих страницах, сама выборка является относительно сложной, её вычисление заметно нагружает backend (БД). 

Способы решения проблемы.

#### Без грязного кеша

Грязный кеш – кеш с устаревшими данными, которые не соответствуют актуальным данным в хранилище.

##### Обновление в realtime

Т.е. не запускается дорогой запрос для полного перестроения кеша, а кеш пересчитывается при каждом обновлении данных.

#### С возможностью грязного кеша

##### Построение по request'у

Метод подходит для кеша в памяти, но не подходит для кеша на диске (в БД), т.к. медленный.

В какой-то момент времени ключ в memcached будет удален, в этот момент несколько frontend’ов (несколько, т.к. выборка часто используется) обратятся в memcached по этому ключу, обнаружат его отсутствие и попытаются построить кэш заново, осуществив выборку из БД. То есть в БД одновременно попадет несколько одинаковых запросов, каждый из которых заметно нагружает базу данных, при превышении некоторого порога запрос не будет выполнен за разумное время, еще больше frontend’ов обратятся к кэшу, обнаружат его отсутствие и отправят еще больше запросов в базу данных, с которыми база данных тем более не справится. В результате сервер БД получил критическую нагрузку, и «прилёг». Такая ситуация называется «проблема стаи собак» (dog-pile effect или cache stampede, паническое бегство кеша). 

###### В критической секции

При отсутствии данных в кэше процесс, который хочет их загрузить, должен захватить лок, который не даст сделать то же самое другим параллельно выполняющимся процессам. 

Чтобы обслужить процессы, которые ожидают перестроение кеша захватившим блокировку процессом, – не ограничиваем время жизни ключа с кэшом в memcached. Ключ будет там находиться до тех пор, пока не будет вытеснен другими ключами. Но вместе с данными кэша мы записываем и реальное время его жизни, например:

{

  годен до: 2008-11-03 11:53,

   данные кэша:

  {

​    ...

  }

}

\1.   Получаем доступ к кэшу cache, его срок жизни истёк.

\2.     Пытаемся заблокироваться по ключу cache_lock.

·    Не удалось получить блокировку:

·    вернуть старое значение ключа;

​               или

·    ждем снятия блокировки

·    не дождались: возвращаем старые данные кэша;

·    дождались: выбираем значения ключа заново, возвращаем новые данные (построенный кэш другим процессом).

·    Удалось получить блокировку:

·    возвращаем false, как будто в кеше ничего нету. Процесс перестраивает кеш.

###### Вероятностный метод

Данные в кэше обновляются не только при отсутствии, но и с какой-то вероятностью при их наличии. Это позволит обновлять их до того, как закэшированные данные «протухнут» и потребуются сразу всем процессам.

Для корректной работы такого механизма нужно, чтобы в начале срока жизни закэшированных данных вероятность пересчёта была небольшой, но постепенно увеличивалась. Добиться этого можно с помощью алгоритма XFetch, который использует экспоненциальное распределение. Его реализация выглядит примерно так:

**function** xFetch($key, $ttl, $beta = 1)
 {
   [$value, $delta, $expiry] = cacheRead($key);
   **if** (!$value || (*time*() - $delta * $beta * *log*(*rand*())) > $expiry) {
   $start = *time*();
   $value = recomputeValue($key);
   $delta = *time*() - $start;
     $expiry = *time*() + $ttl;
     cacheWrite(***key\***, [$value, $delta, $expiry], $ttl);
   }

   **return** $value;
 }

где

$ttl — это время жизни значения в кэше, 

$delta — время, которое потребовалось для генерации кэшируемого значения,

$expiry — время, до которого значение в кэше будет валидным, 

$beta — параметр настройки алгоритма, изменяя который, можно влиять на вероятность пересчёта (чем он больше, тем более вероятен пересчёт при каждом запросе).

Для этого алгоритма существует вероятность параллельных обновлений, однако она значительно снижается. Чтобы исключить полностью параллельные обновления, можно выполнять вероятностное перестроение кеша в критической секции. 

##### Фоновое перестроение по `cron`

Связано с [1](Highload.md#особенности-использования-cron)

Перестроение кеша происходит в фоновом процессе, который запускается в crontab. 

Особенности:

- Для *in memory* кешей. Построение осуществляется в памяти скрипта и затем сбрасывает в кеш.
- Для кешей в БД. При перестроении таблицы часто требуется, чтобы хранящиеся в них данные на время этой операции оставались доступными. Этого можно добиться, используя «теневую таблицу». Закончив построение которой, вы можете поменять таблицы местами, мгновенно переименовав их.

Преимущества:

- запросы пользователей не ожидают перестроения кеша


- конкуренция и одновременное перестроение кешей отсутствуют в принципе, т.к. обновлением занимается один процесс


Недостаток:

- требуются «ресурсы» на мониторинг скрипта, осуществляющего перестроение кеша




### Критические секции

Критические секции в memcache – механизм распределенной синхронизации. Они реализуются через блокировку (мьютекса, двоичного семафора). Варианты реализации. 

Первый некорректный. Пусть мы хотим заблокироваться по ключу ‘lock’: пытаемся получить значения ключа с помощью операции get. Если ключ не найден, значит блокировки нет, и мы с помощью операции `set `устанавливаем значение этого ключа, например, в единицу, а время жизни устанавливаем в небольшой интервал времени, который превышает максимальное время жизни блокировки, например, в 10 секунд. Теперь, если frontend завершится аварийно и не снимет блокировку, она автоматически уничтожится через 10 секунд. Выполнили все необходимые действия, после этого снимаем блокировку просто удаляя соответствующий ключ командой `del`. Если на первой операции `get` мы получили значение ключа, это означает, что блокировка уже установлена другим процессом, наша операция блокировки неуспешна. 

Описанный способ обладает недостатком: наличием состояния гонки (race condition). Два процесса могут одновременно сделать `get`, оба могут получить ответ, что «ключа нет», оба сделают `set`, и оба будут считать, что установили блокировку успешно. В ситуациях, как одновременное перестроение кэшей, этого может быть допустимо, т.к. здесь цель не исключить все другие процессы, а резко уменьшить количество одновременных запросов к БД, что может обеспечить и этот простой, некорректный вариант.
 Второй вариант корректен, и даже проще первого. Для захвата блокировки достаточно выполнить одну команду: `add`, указав имя ключа и время жизни (такое же маленькое, как и в первом варианте). Команда `add` будет успешной только в том случае, если ключа в memcached еще нет, то есть наш процесс и есть тот единственный процесс, которому удалось захватить блокировку. Если `add` вернет ошибку «такой ключ уже существует», значит, блокировка была захвачена раньше каким-то другим процессом. Она атомарно выполняет проверку существования ключа и установку его значения.

После каждой неудачной попытки захвата мьютекса (ключа в мемкеш) процесс засыпает на время. Это могут быть случайные интервалы времени, лучше линейно наращивать время сна от малых значений к большим.

Также критические секции можно реализовать через хранение мьютекса (lock-ключа) в shared memory. При наличии одного бэкенда это будет честная блокировка. Если бекэндов немного, то блокировка отдельно на каждом может быть приемлема для некоторых задач, например, одновременного перестроения кешей, тогда количество параллельных запросов в базу резко снижается.



### Статистика работы memcached

Самая простая команда, stats, позволяет получить элементарную статистику: время работы сервера (uptime), объем используемой памяти, количество get запросов и количество хитов (hits), т.е. попаданий в кэш. Их соотношение позволяет нам судить об эффективности кэширования в целом. Параметр evictions – сколько ключей было удалено раньше истечения срока жизни может сигнализировать о недостаточности объема памяти memcached.

### Распределение памяти

Для распределения памяти под значения ключей memcached использует вариант slab-аллокатора. Распределение slab – это механизм эффективного распределения памяти и устранения значительной фрагментации. Основой этого алгоритма является сохранение выделенной памяти, содержащей объект определенного типа, и повторное использование этой памяти при следующем выделении для объекта того же типа

Распределитель slab хранит информацию о размещении этих участков, которые называются кэши. Таким образом, если поступает запрос на выделение памяти для объекта данных определенного размера, он может мгновенно удовлетворить запрос уже выделенным слотом. Однако, уничтожение объектов не освобождает память, а только открывает слот, который помещается в список свободных слотов распределителем slab. Следующий вызов для выделения памяти того же размера вернет слот памяти, не используемый в данный момент. Этот процесс устраняет необходимость в поиске подходящего участка памяти и значительно снижает фрагментацию памяти.

Когда процесс обращается за новым объектом ядра, система делает попытку найти свободное место для этого объекта в частично занятом slab’е в кэше для этого типа объектов. Если такого места не находится, система выделяет новый slab из смежных физических страниц и передает их в кэш. Новый объект размещается в этом slab’е, а это местоположение помечается как «частично занятое».

Отсутствует внутренняя фрагментация памяти. Распределение происходит быстро, поскольку система создает объекты заранее и легко выделяет их из slab’а.

Например, slab для хранения объектов размером 256 байт, при этом сам slab имеет размер 1 Мб, таким образом он может сохранить 4096 таких объектов. Память внутри такого slab’а выделяется только по 256 байт. Если у нас есть slab’ы для объектов размером 64, 128, 256, 1024 и 2048 байт, то максимальный размер объекта, который мы можем сохранить – 2048 байт (в последнем slabе). Если мы хотим сохранить объект размером 65 байт, под него будет выделена память в slab’е-128, 1 байт – в slab’е 64.

Чтобы добиться эффективного использования памяти memcached для хранения наших ключей и значений, мы должны быть уверены в правильном выборе размеров slab’ов, который выделил memcached, а также в их разумном наполнении. Для этого мы можем попросить memcached предоставить статистику по slab’ам 

$mc->getExtendedStat(‘slab’). 

Как правило, больше всего slab’ов выделено под ключи с относительно небольшими значениями – до 20 Кб, для больших по размеру ключей slab’ов гораздо меньше. Если график отличается от того, который ожидается по логике задачи, это повод для беспокойства.

### Мониторинг работы с memcached

Для мониторинга необходимо писать отладочную информацию о каждом событии в файл в режиме append или в БД (отдельно по конкретному ключу или сразу по всему кешу). Возможные события: кэш устарел (если дата устаревания хранится в кеше) (или не найден), попытка заблокироваться, запись (и построение) нового кэша, удаление блокировки, успешный запрос кэша.

### Другие примеры

**Кеширование категорий пользователей**. Если имеется набор фотографий и каждой назначена приватность по списку: владельцу, друзьям, выбранному кругу лиц. Кеширование списка можно организовать так: если типов доступа не много хранить отдельно три списка. Если много, то хранить весь список (если большой, то возможно с некоторым лимитом) и на стороне приложения делать фильтрацию списка по нужной группе пользователей.



```mysql

```
