**Взять ручку и листок!!!!**

Материал:

- Grokking the system design interview (https://www.educative.io/courses/grokking-the-system-design-interview/m2yDVZnQ8lG, есть копия в папке tricks
- Высоконагруженные приложения. Программирование, масштабирование, поддержка | Клеппман Мартин
- https://leetcode.com/discuss/general-discussion/125038/system-design-interview-prep
- https://engineering.videoblocks.com/web-architecture-101-a3224e126947
- https://bege13mot.github.io/grokking/#caching
- https://github.com/donnemartin/system-design-primer

# Общее

Проектирование системы состоит из шагов.

## Выяснение требований

Вопросы о дизайне открытые, и у них нет ОДНОГО правильного ответа. 

Поэтому важно задавать вопросы, чтобы:

- найти точный масштаб проблемы.
- понять на каких частях системы сосредоточиться 

### Нагрузка

- Сколько пользователей будут использовать систему?
- Количество read/write на пользователя?
- Количество read/write на систему (получается, это (1) * (2))
  - нужно уточнение. RPS не равномерно распределяется в течении дня ([1](#метрики-для-rps))

### Функциональные требования

Проговорить словами, что будет делать система!!!

- что размещать на сервисе (твиты, посты, комментарии, тексты)?
- что получают в ответ от сервиса (URL адрес)
- что могут делать пользователи на сервисе (create, read)
- что происходит в момент *create* и *read*
- необходимо ли размещать большой контент или медиа в *entity* (большой текст, фото, видео)
- необходимо ли отдельно загружать/скачивать медиа (фото, видео)
- ограничение размера *entity* (размера URL, размера текста)
- можно ли задавать `expiration_time`, удаляются ли entity автоматически через некоторое время.
- можно ли задавать `custom_entity_hash`, `custom_URL`
- пользователи
  - какие типы пользователей (usergroup), группы пользователей, (гости, зарегистрированные, админы)
  - ограничение доступа к entity для пользователей
  - как задается ограничение пользователей к entity (дискреционная система, мандатная, матрица доступа)
  - как связаны пользователи (подписки, чаты)
  - статус-онлайн
  - кошелек пользователя
  - регистрация / авторизация (смс)
  - профиль
- личные сообщения
  - одиночные чаты
  - групповые чаты
- комментарии
- паблишер постов
- генерация пользовательского контента
- геотаргетинг
- реклама
- теги
- категории
- suggestion
- подписка на контент (посты, теги, категории, сообщения), пользователей (follow), сообщества.
- избранные *entity*
- теги
- Похожий контент (посты (20М+), комментарии (35M+)), статика (картинки, видео), пользователи (2M+),
- поиск похожего контента для устранения дублирования (фото, видео,)
- необходимо ли разрабатывать интерфейс (???)
- требуется ли поиск
  - полнотекстовый
  - по названиям
  - по тегам
- требуются ли какие-то ленты с *entity*'s (лента новостей друзей, общие ленты новостей сайта )
- какие сортировки в лентах (hot, best, recent, trend)
- требуются ли блоки с *hot entity*'s (лучшие новости, топ пользователи)
- рассылка уведомлений  в веб-интерфейс, браузеры, телеграмм, мобильные приложения, push уведомлений в ios и android (ios – технология APN, android – технология GCM).
- как будем бороться со злоупотреблениями (антиспам, большое количество запросов от пользователя/IP)
- почтовые рассылки
- антиспама, автобана, автоматической фильтрации ненормативной лексики.
- жалобы (пост, коммент, пользователь)
- избранное (`favorite`)

Дополнительные требования:

- какие дополнительные настройки у *entity*:
  - выбор *custom ID* для *entity*
  - *expiration time* для *entity*

### Нефункциональные требования:

- требуемое время генерации страницы
- задержка получения *entity* (сообщений, лент)
- *durability*, почему и как нужно обеспечить
- *high availability*, почему нужно и как обеспечить
- непредсказуемость генерации *entity ID*
- соотношение *consistency - availability*

### Дополнительные требования

- Нужны ли сводные аналитические отчеты? Какие? Мониторинг?
- Доступ через REST API для сторонних сервисов



## Определение API системы

Позволяет:

- установить точный контракт, ожидаемый от системы.
- более точно формулирования требования к системе (входные и выходные данные)

Входные данные определяются на основе раздела функциональные требования!!!:

- смотреть [Построение data model](#построение-data-model)

Выходные данные:

- для `create` – URL на *entity* (`string`)
- для `delete ` – статус `OK`, `Error`

Выходные данные для сервисов:

- разные коды HTTP:
  - 200 OK 
  - 201 Created
  - 301 Moved Permanently 
  - 302 Redirect
  - 400 Bad Request 
  - 401 Unauthorized 
  - 403 Forbidden — запрещен доступ из-за ограничений
  - 404 Not found
  - 500 Internal Server Error 
  - 504 Gateway Timeout 

Типичные методы:

- `create`, `post`, 
- `read`, `get`
- `search`
- `update`
- `delete`
- `generate` (сгенерировать ленту)
- `mark` (пометить как какой-то статус, *favorite*, *moderate*,..)
- `setPermission` (установить права на entity)

Особенности работы:

- как будем бороться со злоупотреблениями (антиспам, большое количество запросов от пользователя/IP)

### REST

В имени `<entity>` необходимо использовать множественное число (`users`, `posts`)

Методы:

- `GET /<entity>` – получить список сущностей (`SELECT`)
- `GET /<entity>/<id>` – получить сущность с конкретным `id` (`SELECT`)
- `POST /<entity` – создать новую сущность (`INSERT`)
- `PUT /<entity>/<id>` – обновить сущность целиком (`UPDATE`)
- `PATCH /<entity>/<id>` – частично обновить сущность (`UPDATE`) 
- `DELETE /<entity>/<id>` – удалить сущность с `<id>`

Можно использовать вложенные методы:

- `GET /<entity>/<entity_id>/comments` – получить комментарий из сущности
- `GET /<entity>/<entity_id>/comments/<comment_id>` – получить комментарий с `<comment_id>` из сущности

Дополнительные параметры запроса:

- `GET /tickets?sort=-priority` – сортировка

Способы сериализации:

- `json`
- `xml`
- `yaml`

Версионирование API осуществляется указанием номера версии:

```
http://host/v1/users
```

Сегмент пути должен быть в нижнем регистре и разделен дефисами.

```
/customer-details/{customer-id}
```

Необходимо избегать косой черты в конце.

Документирование API:

- swagger



## Оценка характеристик системы

### Типы ресурсов

- Процессор


- Память (RAM)


- Disk IO


- Сеть

### Оценка нагрузки

- Задаем соотношение `создание_entity : чтение_entity` (например, `1:100`)

- Задаем RPM (*Request per month*) для `создание_entity`

- Считаем RPM для `чтение_entity`:

  ```
  чтение_entity_в_месяц = создание_entity_в_месяц * (создание_entity : чтение_entity)
  ```

- Считаем RPS для `создание_entity` и `чтение_entity`:

  ```
  создание_entity_в_секунду = создание_entity_в месяц / (30 * 24 * 3600)
  чтение_entity_в_секунду = чтение_entity_в_месяц / (30 * 24 * 3600)
  ```

### Оценки Entity

Задаем количество лет `хранить_лет`, в течении которых будем хранить *entity*'s. 

Задаем `размер_entity`:

- Если нет внешних объектов (фото, тексты), то `размер_entity` считается по размеру записи в БД
- Если есть внешние объекты (фото, тексты), то учитываем их размер, нужно оценить средний размер *entity*. Для внешних объектов можно задать: каждый 5-й содержит фото, каждый 10-й видео.
- Превью для внешних объектов.

Общее количество entity:

```
общее_количество_entity = создание_entity_в_месяц * 12 месяцев * хранить_лет
```



Размер `entity_id`:

```
размер_entity_id = log (общее_количество_entity)
```







### Оценка storage

Нужно отдельно посчитать *entity* и медиа в *entity*

Считаем общий размер *storage*:

```
размер_storage = общее_количество_entity * размер_entity
```

Количество серверов под storage:

```
количество_серверов_под_storage = размер_storage / (размер диска сервера)
```



### Оценка *network bandwidth* (пропускная способность сети)

Нужно отдельно посчитать трафик на *entity* и медиа в *entity*

- входящий трафик (*incoming traffic*)

  ```
  входящий_трафик = создание_entity_в_секунду * размер_entity
  ```

- исходящий трафик (*outgoing traffic*)

  ```
  исходящий_трафик = чтение_entity_в_секунду * размер_entity
  ```

### Оценка скорости чтения / записи на диск

```
скорость чтения = исходящий_трафик / количество_серверов
```

```
скорость записи = входящий_трафик / количество_серверов
```



### Оценка memory cache (кеша в памяти)

Согласно правилу 80-20, 20% *entity*'s генерируют 80% трафика, необходимо кэшировать эти 20% горячих entity's.

Размер *memory cache* для кэширования горячих *entity*'s в течении 24 часов (или можно несколько суток):

```
размер_memory_cache = чтение_entity_в_день * размер_entity * 20%
```









 

- количество серверов
- как часто надо перегенерировать *secondary information* (блоки, ленты) 

- 

- 



## Построение data model

В MongoDB можно хранить `array` в документах!!!

На этом шаге нужно посчитать размер *Entity*. 

В БД хранится только метаинформация, большие данные (статика, тексты) выносятся в облако.

Типичные объекты:

- 

- общие
  - `id`, `hash`, `session_id` 
  - `date` или `timestamp ` (дата)
    - `creation_date`
    - `expiration_date` (время протухания)
  - `location` (местоположение)
    - `latitude` (широта)
    - `longitude` (долгота) 

- `User` 
  - `user_id`
  -  `name`
  -  `email`
  -  `registration_date`
  -  `last_activity`
  -  `birthday`
  -  `age`
- `Entity` 
  - `entity_id`
  - `entity_hash`
  - `custom_entity_hash`,  `custom_URL`  (заданный пользователем)
  - `user_id`
  - `name ` или `title`
  - `category`
  - `description` 
  -  `content`  или `data` (контент)
  - `path_to_file` 
  - `image`, `video`
  -   (для NoSQL) `[user_ids]` с разрешением на доступ
  - рейтинг
    - `likes ` (лайки)
    - `dislikes` (дизлайки)
    - `rates` (рейтинг)
    - `views` количество просмотров
- `Media`, `Photo`, `Video`
  - `offset` (смещение) (для API, не БД)
  - `codec`
  - `resolution`
  - `size`
  - `preview`
- `Comment`
  - `text`
  - `user_id`
  - `entity_id`
  - `time`
  - `media` (`photo`, `video`)
- `Tag`
- `UserFollow` (подписки)
- `Favorite` (избранное)
- `Permissions` (имеющиеся разрешения)
  - `permission_id`
  - `permission_name`
- `User_permissions`  (разрешения пользователей на отдельные `entity`)
  - `user_id`
  - `permission_id`
  - `entity_id`
- `User_groups` (типы пользователей по правам)
- `adv` (реклама)
- `mail` (почтовые сообщения)
- `ban` (баны)
- `block_cache` (блоки в кеше)
- `category` (категории)
- `community` (сообщества)
- `complaint` (жалоба)
- `gallery` (галереи)
- `post` (пост)
- `notification` (уведомления)
- `subscribe` (подписка)
- `wallet` (кошелек)

### Выбор СУБД

Аргументы в пользу документно-ориентированной NoSQL (Mongo):

- хранятся большое количество строк
- между сущностями мало связей
- легко выполняется, встроенное шардирование
- можно вкладывать в документ массивы сущностей `{ user_photos: [ {....}, {...}] }`

Необходимо выбрать СУБД

- NoSQL
- RDBMS (MySQL, Postgres)

 Выбор *Storage* для хранения статики:

- HDD
- SDD

### Оценка storage под БД

Аналогично [Оценка storage](#оценка-storage)

- `unsigned int` – 4 байта (4,2 млрд), 8 байт
- `date`
  - `datetime` – 8 байт
  - `timestamp` – 4 байт

- `string` (1 байт или 1-3 байта на символ)
  - `name` – 20 байт
  - `email` – 32 байт
- вещественные
  - `float` (4 байт)
  - `double` (8 байт)
  - `decimal` – отдельно требуется место под целую и дробную часть, каждые 9 цифр - 4 байта. Все что больше 9 цифр, упаковывается в 1-4 байта. 

Отдельно считается каждая таблица

## Алгоритм работы

### Генерация внешнего `entity_hash`

Также [Генерация глобально уникальных идентификаторов](Sharding.md#генерация-глобально-уникальных-идентификаторов)

Варианты:

- использовать свойства Entity для получения `entity_hash` (например, `URL` или `name`). 

  Недостаток: предсказуемость `entity_hash`.

- генерировать `entity_hash` от случайных значений.

  Недостаток: возможные дубликаты ключей

- Использовать сервис генерации ключей (KGS), которая заранее генерирует множество `entity_hash` и сохраняет их в базе данных (назовем ее key-DB). Backend'ы берем один из уже сгенерированных *hash*'ей и используем его. А лучше берет сразу пачку *hash*'ей.

  Можно посчитать – сколько место будут занимать все заранее сгенерированные хеши:

  ```
  место_на_диске = количество_хешей * размер_хеша
  ```

  

  Преимущества: нет дубликатов, они проверяются заранее.

Для получения `entity_hash` необходимо рассчитать каким-то образом *hash*:

- MD5. Хеш содержит 128 бит (16 байт) и обычно представляется как последовательность из 32 шестнадцатеричных цифр

  ```
  MD5("md5") = 1BC29B36F623BA82AAF6724FD3B16718
  ```

  

- SHA256

А затем *binary hash* необходимо представить в виде набора отображаемых символов, которые допустимо использовать в URL. Например, с помощью:

- base64 ([AZ, az, 0-9] «-» «.»)  (1 символ - 6 бит)

На основе основания кодировки рассчитываем количество возможных хешей:

```
количество_хешей = 64 ^ количество_символов_в_хеше
```

Можно рассчитать нужное `количество_символов_в_хеше`

`количество_символов_в_хеше` = *log <sub>64</sub>* `общее_количество_entity`

### Генерация лент из данных нескольких шард

- медленный. Сервер собирает данные из нескольких шард. Например, для формирования ленты в 100 фото, он собирает по 100 фото для каждого подписанного друга, сортирует их и выбирает лучшие 100.
- постоянно генерировать для каждого пользователя таблицу `UserNewsFeed`. Для этого выделить отдельные сервера генерации лент

## Фронтенд

Способы получения с backend данных:

- для сообщений
- для лент

Способы:

- pull. Клиенты сами перезагружают страницу.
- push. сервер сам отправляет новые данные пользователям
  - websocket
  - long pooling для тех, у кого websocket не работает (старый браузер, сидят за прокси). Если сервер не имеет новой информации для клиента при получении опроса, вместо отправки пустого ответа сервер держит запрос открытым и ожидает, пока информация ответа станет доступной. Как только у него появляется новая информация, сервер немедленно отправляет клиенту ответ HTTP/S, завершая открытый запрос HTTP/S.

Если используется websocket соединение, то нужно посчитать сколько серверов требуется, чтобы держать коннекты:

```
количество_серверов = количество_подключений_в_один_момент / 50 000
```

При потере соединения, браузер должен автоматически переподключаться.

## High-level design (стандартная архитектура)



Нужно нарисовать блок-схему из 5-6 блоков, представляющих основные компоненты системы.

При построении архитектуры важно рассмотреть различные подходы, их плюсы и минусы, понять trade-off (компромиссы).

Основные компоненты архитектуры.

### Backend (web application server)

*backend*'s (*web application servers*) для обработки *dynamic requests*'s. 

*backend*'s можно разделить на группы (отдельные на схеме), в зависимости от типа нагрузки:

- *write* (как у нас `adm1` для записи статики, сохранениям комментов) – т.к. загрузка это тяжелая операция и если поступает много операций write, то пользователи не смогу *read*
- *read*

### Load balancing

(точка отказа, дублируется)

Где использовать балансировку:

- между клиентами и *application server*'ами
  - *Front Load Balancer*. Перед *backend*'s размещается несколько программных балансировщиков в виде *nginx* на отдельном узле. 
  - DNS-балансировка. Для балансировки нагрузки на программные балансировщики *nginx*.
- между *application server*'ами и *database server*'ами
- между *application server*'ами и *cache server*'ами

Алгоритмы балансировки:

- Round-robin
- Least Connection – с наименьшим количеством соединений
- Least Response Time – с наименьшим временем ответа
- Least Bandwidth – с наименьшим объемом трафика
- Weighted Round Robin – взвешенный Round Robin
- IP Hash – по IP

### Nginx


- *nginx* для проектирования запросов на *backend*'ы. *nginx* проксирует запросы к `*.php` на PHP-FPM (*Apache*). В итоге *Nginx* сам поддерживает большое количество `keep-alive` соединений небольшим количеством воркеров за счет эффективной архитектуры. До *Apache* долетает лишь малое количество очень коротких по времени проксированных запросов от nginx. Ответ *Apache* вычитывается в буфер *nginx* и отдается с требуемой клиентом скоростью.


- *nginx* для отдачи статики.

### Облако (статика, storage)

Варианты реализации:


- собственная система статики. Статика (картинки, видео) и динамика (php-скрипты) разносятся по разным серверам. Запросы к API-приложения, которые обрабатываются серверами динамики, небольшие по размеру и должны выполняться очень быстро. Запросы к статике, наоборот, тяжелые и для них не требуется значительная оперативность. Поэтому для них требуется разная конфигурация серверов по процессору и памяти. Если статика и динамика расположены на одном сервере, тяжелые запросы к статике начнут тормозить легкие оперативные запросы к API.
- Часто статика выносится в облако (Amazon S3), для того чтобы использовать готовую реализацию хранения и обработки статики.

Собственная система:

- *durability*, дублирование данных на разных серверах
- шардирование статики по серверам

### CDN

Нужна всем проектам со статикой. Можно обойтись своей системой хранения статики.

CDN запрашивает файл у серверов статики, а затем кэшировать его локально и передавать запрашивающему пользователю.

### База данных

База данных вынесена на отдельный сервер. 

Если есть внешние объекты (тексты, фото), то здесь хранятся *Entity Metadata* (так пишется на схеме)

Вопросы:

- каким образом масштабировать базу данных:
  - масштабировать не нужно, все влезает в одну БД. Не позволяет наращивать масштаб системы, имеет ограничение по RPS.
  - репликация. **В архитектуре replicas**. Выбираем для масштабирования по *read*. Не позволяет наращивать масштаб системы, имеет ограничение по RPS по write. Есть сервер с master DB и несколько slave DB, на которые осуществляется репликация.
  - шардирование
  - scale back? (*удаление неиспользуемых entity*'s) В архитектуре **Сервис переноса в архив**. Возможно хранить `expiration_time`. Смотреть [Scaling back](Highload.md#scaling-back)
- каким образом проиндексировать данные. Кластерный ключ определяет порядок хранения данных и возможность размещения горячих данных вместе.
- ленты с большими смещения `OFFSET` ()
  - покрывающие индексы
  - ограничение количества страниц
  - переделано с `OFFSET` на условие `id>`
  - транзакционный (InnoDB) и нетранзакционный движок

#### Шардирование

Также [шардирование](Sharding.md)

Усложняет архитектуру системы.

Вопросы:

- Подсистема роутинга запросов к шардированной БД. Координатор (coordinator), умный клиент, прокси.
- виды шардирования
  - вертикальное шардирование
  - горизонтальное шардирование
- выбор ключа шардирования – идентификатор важной сущности (чаще всего `user_id` или `entity_id`), при этом этот обработка данных одного самого активного идентификатора (самого активного пользователя) должна влезать на сервер. 
- выбор функции шардирования:
  - фиксированное – плохо, неравномерно
  - *consistent hashing*  – лучше, позволяет гибко!!! управлять распределением слотов по шардам, путем задания параметров для формулы *consistent hashing*
  - динамическое – еще лучше, но нужно хранить где-то отображение
- дублирование данных в shard'ах. 
  - Например сообщения можно хранить сразу на shard'ах обоих пользователей. Или хранить в отдельном кластере с диалогами.
- [генерация глобально уникальных идентификаторов]()
- что делать с горячими *user*'ами , которые много твитят или подписываются на множество людей? Использовать кеширование (смотреть [горячие фотографии](Highload.md#хранение-статики-в-своем-кластере), смотреть [горячие ключи](Highload.md#горячие-ключи), [расчёт степени теплоты секций](Sharding.md#новые-данные-на-выбранные-сервера-new-data-on-selected-servers)). Считать степень теплоты секции и когда она перегревается прекращать туда запись.
- Подсистема исполнения распределенных транзакций, согласованных в конечном счете, используется единая очередь транзакций, транзакции реализованы как идемпотентные и коммутативные (для этого извлекаем сообщение о событии из исходном шарда).

На основе [оценки storage под БД]() можно посчитать количество шардов:

```
количество_шард = размер_БД / размер шарда (лучше с запасом)
```



### Кеш

Какие виды кешей использовать.

- Система распределенного кеширования в памяти (memcached, redis) вынесена на отдельный сервер с большим количеством оперативной памяти.

  Современный сервер может иметь 256 ГБ памяти, количество требуемых серверов:

  ```
  количество_серверов = размер_memory_cache / 256 ГБ
  ```

- в разделяемой памяти *application server*, shared memory, расширение `shmop`
- в базе данных (кеширующие и сводные таблицы)
- на диске (статика, превью)
- в сети, реверс прокси nginx
- а браузере, заголовки `Cache-Control`, `ETag`, `If-None-Match`, `Vary`

Особенности:

- включить в архитектуру реплики для кешей
- использовать *sharding* через *consistent hashing*
- *dog pile effect*
- критическая секция
- инвалидация ключей на основе тегирования
- Реализация счетчиков, с шардированием ключей на чтение и на запись

#### Алгоритм вытеснения из кеша

Необходимо выбрать алгоритм вытеснения кеша (также [1](Algorithm.md#алгоритмы-вытеснения-из-кеша)). Все методы требуют использования структуры, для сбора статистики по использованию ключей.

- Least recently used (LRU, наименее недавно используемый) – в первую очередь вытесняются записи, неиспользованные дольше всех. 

- Most Recently Used (MRU, наиболее недавно использовавшийся): в первую очередь вытесняется последний использованный элемент. Полезны, когда чем старше элемент, тем больше обращений к нему происходит.


- Least-Frequently Used (LFU, наименее часто используемый) – подсчитывает, как часто используется элемент. Те элементы, обращения к которым происходят реже всего, вытесняются в первую очередь.

Кроме того можно учитывать: 

- Хранить дольше данные, которые дороже получать.


- Вытеснять быстрее записи большого размера, т.к. это позволит сохранить несколько записей поменьше. 

### Очереди

Очереди для того, чтобы хранить фоновые тяжелые задачи

- синхронизация статики (rsync картинок)
- обработка видео и аудио
- отправки смс
- отправки уведомлений в браузер и моб приложения, мобильные устройства

 Для их поддержки нужны:


  - *Message broker*'s (часто Rabbit MQ, или просто БД)

  - *backend*'s, которые взаимодействуют с *message broker*'s и выполняют фоновые тяжелые задачи. Это часто группы backend's, каждая из которые выполняет некоторую специфичную задачу и соответствующим образом под нее сконфигурирована. Например, для обработки видео требуется быстрый CPU, а для отправки сообщений – быстрый *network*.

  *Message broker* и эти бекенды размещают на отдельных серверах. 



### Поиск

Поисковый движок: Apache Solr, Sphinx, ElasticSearch

### Сервисы

набор сервисов (микросервисная архитектура). Они могут быть:


  - внешние (сторонние), например, отправка писем
  - внутренние (собственные), например на Go

      - кодировка фото/видео
      - генерация превью (фото, видео)
      - генерация лент для пользователей в шардах
    - почтовые рассылки
    - рассылка уведомлений  в веб-интерфейс, браузеры, телеграмм, мобильные приложения, push уведомлений в ios и android (ios – технология APN, android – технология GCM).
    - смс-уведомления
    - поиска похожего контента для устранения дублирования (фото, видео)

Для сервисов три столпа:

- мониторинг
- логирование
- трасировка

Из трейсеров:

-  Jaeger (Go)
- Zipkin (Java)








- потоковая обработка данных (стримминг). Реализуется Apache Kafka. Собирает поток событий из системы (лайки, публикации, комментарии) и подготавливает их и агрегирует, чтобы дальше они могли быть удобно визуализированы. Например, сколько лайков было ставлено за последний час. То же самое можно сделать и с базой данный, но Kafka позволяет обрисовывать данные из скользящего окна за последний час/день (и т.д.) и не нагружает базу данных.
- хранилище данных – для сбора событий и построения сложных аналитических отчетов. Реализация – Hadoop. Он хранит огромное количество данных, мы запускаемм Map-Reduce и он агрегирует эти данные из хранилища.

### Test и Deployment

- Непрерывная интеграция с помощью Jenkins
- тестирование
- развертывание приложения

## Выявление и устранение bottlenecks (узких мест)

Вопросы:

- Точки отказа (*point of failure*) среди компонентов архитектуры? Устраняются за счет избыточности компонентов.
  
  Необходимо дублировать все сервисы
  
  - служба генерации *hash*'ей
  
- Потеря данных устраняется за счет избыточного хранения данных.

  Необходимо сделать replica's (для БД, кешей) для всех данных, чтобы при выходе из строя одного из них выдержать нагрузку. 

## Мониторинг

- Мониторинг компонентов архитектуры
  - самописное в СУБД
  - ELK-стек –  для анализа логов
  - Prometheus + Grafana
  - Zabbix 
  - newrelic
  - след оповещения
  - логирование

- визуализации статистики
- оповещения когда критические компоненты выходят из строя или их производительность снижается.

Мониторить:

- сервера, 
- кэши, 
- очереди
  - длина очередей
  - время хранения сообщений, 
- подсистем приложения, 
- бизнес-метрик
  - проблемы с загрузкой картинок со сторонних серверов. Мы написали утилиту, которая периодически проверяет доступность картинок, время их загрузки
  - Лайки
  - Кол-во *entity*
  - Рассылки
  - Регистрации, авторизации
  - Переходы из соцсетей, поисковиков
  - время генерации 



