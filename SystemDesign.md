**Взять ручку и листок!!!!**

Материал:

- Grokking the system design interview (https://www.educative.io/courses/grokking-the-system-design-interview/m2yDVZnQ8lG, есть копия в папке tricks
- Высоконагруженные приложения. Программирование, масштабирование, поддержка | Клеппман Мартин
- https://leetcode.com/discuss/general-discussion/125038/system-design-interview-prep

- https://engineering.videoblocks.com/web-architecture-101-a3224e126947

# Общее

Проектирование системы состоит из шагов.

## Выяснение требований

Вопросы о дизайне открытые, и у них нет ОДНОГО правильного ответа. 

Поэтому важно задавать вопросы, чтобы:

- найти точный масштаб проблемы.
- понять на каких частях системы сосредоточиться 

### Нагрузка

- Сколько пользователей будут использовать систему?
- Количество read/write на пользователя?
- Количество read/write на систему (получается, это (1) * (2))
  - нужно уточнение. RPS не равномерно распределяется в течении дня ([1](#метрики-для-rps))

### Функциональные требования

Проговорить словами, что будет делать система!!!

- что размещать на сервисе (твиты, посты, комментарии)?
- что могут делать пользователи на сервисе (create, read)
- что происходит в момент *create* и *read*
- необходимо ли размещать медиа в *entity* (фото, видео)
- необходимо ли разрабатывать интерфейс (???)
- требуются ли какие-то ленты с *entity*'s (лента новостей друзей, )
- требуется ли поиск
- какие сортировки в лентах (hot, best, recent, trend)
- требуются ли блоки с *hot entity*'s (лучшие новости, топ пользователи)
- *notification* пользователей?
- как будем бороться со злоупотреблениями (антиспам, большое количество запросов от пользователя/IP)

Дополнительные требования:

- какие дополнительные настройки у *entity*:
  - выбор *custom ID* для *entity*
  - *expiration time* для *entity*

### Нефункциональные требования:

- требуемое время ответа
- *high availability*, почему нужно и как обеспечить
- непредсказуемость генерации *entity ID*

### Дополнительные требования

- Нужны ли сводные аналитические отчеты? Какие?
- Доступ через REST API для сторонних сервисов



## Определение API системы

Позволяет:

- установить точный контракт, ожидаемый от системы.
- более точно формулирования требования к системе (входные и выходные данные)

Входные данные определяются на основе раздела функциональные требования!!!:

- `key`, `hash`, `session_id` для итентификации пользователя
- 
- `user_id`
- `content` или `data` (контент)
- `date` или `timestamp ` (дата)
- `location` (местоположение)
- `likes ` (лайки)
- `dislikes` (дизлайки)
- `rates` (рейтинг)
- `custom ID` (кастомный ID)
- `expiration_time` (время протухания)

Выходные данные:

- для `create` – ссылка на *entity* (`string`)
- для `delete ` – статус `OK`, `Error`



Типичные методы:

- `create`, `post`, `delete`
- `generate` (сгенерировать ленту)
- `mark` (пометить как какой-то статус, *favorite*, *moderate*,..)

Особенности работы:

- как будем бороться со злоупотреблениями (антиспам, большое количество запросов от пользователя/IP)

## Оценка характеристик системы

### Оценка нагрузки

- Задаем соотношение `создание_entity : чтение_entity` (например, `1:100`)

- Задаем RPM (*Request per month*) для `создание_entity`

- Считаем RPM для `чтение_entity`:

  ```
  чтение_entity_в_месяц = создание_entity_в_месяц * (создание_entity : чтение_entity)
  ```

- Считаем RPS для `создание_entity` и `чтение_entity`:

  ```
  создание_entity_в_секунду = создание_entity_в месяц / (30 * 24 * 3600)
  чтение_entity_в_секунду = чтение_entity_в_месяц / (30 * 24 * 3600)
  ```

### Оценка storage

- Задаем количество лет `хранить_лет`, в течении которых будем хранить *entity*'s. 

  (Где-то дальше считается размер одной *entity* – `размер_entity`??)

- Считаем общий размер *storage*:

  ```
  размер_storage = создание_entity_в_месяц * 12 месяцев * хранить_лет * размер_entity
  ```

### Оценка *network bandwidth* (пропускная способность сети)

- входящий трафик (*incoming traffic*)

  ```
  входящий_трафик = создание_entity_в_секунду * размер_entity
  ```

- исходящий трафик (*outgoing traffic*)

  ```
  исходящий_трафик = чтение_entity_в_секунду * размер_entity
  ```

### Оценка memory cache (кеша в памяти)

Согласно правилу 80-20, 20% *entity*'s генерируют 80% трафика, необходимо кэшировать эти 20% горячих entity's.

Размер *memory cache* для кэширования горячих *entity*'s в течении 24 часов:

```
размер_memory_cache = чтение_entity_в_день * размер_entity * 20%
```









 

- количество серверов
- как часто надо перегенерировать *secondary information* (блоки, ленты) 

- 

- 



## Построение data model

Типичные объекты:

- `User` (`user_id`, `name`, `email`, `registration_date`, `last_activity`)
- `Entity` (`entity_id`, `content`,  ...) (смотреть входные данные в [определение API системы]())

- `Follow`
- `Favorite`

Необходимо выбрать СУБД:

- NoSQL
- RDBMS (MySQL, Postgres)

 Выбор *Storage* для хранения статики:

- HDD
- SDD

## High-level design (стандартная архитектура)



Нужно нарисовать блок-схему из 5-6 блоков, представляющих основные компоненты системы.

При построении архитектуры важно рассмотреть различные подходы, их плюсы и минусы, понять trade-off (компромиссы).

Основные компоненты архитектуры.

### Backend (web application server)

*backend*'s (*web application servers*) для обработки *dynamic requests*'s. 

*backend*'s можно разделить на группы, в зависимости от типа нагрузки:

- *write* (как у нас `adm1` для записи статики, сохранениям комментов)
- *read*

### Load balancing

Где использовать балансировку.

- *Front Load Balancer*. Перед *backend*'s размещается несколько программных балансировщиков в виде *nginx* на отдельном узле. 


- DNS-балансировка. Для балансировки нагрузки на программные балансировщики *nginx*.

### Nginx


- *nginx* для проектирования запросов на *backend*'ы. *nginx* проксирует запросы к `*.php` на PHP-FPM (*Apache*). В итоге *Nginx* сам поддерживает большое количество `keep-alive` соединений небольшим количеством воркеров за счет эффективной архитектуры. До *Apache* долетает лишь малое количество очень коротких по времени проксированных запросов от nginx. Ответ *Apache* вычитывается в буфер *nginx* и отдается с требуемой клиентом скоростью.


- *nginx* для отдачи статики.

### Статика

Варианты реализации:


- собственная система статики. Статика (картинки, видео) и динамика (php-скрипты) разносятся по разным серверам. Запросы к API-приложения, которые обрабатываются серверами динамики, небольшие по размеру и должны выполняться очень быстро. Запросы к статике, наоборот, тяжелые и для них не требуется значительная оперативность. Поэтому для них требуется разная конфигурация серверов по процессору и памяти. Если статика и динамика расположены на одном сервере, тяжелые запросы к статике начнут тормозить легкие оперативные запросы к API.

- Часто статика выносится в облако (Amazon S3), для того чтобы использовать готовую реализацию хранения и обработки статики.

### База данных

База данных вынесена на отдельный сервер. 

Вопросы:

- каким образом масштабировать базу данных:
  - масштабировать не нужно, все влезает в одну БД. Не позволяет наращивать масштаб системы, имеет ограничение по RPS.
  - репликация. Не позволяет наращивать масштаб системы, имеет ограничение по RPS по write. Есть сервер с master DB и несколько slave DB, на которые осуществляется репликация.
  - шардирование. Усложняет архитектуру системы.
    - что делать с горячими *user*'ами , которые много твитят или подписываются на множество людей? Использовать кеширование (смотреть [горячие фотографии](Highload.md#хранение-статики-в-своем-кластере), смотреть [горячие ключи](Highload.md#горячие-ключи), [расчёт степени теплоты секций](Sharding.md#новые-данные-на-выбранные-сервера-new-data-on-selected-servers))

- каким образом проиндексировать данные. Кластерный ключ определяет порядок хранения данных и возможность размещения горячих данных вместе.

### Кеш

Какие виды кешей использовать.

- Система распределенного кеширования в памяти (memcached, redis) вынесена на отдельный сервер с большим количеством оперативной памяти.



### Очереди


- Очереди для того, чтобы хранить фоновые тяжелые задачи (обработать видео, отправить сообщение). Для их поддержки нужны:


    - *Message broker*'s (часто Rabbit MQ, или просто БД)
    
    - *backend*'s, которые взаимодействуют с *message broker*'s и выполняют фоновые тяжелые задачи. Это часто группы backend's, каждая из которые выполняет некоторую специфичную задачу и соответствующим образом под нее сконфигурирована. Например, для обработки видео требуется быстрый CPU, а для отправки сообщений – быстрый *network*.
    
      *Message broker* и эти бекенды размещают на отдельных серверах. 

- Поисковый движок: Apache Solr, Sphinx, ElasticSearch

- набор сервисов (микросервисная архитектура). Они могут быть:


  - внешние (сторонние), например, отправка писем
  - внутренние (собственные), например на Go

- потоковая обработка данных (стримминг). Реализуется Apache Kafka. Собирает поток событий из системы (лайки, публикации, комментарии) и подготавливает их и агрегирует, чтобы дальше они могли быть удобно визуализированы. Например, сколько лайков было ставлено за последний час. То же самое можно сделать и с базой данный, но Kafka позволяет обрисовывать данные из скользящего окна за последний час/день (и т.д.) и не нагружает базу данных.

- хранилище данных – для сбора событий и построения сложных аналитических отчетов. Реализация – Hadoop. Он хранит огромное количество данных, мы запускаемм Map-Reduce и он агрегирует эти данные из хранилища.

## Выявление и устранение bottlenecks (узких мест)

Вопросы:

- Точки отказа (*point of failure*) среди компонентов архитектуры? Как их устранить?
- Достаточно ли replica's, чтобы при выходе из строя одного из них выдержать нагрузку. 
- Мониторинг компонентов архитектуры (Prometheus + Grafana, Zabbix), оповещения когда критические компоненты выходят из строя или их производительность снижается.



Как мы обнаруживаем и предотвращаем злоупотреблени

Каждый api_dev_key может быть ограничен определенным количеством созданий URL-адресов и перенаправлений за некоторый период времени

Авторизация

Ограничение по сессии или ip

. Дизайн базы данных

* Нам нужно хранить миллиарды записей. * Каждый объект, который мы храним, небольшой (менее 1К). * Между записями нет никаких связей, кроме сохранения того, какой пользователь создал URL. * Наш сервис требует много чтения.

Поскольку мы ожидаем хранения миллиардов строк, и нам не нужно использовать отношения между объектами, хранилище ключей и значений NoSQL, такое как Dynamo или Cassandra, является лучшим выбором. Выбор NoSQL также будет легче масштабироват

6. Базовая конструкция системы и алгоритм

Сколько ключей можем за кодировать?

Base64 — стандарт кодирования двоичных данных при помощи только 64 символов ASCII. Алфавит кодирования содержит текстово-цифровые латинские символы A-Z, a-z и 0-9 (62 знака) и 2 дополнительных символа, зависящих от системы реализации. Каждые 3 исходных байта кодируются 4 символами (увеличение на ¹⁄₃).

алгоритм MD5 в качестве нашей хеш-функции, он выдаст 128-битное хеш-значение

Мы можем вычислить уникальный хэш (например, MD5 5 или SHA256 6 и т. Д.) Данного URL. З

Рисунок архитектуры
Павел
Павел 18:15

автономная служба генерации ключей (KGS), которая заранее генерирует случайные строки из

размер БД ключей

единственной точкой отказа? Д

кэшировать некоторые ключи из базы данных ключей? Д

Какие http коды должен отдавать сервис



нужно учитывать несколько вещей:

Какие разные архитектурные элементы можно использовать?

Как эти части работают друг с другом?

Как мы можем лучше всего использовать эти части, каковы правильные компромиссы?

Инвестирование в масштабирование до того, как это необходимо, обычно не является разумным бизнес-предложением; однако, некоторые заранее продуманные конструкции

Load Balancer (LB)
Павел
Павел 22:05

помогает распределить трафик по кластеру серверов, чтобы улучшить скорость отклика и доступность

. LB также отслеживает состояние всех ресурсов при распределении запросов. Если сервер недоступен для приема новых запросов или не отвечает или имеет повышенный уровень ошибок, LB прекратит отправку трафика на такой сервер.

Обычно балансировщик нагрузки находится между клиентом и сервером, принимающим входящий сетевой трафик и трафик приложений, и распределяющим трафик между несколькими внутренними серверами, используя различные алгоритмы. Балансируя запросы приложений на нескольких серверах, балансировщик нагрузки снижает нагрузку на отдельный сервер и предотвращает превращение одного сервера приложений в единую точку отказа, что повышает общую доступность и скорость отклика приложений.

Мы можем добавить LB в трех местах:

Между пользователем и веб-сервером

Между веб-серверами и внутренним уровнем платформы, таким как серверы приложений или серверы кэширования

Между внутренним уровнем платформы и базой данных.

Алгоритмы балансировки нагрузки

? Балансировщики нагрузки учитывают два фактора перед отправкой запроса на внутренний сервер. Сначала они гарантируют, что сервер, который они могут выбрать, действительно отвечают соответствующим образом на запросы, а затем используют предварительно настроенный алгоритм, чтобы выбрать один из набора исправных серверов.
29 июля
Павел
Павел 21:18

методов балансировки нагрузки

Метод наименьшего соединения - этот метод направляет трафик на сервер с наименьшим количеством активных соединени

Метод наименьшего времени отклика

ыбирает сервер, который в настоящее время обслуживает наименьший объем трафика

Метод Round Robin

Метод взвешенного циклического перебора -

Каждому серверу присваивается вес,

IP Hash - этот метод вычисляет хэш IP-адреса клиента, чтобы определить, какой сервер получает запрос.

Избыточные балансировщики нагрузки

Балансировщик нагрузки может быть единственной точкой отказа, для преодоления этого второй балансировщик нагрузки может быть подключен к первому

способо

Разработчики могут добавить алгоритм балансировки нагрузки в приложение или клиент базы данных

2. Аппаратные балансировщики нагрузки
. Самым дорогим,

3. Программные балансировщики нагрузки

HAProxy
Павел
Павел 21:47

HAProxy может работать на промежуточном сервере.

HAProxy может работать на той же машин

Очереди

требуются различные компоненты системы для асинхронной работы; общий способ сделать это с помощью очередей.

все входящие задачи добавляются в очередь, и, как только у любого работника появляется возможность обрабатывать, он может выбрать задачу из очереди.

Очереди реализованы по протоколу асинхронной связи.
Павел
Павел 22:09

Очереди также используются для обеспечения отказоустойчивости, поскольку они могут обеспечить некоторую защиту от перебоев в работе и отказов. Например, мы можем создать очень надежную очередь, которая может повторять запросы на обслуживание, которые не были выполнены из-за временных сбоев системы

RabbitMQ, ZeroMQ, ActiveMQ и BeanstalkD.
Павел
Павел 22:16

Нужно выяснить нагрузку



Основное различие между дизайнерскими собеседованиями и остальными заключается в том, что вам не дают полную информацию о проблеме, скорее вам необходимо масштабировать широту и глубину размытой проблемы. Вы должны взять детали и выяснить проблему, задавая пробные вопросы. Ваши вопросы для выяснения проблемы отражают ваши оценочные способности и компетенции, которые могут быть полезны для компании.

дход сверху вниз и модульность могут очень помочь в решении проблемы. Поэтому вы должны разбить проблему на модули, а затем заняться каждым из них независимо. Впоследствии каждый компонент может быть объяснен как подзадача путем снижения его до уровня известного алгоритма. Э

При устранении узких мест вашей системе может потребоваться балансировщик нагрузки со многими машинами за ней, чтобы обрабатывать пользовательские запросы, или данные могут быть настолько огромными, что вам нужно распределить базу данных по нескольким серверам.

ваша способность говорить об этих компромиссах и оценивать их влияние на систему

три этапа:

Рассмотрение проблемы: не делайте предположений; Задайте уточняющие вопросы, чтобы понять ограничения и варианты использования.

Создание абстрактного проекта Иллюстрирование строительных блоков системы и взаимосвязей между ними.

Выявление и устранение узких мест с использованием фундаментальных принципов построения масштабируемой системы.
30 июля
Павел
Павел 1:53

