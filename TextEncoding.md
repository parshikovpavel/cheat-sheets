# Кодирование текста

## Юникод (Unicode)

Стандарт состоит из двух основных частей.

·  Универсальный набора символов (Universal character set, UCS). Перечисляет допустимые по стандарту Юникод символы и присваивает каждому символу код в виде неотрицательного целого числа, записываемого обычно в шестнадцатеричной форме с префиксом U+, например, U+040F. Код символа называется также кодовой точкой (code point).

·  Семейство кодировок (Unicode transformation format, UTF). Определяет способы преобразования кодов символов в двоичный вид для хранения. 

Структура кодов UCS:

·  Область с кодами от U+0000 до U+007F содержит символы набора ASCII, и коды этих символов совпадают с их кодами в ASCII. 

·  Далее расположены области символов других систем письменности, знаки пунктуации и технические символы. 

·  Под символы кириллицы выделены области знаков с кодами от U+0400 до U+052F, от U+2DE0 до U+2DFF, от U+A640 до U+A69F

8-битная кодировка не позволяла разместить символы всех национальных алфавитов. Появляется множество видов 8 битных кодировок и даже по несколько для одного языка. Способы решения проблемы:

·  для корректного раскодирования разработать стадарт указания кодировки для файла. Все равно возникает много проблем с переключением между кодировками и языками в программах, преобразованием символов между кодировками.

·  создание единого реестра символов и единой «широкой» кодировки.

Первая версия Юникода представляла собой кодировку с фиксированным размером символа в 16 бит, т.е. содержала только UCS. С тех пор символы стали обозначать в формате U+04F0.

Затем было принято решение преобразовывать коды символов с помощью кодировок UTF, что позволило значительно расширить кодовую область. Коды символов стали рассматриваться не как 16-битные значения, а как абстрактные числа, которые в двоичный вид переводятся одной из кодировок UTF. 

Хотя формы записи UTF-8 и UTF-32 позволяют кодировать до                                 (2 147 483 648) кодовых позиций, было принято решение использовать лишь 1 112 064 для совместимости с UTF-16. В итоге максимальный код символа в UCS U+10FFFF . Впрочем, даже и этого на текущий момент более чем достаточно — в последней версии используется всего 136 690 кодовых позиций.

Кодовое пространство разбито на 17 плоскостей (англ. *planes*) по   (65 536) символов. Нулевая плоскость (*plane 0*) называется *базовой* (*basic*) и содержит символы наиболее употребительных письменностей. Остальные плоскости — *дополнительные* (*supplementary*).

### Порядок байтов

Любое число M в памяти компьютера записывается в виде последовательности байт, что можно представить как запись в системе счисления с основанием 256:

 

При этом   называется младшим байтом, а   — старшим байтом.

Если число представляется более чем одним байтом, то имеет значение в каком порядке в памяти эти байты записываются. 

#### Big-endian (BE)

Порядок от *старшего* к *младшему* (*big-endian* — большим концом): 

  .

Этот порядок соответствует привычному порядку записи арабских цифр, т.е.:

 

Этот порядок является стандартным для протоколов TCP/IP, он используется в заголовках пакетов данных и во многих протоколах более высокого уровня, разработанных для использования поверх TCP/IP. Поэтому порядок байтов от старшего к младшему часто называют «сетевым порядком байтов» (англ. network byte order).

#### Little-endian (LE)

Порядок от *младшего* к *старшему* (*little-endian* — малым концом): 

 

Это обратный порядок по отношению к привычному порядку записи арабских цифр, например, число 123 было бы записано как 321. 

Этот порядок записи принят в памяти персональных компьютеров с процессорами архитектуры x86, в связи с чем иногда его называют интеловский порядок байтов

#### BOM (Byte order mark)

Для кодировок UTF-16 и UTF-32 порядок байтов является существенным, поэтому существует варианты кодировок UTF-16 (BE) и UTF-16 (LE); UTF-32 (BE) и UTF-32 (LE).

Маркер последовательности байтов (Byte Order Mark, BOM) — специальный символ Юникод, вставляемый в начало текстового файла для обозначения того, что в файле используется Юникод, а также в кодировках UTF-16 и UTF-32 для косвенного указания кодировки и порядка байтов.

Номер этого символ в стандарте Юникод U+FEFF – неразрывный пробел нулевой длины, т.е. символ неотображаемый. «Перевёрнутый» вариант этого символа (U+FFFE) не существует и зарезервирован как раз для целей определения порядка байтов, что позволяет для UTF-16 и UTF-32 определить порядок байтов.

| UTF-8       | EF  BB BF    |
| ----------- | ------------ |
| UTF-16 (BE) | FE  FF       |
| UTF-16 (LE) | FF  FE       |
| UTF-32 (BE) | 00  00 FE FF |
| UTF-32 (LE) | FF  FE 00 00 |

Использование этого символа, согласно спецификации Юникод, не является обязательным, однако оно широко распространено, так как позволяет легко избежать неверного раскодирования текстовой информации.

### Кодировки UTF

Разработаны следующие кодировки UTF:

·  UTF-8

·  UTF-16 (UTF-16BE, UTF-16LE)

·  UTF-32 (UTF-32BE, UTF-32LE).

#### UTF-8

Использует переменное количество байт (от 1 до 4) и обеспечивает полную обратную совместимость с 7-битной кодировкой ASCII. Текст, состоящий только из символов с номерами меньше 128, при записи в UTF-8 превращается в обычный текст ASCII и может быть отображён любой программой, работающей с ASCII; и наоборот, текст, закодированный 7-битной ASCII может быть отображён программой, предназначенной для работы с UTF-8.

Наибольший выигрыш в компактности UTF-8 даёт для текстов на латинице, поскольку латинские буквы, цифры и наиболее распространённые знаки препинания кодируются в UTF-8 лишь одним байтом.

UTF-8 является доминирующей в веб-пространстве.

Алгоритм кодирования состоит из 3 этапов:

\1.   Определить количество байтов, требуемых для кодирования символа. Номер символа берётся из UCS.

| **Диапазон  номеров символов** | **Требуемое  количество октетов** |
| ------------------------------ | --------------------------------- |
| 00000000-0000007F              | 1                                 |
| 00000080-000007FF              | 2                                 |
| 00000800-0000FFFF              | 3                                 |
| 00010000-0010FFFF              | 4                                 |

\2. Установить старшие биты первого октета в соответствии с необходимым количеством октетов, определённом на первом этапе:

·  0xxxxxxx — если для кодирования потребуется *один* октет;

·  110xxxxx — если для кодирования потребуется *два* октета;

·  1110xxxx — если для кодирования потребуется *три* октета;

·  11110xxx — если для кодирования потребуется *четыре* октета.

Если для кодирования требуется больше одного октета, то в октетах 2-4 два старших бита всегда устанавливаются равными 10 (10xxxxxx). Это позволяет легко отличать первый октет в потоке, потому что его старшие биты никогда не равны 10.

| **Количество октетов** | **Значащих бит** | **Шаблон**                           |
| ---------------------- | ---------------- | ------------------------------------ |
| 1                      | 7                | 0xxxxxxx                             |
| 2                      | 11               | 110xxxxx  10xxxxxx                   |
| 3                      | 16               | 1110xxxx  10xxxxxx 10xxxxxx          |
| 4                      | 21               | 11110xxx  10xxxxxx 10xxxxxx 10xxxxxx |

\3. Установить значащие биты октетов в соответствии с номером символа в UTC. Начать заполнение с младших битов номера символа, поставив их в младшие биты последнего октета, продолжить справа налево до первого октета. Свободные биты первого октета, оставшиеся незадействованными, заполнить нулями.

Примеры:

 

| **Символ**                                        | **Двоичный код символа** | **UTF-8 в двоичном виде** |                                     |
| ------------------------------------------------- | ------------------------ | ------------------------- | ----------------------------------- |
| [$](https://ru.wikipedia.org/wiki/Символ_доллара) | U+0024                   | 10 0100                   | 00100100                            |
| [¢](https://ru.wikipedia.org/wiki/Символ_цента)   | U+00A2                   | 1010 0010                 | 11000010 10100010                   |
| [€](https://ru.wikipedia.org/wiki/Символ_евро)    | U+20AC                   | 10 0000 1010 1100         | 11100010 10000010 10101100          |
| [𐍈](https://ru.wikipedia.org/wiki/Хвайр)          | U+10348                  | 1 0000 0011 0100 1000     | 11110000 10010000 10001101 10001000 |

#### UTF-16

Первая версия Юникода (1991 г.) представляла собой 16-битную кодировку с фиксированной шириной символа; общее число разных символов было   (65 536). Во второй версии Юникода (1996 г.) было решено значительно расширить кодовую область; для сохранения совместимости с теми системами, где уже был реализован 16-битный Юникод, и была создана UTF-16.

Символы кодируются одним или двумя 16-битными словами с использованием всех возможных диапазонов значений (от 0 до FFFF16). При этом можно кодировать символы Unicode в диапазонах 000016..D7FF16 и E00016..10FFFF16. Исключенный отсюда диапазон D80016..DFFF16 используется для кодирования символов с помощью двух 16-битных слов (суррогатная пара) и эти коды в UCS не использовались.

Символы от U+0000 до U+FFFF, исключая диапазон для суррогатов D80016..DFFF16, записываются как есть 16-битным словом.

Символы же в диапазоне 1000016..10FFFF16 (больше 16 бит) кодируются по следующей схеме:

·  Из кода символа вычитается минимальное число 1000016. В результате получится значение от 0 до FFFFF16, которое занимает до 20 бит.

·  Старшие 10 бит (число в диапазоне 000016..03FF16) суммируются с D80016, и результат идёт в лидирующее (первое) слово, которое входит в диапазон D80016..DBFF16.

·  Младшие 10 бит (тоже число в диапазоне 000016..03FF16) суммируются с DC0016, и результат идёт в последующее (второе) слово, которое входит в диапазон DC0016..DFFF16.
 В обоих словах старшие 5 бит (15-11 бит) равны 110112, а 10-й бит содержит 0 у первого слова и 1 – у второго. Значения старших бит являются признаками суррогатной пары. 

Который из двух байтов в слове идёт впереди, старший или младший, зависит от порядка байтов.

#### UTF-32

Каждый символ кодируется ровно 32 битами. Остальные кодировки, UTF-8 и UTF-16, используют для представления символов переменное число байтов. Символ UTF-32 является прямым представлением его кодовой позиции

Главное преимущество UTF-32 перед кодировками переменной длины заключается в том, что символы Юникод непосредственно индексируемы. Получение n-ой кодовой позиции является операцией, занимающей одинаковое время. Напротив, коды с переменной длиной требует последовательного доступа к n-ой кодовой позиции. Это делает замену символов в строках UTF-32 простой, для этого используется целое число в качестве индекса, как обычно делается для строк ASCII.

Главный недостаток UTF-32 — это неэффективное использование пространства, так как для хранения любого символа используется четыре байта. Символы, лежащие за пределами нулевой (базовой) плоскости кодового пространства, редко используются в большинстве текстов. Поэтому удвоение, в сравнении с UTF-16, занимаемого строками в UTF-32 пространства, зачастую не оправдано.

## Перевод строки

Возврат каретки (carriage return, `CR`) — управляющий символ ASCII (`0x0D`, 13<sub>10</sub>, `\r`), при выводе которого курсор перемещается к левому краю поля.

Перевод на строку (*line feed*, `LF` — «подача [бумаги] на строку») — управляющий символ ASCII (`0x0A`, 10<sub>10</sub>, `\n`), при выводе которого курсор перемещается на следующую строку.

Для разделения строк ОС используют или `LF` или `CR` по отдельности, или последовательность `CR`+`LF`:

- `LF` используется в UNIX, UNIX-подобных операционных системах (GNU/Linux, Mac OS X, FreeBSD и др.);
- `CR` используется в Classic MacOS (Mac OS до версии 9);
- `CR`+`LF`  используется в  MS-DOS, Microsoft Windows, протоколах Интернет (?).

## Binary-safe

Binary-safe (бинарно-безопасный) – объект (например, функция), обрабатывающий данные как сырой поток байт и игнорирующий любые текстовые особенности данных. 

Например, в PHP можно открывать файл в *binary-safe* (`b`) или *text* (`t`) режиме. При чтении в *text* режиме в ОС Windows осуществляется прозрачное преобразование `\r\n` в `\n`. В *binary* режиме данные читаются как есть в бинарном виде ([1](#text-и-binary-modes))